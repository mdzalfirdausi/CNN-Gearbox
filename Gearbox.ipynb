{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Gearbox","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMFnwG1iyI5PU2Kha+IDEn0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBL52XMAgJux","executionInfo":{"status":"ok","timestamp":1640154326888,"user_tz":-180,"elapsed":6842,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"0ad1ad64-fb1d-440d-bb33-5af8d7f1d25a"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# firdaus251@gmail.com\n","# %cd /content/gdrive/My\\ Drive/S2/IE\\ 600\\ M.Sc.\\ Thesis/Gearbox"],"metadata":{"id":"qBXIM8_NgPV4"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ru9EwMCKekXo"},"outputs":[],"source":["# !git clone https://github.com/cathysiyu/Mechanical-datasets.git"]},{"cell_type":"code","source":["# def label(filename):\n","#     if 'Health' in filename:\n","#         return 0\n","#     elif 'Chipped' in filename:\n","#         return 1\n","#     elif 'Miss' in filename:\n","#         return 2\n","#     elif 'Root' in filename:\n","#         return 3\n","#     elif 'Surface' in filename:\n","#         return 4"],"metadata":{"id":"7yHu-S6tife_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import pandas as pd\n","# import numpy as np\n","# import os\n","# from pathlib import Path\n","# import re"],"metadata":{"id":"GtZfRRvRiiHm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/gdrive/My\\ Drive/S2/IE\\ 600\\ M.Sc.\\ Thesis/Gearbox/Mechanical-datasets/gearbox/gearset/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0nXZ8s4NhPM3","executionInfo":{"status":"ok","timestamp":1640154332668,"user_tz":-180,"elapsed":7,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"85d7fc6f-19b9-4dd2-90ce-4a311c4e8d5b"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/S2/IE 600 M.Sc. Thesis/Gearbox/Mechanical-datasets/gearbox/gearset\n"]}]},{"cell_type":"code","source":["# data_path = Path('.')"],"metadata":{"id":"PNjDgREBinYl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %%time\n","# dic_all = {}\n","# for filepath in data_path.glob('*.csv'):\n","#     key_name = str(filepath).split('\\\\')[-1]\n","#     df = pd.read_csv(filepath)\n","#     df = df.iloc[np.r_[11:1048571]]\n","#     df = pd.DataFrame([df.iloc[i][0].split('\\t') for i in range(df.reset_index(drop=True).shape[0])])\n","#     df = df.drop([8], axis=1)\n","#     df['label'] = label(str(filepath))\n","#     dic_all[key_name] = df"],"metadata":{"id":"N2sTSkQQki4J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %%time\n","# df = pd.DataFrame([])\n","# for i in dic_all:\n","#     df = pd.concat([df,dic_all[i]])\n","# df"],"metadata":{"id":"YkCRm5esmHL4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %%time\n","# df.to_csv('gearbox.csv')"],"metadata":{"id":"hKgL0GilqC7G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def append_signal(df, segment_length):\n","    dic = {}\n","    idx = 0\n","    idxd = 0\n","    for i in range(int(df.shape[0] // (segment_length / (df.shape[1] - 1)))):\n","        n_rows = int(segment_length / (df.shape[1] - 1))\n","        tmp = np.array([])\n","        for j in range(n_rows):\n","            tmp = np.append(tmp, df.iloc[idx, :-1])\n","            label = df.iloc[idx,-1]\n","            idx += 1\n","        dic[idxd] = {\n","            'signal': tmp,\n","            'label': label\n","        }\n","        idxd += 1\n","    df_tmp = pd.DataFrame.from_dict(dic,orient='index')\n","    df_output = pd.concat(\n","                [pd.DataFrame(np.vstack(df_tmp[\"signal\"])),\n","                 df_tmp[['label']]\n","                ], \n","                axis=1 )\n","    return df_output"],"metadata":{"id":"zhWzrVzwqb7K","executionInfo":{"status":"ok","timestamp":1640154335079,"user_tz":-180,"elapsed":6,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["# %%time\n","# wk = append_signal(df, 1600)\n","# wk"],"metadata":{"id":"ym6d1KtSqgNc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %%time\n","# wk.to_csv('gearbox_1600.csv')"],"metadata":{"id":"hKcFZKusqyI4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","# Data science libraries\n","import scipy.io\n","from scipy.io import savemat\n","from scipy import signal\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import figure\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import random\n","import re\n","from sklearn.metrics import confusion_matrix\n","\n","# Pytorch\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from torch import Tensor\n","from torch.utils.data import TensorDataset, DataLoader\n","from torch import optim\n","from torch.nn.modules.loss import CrossEntropyLoss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tnKLzakSiEYT","executionInfo":{"status":"ok","timestamp":1640154363916,"user_tz":-180,"elapsed":398,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"dcf183df-c029-4d70-eee5-19320b25be4f"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 52 µs, sys: 0 ns, total: 52 µs\n","Wall time: 56 µs\n"]}]},{"cell_type":"code","source":["%%time\n","wk = pd.read_csv('gearbox.csv')\n","wk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BKzQ3RAcpAuH","executionInfo":{"status":"ok","timestamp":1640154374942,"user_tz":-180,"elapsed":10453,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"8f199a10-9ad3-47fc-96a1-a958a319d125"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 8.63 s, sys: 960 ms, total: 9.59 s\n","Wall time: 10.5 s\n"]}]},{"cell_type":"code","source":["wk = wk.iloc[:,1:]\n","wk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"ccbh1jVTpmyO","executionInfo":{"status":"ok","timestamp":1640154375301,"user_tz":-180,"elapsed":12,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"143a03a7-e760-4923-9d27-729b988c66ac"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-4ef20de8-8b22-4b56-8e86-b1682942052c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.166990</td>\n","      <td>0.000503</td>\n","      <td>0.000496</td>\n","      <td>0.001961</td>\n","      <td>-0.009605</td>\n","      <td>-0.001930</td>\n","      <td>-0.004188</td>\n","      <td>-0.003593</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.166672</td>\n","      <td>0.002112</td>\n","      <td>0.002393</td>\n","      <td>0.003843</td>\n","      <td>-0.012335</td>\n","      <td>-0.014278</td>\n","      <td>0.003805</td>\n","      <td>-0.003625</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.168072</td>\n","      <td>0.003276</td>\n","      <td>0.001824</td>\n","      <td>0.002321</td>\n","      <td>-0.013756</td>\n","      <td>-0.010800</td>\n","      <td>0.006691</td>\n","      <td>0.001322</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.167397</td>\n","      <td>0.002187</td>\n","      <td>0.000870</td>\n","      <td>0.005610</td>\n","      <td>-0.011922</td>\n","      <td>-0.006158</td>\n","      <td>0.006317</td>\n","      <td>0.004017</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.167269</td>\n","      <td>0.000864</td>\n","      <td>0.002501</td>\n","      <td>-0.000274</td>\n","      <td>-0.007973</td>\n","      <td>-0.003726</td>\n","      <td>0.000799</td>\n","      <td>-0.003133</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10485595</th>\n","      <td>-0.096711</td>\n","      <td>0.001663</td>\n","      <td>0.009999</td>\n","      <td>0.009701</td>\n","      <td>0.010765</td>\n","      <td>-0.032554</td>\n","      <td>-0.004383</td>\n","      <td>0.030427</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>10485596</th>\n","      <td>-0.117769</td>\n","      <td>-0.003766</td>\n","      <td>-0.003173</td>\n","      <td>-0.008997</td>\n","      <td>0.008203</td>\n","      <td>-0.024344</td>\n","      <td>-0.001603</td>\n","      <td>0.023708</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>10485597</th>\n","      <td>-0.125676</td>\n","      <td>0.000100</td>\n","      <td>-0.006078</td>\n","      <td>0.007027</td>\n","      <td>-0.015857</td>\n","      <td>0.001858</td>\n","      <td>0.003486</td>\n","      <td>-0.038427</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>10485598</th>\n","      <td>-0.132912</td>\n","      <td>-0.008304</td>\n","      <td>0.009670</td>\n","      <td>0.005668</td>\n","      <td>-0.034431</td>\n","      <td>-0.006635</td>\n","      <td>0.024041</td>\n","      <td>-0.018816</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>10485599</th>\n","      <td>-0.124121</td>\n","      <td>-0.003865</td>\n","      <td>0.009844</td>\n","      <td>0.001152</td>\n","      <td>-0.021900</td>\n","      <td>0.007768</td>\n","      <td>-0.002160</td>\n","      <td>0.006992</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10485600 rows × 9 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ef20de8-8b22-4b56-8e86-b1682942052c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4ef20de8-8b22-4b56-8e86-b1682942052c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4ef20de8-8b22-4b56-8e86-b1682942052c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 0         1         2  ...         6         7  label\n","0        -0.166990  0.000503  0.000496  ... -0.004188 -0.003593      1\n","1        -0.166672  0.002112  0.002393  ...  0.003805 -0.003625      1\n","2        -0.168072  0.003276  0.001824  ...  0.006691  0.001322      1\n","3        -0.167397  0.002187  0.000870  ...  0.006317  0.004017      1\n","4        -0.167269  0.000864  0.002501  ...  0.000799 -0.003133      1\n","...            ...       ...       ...  ...       ...       ...    ...\n","10485595 -0.096711  0.001663  0.009999  ... -0.004383  0.030427      4\n","10485596 -0.117769 -0.003766 -0.003173  ... -0.001603  0.023708      4\n","10485597 -0.125676  0.000100 -0.006078  ...  0.003486 -0.038427      4\n","10485598 -0.132912 -0.008304  0.009670  ...  0.024041 -0.018816      4\n","10485599 -0.124121 -0.003865  0.009844  ... -0.002160  0.006992      4\n","\n","[10485600 rows x 9 columns]"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["n_rows = 1048560"],"metadata":{"id":"vFxkn-3QrDwk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","d = {}\n","for i in range(10):\n","    d['a{0}'.format(i)] = wk.iloc[i*n_rows:(i+1)*n_rows]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ciwJ0dMTseG3","executionInfo":{"status":"ok","timestamp":1640154418289,"user_tz":-180,"elapsed":329,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"9b83a190-2d66-4976-828b-a4426b20a09d"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 873 µs, sys: 0 ns, total: 873 µs\n","Wall time: 882 µs\n"]}]},{"cell_type":"code","source":["%%time\n","dd = {}\n","for i in range(10):\n","    dd['a{}'.format(i)] = append_signal(d['a{}'.format(i)], 1600)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ZhjPGw-vQFT","executionInfo":{"status":"ok","timestamp":1640158839051,"user_tz":-180,"elapsed":4341810,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"0f1923f7-c9aa-4c2a-84ca-84a64596b867"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 1h 12min 7s, sys: 5min 46s, total: 1h 17min 53s\n","Wall time: 1h 12min 21s\n"]}]},{"cell_type":"code","source":["wkwkwk = pd.DataFrame([])\n","for i in dd:\n","    wkwkwk = pd.concat([wkwkwk,dd[i]], axis=0)"],"metadata":{"id":"_l-1x0azDhyv","executionInfo":{"status":"ok","timestamp":1640159003908,"user_tz":-180,"elapsed":3116,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["%%time\n","wkwkwk.to_csv('gearbox_1600_ok.csv')"],"metadata":{"id":"UXTZStVXGFDm","executionInfo":{"status":"ok","timestamp":1640159198717,"user_tz":-180,"elapsed":141600,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["wkwkwk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"fV7Tm8FvHsS7","executionInfo":{"status":"ok","timestamp":1640159433553,"user_tz":-180,"elapsed":912,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"5f254e7a-7dc4-418f-d53d-015d2c76f5aa"},"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-de725b47-67a3-4bf9-b3b2-43fa59d6a87e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>...</th>\n","      <th>1561</th>\n","      <th>1562</th>\n","      <th>1563</th>\n","      <th>1564</th>\n","      <th>1565</th>\n","      <th>1566</th>\n","      <th>1567</th>\n","      <th>1568</th>\n","      <th>1569</th>\n","      <th>1570</th>\n","      <th>1571</th>\n","      <th>1572</th>\n","      <th>1573</th>\n","      <th>1574</th>\n","      <th>1575</th>\n","      <th>1576</th>\n","      <th>1577</th>\n","      <th>1578</th>\n","      <th>1579</th>\n","      <th>1580</th>\n","      <th>1581</th>\n","      <th>1582</th>\n","      <th>1583</th>\n","      <th>1584</th>\n","      <th>1585</th>\n","      <th>1586</th>\n","      <th>1587</th>\n","      <th>1588</th>\n","      <th>1589</th>\n","      <th>1590</th>\n","      <th>1591</th>\n","      <th>1592</th>\n","      <th>1593</th>\n","      <th>1594</th>\n","      <th>1595</th>\n","      <th>1596</th>\n","      <th>1597</th>\n","      <th>1598</th>\n","      <th>1599</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.166990</td>\n","      <td>0.000503</td>\n","      <td>0.000496</td>\n","      <td>0.001961</td>\n","      <td>-0.009605</td>\n","      <td>-0.001930</td>\n","      <td>-0.004188</td>\n","      <td>-0.003593</td>\n","      <td>-0.166672</td>\n","      <td>0.002112</td>\n","      <td>0.002393</td>\n","      <td>0.003843</td>\n","      <td>-0.012335</td>\n","      <td>-0.014278</td>\n","      <td>0.003805</td>\n","      <td>-0.003625</td>\n","      <td>-0.168072</td>\n","      <td>0.003276</td>\n","      <td>0.001824</td>\n","      <td>0.002321</td>\n","      <td>-0.013756</td>\n","      <td>-0.010800</td>\n","      <td>0.006691</td>\n","      <td>0.001322</td>\n","      <td>-0.167397</td>\n","      <td>0.002187</td>\n","      <td>0.000870</td>\n","      <td>0.005610</td>\n","      <td>-0.011922</td>\n","      <td>-0.006158</td>\n","      <td>0.006317</td>\n","      <td>0.004017</td>\n","      <td>-0.167269</td>\n","      <td>0.000864</td>\n","      <td>0.002501</td>\n","      <td>-0.000274</td>\n","      <td>-0.007973</td>\n","      <td>-0.003726</td>\n","      <td>0.000799</td>\n","      <td>-0.003133</td>\n","      <td>...</td>\n","      <td>0.004307</td>\n","      <td>-0.001523</td>\n","      <td>-0.001957</td>\n","      <td>0.007362</td>\n","      <td>-0.005063</td>\n","      <td>0.004883</td>\n","      <td>0.001014</td>\n","      <td>-0.165890</td>\n","      <td>0.003058</td>\n","      <td>0.000736</td>\n","      <td>0.003064</td>\n","      <td>0.007229</td>\n","      <td>-0.003247</td>\n","      <td>-0.000913</td>\n","      <td>0.001471</td>\n","      <td>-0.164526</td>\n","      <td>0.000125</td>\n","      <td>0.000404</td>\n","      <td>0.003482</td>\n","      <td>0.005091</td>\n","      <td>-0.000756</td>\n","      <td>-0.000482</td>\n","      <td>0.002694</td>\n","      <td>-0.167673</td>\n","      <td>-0.001067</td>\n","      <td>-0.000404</td>\n","      <td>-0.002841</td>\n","      <td>0.002593</td>\n","      <td>-0.002176</td>\n","      <td>-0.002798</td>\n","      <td>-0.003427</td>\n","      <td>-0.169846</td>\n","      <td>0.002413</td>\n","      <td>0.001577</td>\n","      <td>0.002810</td>\n","      <td>0.001550</td>\n","      <td>0.003215</td>\n","      <td>-0.006516</td>\n","      <td>-0.006297</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.170202</td>\n","      <td>-0.001537</td>\n","      <td>-0.000634</td>\n","      <td>0.002918</td>\n","      <td>0.003067</td>\n","      <td>-0.002054</td>\n","      <td>0.002491</td>\n","      <td>-0.001354</td>\n","      <td>-0.166199</td>\n","      <td>0.000958</td>\n","      <td>0.002571</td>\n","      <td>-0.003273</td>\n","      <td>0.002879</td>\n","      <td>-0.002738</td>\n","      <td>-0.001800</td>\n","      <td>0.004760</td>\n","      <td>-0.164349</td>\n","      <td>0.003797</td>\n","      <td>-0.002583</td>\n","      <td>0.004766</td>\n","      <td>-0.000319</td>\n","      <td>-0.005027</td>\n","      <td>-0.001099</td>\n","      <td>0.005931</td>\n","      <td>-0.162462</td>\n","      <td>0.000569</td>\n","      <td>0.003959</td>\n","      <td>0.004450</td>\n","      <td>-0.002919</td>\n","      <td>-0.008571</td>\n","      <td>0.004872</td>\n","      <td>0.002028</td>\n","      <td>-0.161756</td>\n","      <td>0.003053</td>\n","      <td>-0.004883</td>\n","      <td>-0.002912</td>\n","      <td>-0.000938</td>\n","      <td>-0.005434</td>\n","      <td>0.002531</td>\n","      <td>-0.002586</td>\n","      <td>...</td>\n","      <td>-0.003651</td>\n","      <td>-0.001613</td>\n","      <td>-0.008396</td>\n","      <td>0.009636</td>\n","      <td>0.003273</td>\n","      <td>-0.008202</td>\n","      <td>-0.023249</td>\n","      <td>-0.170549</td>\n","      <td>0.003635</td>\n","      <td>0.003405</td>\n","      <td>0.005028</td>\n","      <td>0.005492</td>\n","      <td>-0.003413</td>\n","      <td>0.001488</td>\n","      <td>0.001037</td>\n","      <td>-0.171037</td>\n","      <td>-0.000347</td>\n","      <td>0.001673</td>\n","      <td>0.000311</td>\n","      <td>0.011348</td>\n","      <td>-0.017080</td>\n","      <td>0.009515</td>\n","      <td>0.024073</td>\n","      <td>-0.169072</td>\n","      <td>0.003345</td>\n","      <td>-0.004230</td>\n","      <td>-0.000901</td>\n","      <td>0.019561</td>\n","      <td>-0.017601</td>\n","      <td>0.010616</td>\n","      <td>0.024786</td>\n","      <td>-0.163680</td>\n","      <td>0.005854</td>\n","      <td>-0.004432</td>\n","      <td>0.009999</td>\n","      <td>0.021507</td>\n","      <td>-0.018655</td>\n","      <td>0.011145</td>\n","      <td>-0.001709</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.165242</td>\n","      <td>0.001490</td>\n","      <td>-0.000380</td>\n","      <td>-0.000206</td>\n","      <td>0.014886</td>\n","      <td>-0.004308</td>\n","      <td>0.004696</td>\n","      <td>-0.017110</td>\n","      <td>-0.169846</td>\n","      <td>-0.001564</td>\n","      <td>-0.006975</td>\n","      <td>-0.006545</td>\n","      <td>0.007240</td>\n","      <td>0.013074</td>\n","      <td>-0.001839</td>\n","      <td>-0.008441</td>\n","      <td>-0.171285</td>\n","      <td>-0.001146</td>\n","      <td>0.008605</td>\n","      <td>-0.000291</td>\n","      <td>0.006317</td>\n","      <td>0.011560</td>\n","      <td>-0.012691</td>\n","      <td>0.000072</td>\n","      <td>-0.176054</td>\n","      <td>-0.001051</td>\n","      <td>-0.000072</td>\n","      <td>-0.005729</td>\n","      <td>0.010992</td>\n","      <td>0.003281</td>\n","      <td>-0.016693</td>\n","      <td>0.005032</td>\n","      <td>-0.177592</td>\n","      <td>-0.000731</td>\n","      <td>-0.001913</td>\n","      <td>-0.000349</td>\n","      <td>0.012566</td>\n","      <td>-0.000895</td>\n","      <td>-0.002148</td>\n","      <td>0.010576</td>\n","      <td>...</td>\n","      <td>-0.000643</td>\n","      <td>-0.001874</td>\n","      <td>0.002393</td>\n","      <td>-0.001413</td>\n","      <td>-0.010589</td>\n","      <td>0.002376</td>\n","      <td>0.000849</td>\n","      <td>-0.163919</td>\n","      <td>0.001248</td>\n","      <td>0.002267</td>\n","      <td>0.001622</td>\n","      <td>-0.003375</td>\n","      <td>-0.005691</td>\n","      <td>-0.000209</td>\n","      <td>-0.000100</td>\n","      <td>-0.165908</td>\n","      <td>-0.000538</td>\n","      <td>-0.002232</td>\n","      <td>0.005848</td>\n","      <td>-0.004001</td>\n","      <td>-0.005914</td>\n","      <td>0.004137</td>\n","      <td>0.000352</td>\n","      <td>-0.162795</td>\n","      <td>-0.003035</td>\n","      <td>0.002514</td>\n","      <td>-0.000581</td>\n","      <td>-0.002531</td>\n","      <td>-0.006424</td>\n","      <td>0.000945</td>\n","      <td>-0.002036</td>\n","      <td>-0.163901</td>\n","      <td>0.002298</td>\n","      <td>-0.000696</td>\n","      <td>0.002671</td>\n","      <td>0.001211</td>\n","      <td>-0.008192</td>\n","      <td>-0.005305</td>\n","      <td>0.002571</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.163976</td>\n","      <td>-0.002890</td>\n","      <td>0.003787</td>\n","      <td>0.004954</td>\n","      <td>0.001082</td>\n","      <td>-0.012310</td>\n","      <td>0.000126</td>\n","      <td>-0.001671</td>\n","      <td>-0.164812</td>\n","      <td>-0.002314</td>\n","      <td>0.001326</td>\n","      <td>0.002117</td>\n","      <td>-0.002290</td>\n","      <td>-0.004389</td>\n","      <td>0.003270</td>\n","      <td>-0.000780</td>\n","      <td>-0.163821</td>\n","      <td>-0.001932</td>\n","      <td>0.000757</td>\n","      <td>0.002918</td>\n","      <td>-0.003462</td>\n","      <td>-0.008807</td>\n","      <td>0.003046</td>\n","      <td>-0.009866</td>\n","      <td>-0.163902</td>\n","      <td>-0.000594</td>\n","      <td>0.006145</td>\n","      <td>0.005692</td>\n","      <td>-0.002066</td>\n","      <td>-0.001539</td>\n","      <td>-0.002145</td>\n","      <td>0.007930</td>\n","      <td>-0.166689</td>\n","      <td>-0.004939</td>\n","      <td>-0.003031</td>\n","      <td>-0.000076</td>\n","      <td>0.000179</td>\n","      <td>-0.013505</td>\n","      <td>-0.000051</td>\n","      <td>0.010740</td>\n","      <td>...</td>\n","      <td>0.001125</td>\n","      <td>0.002686</td>\n","      <td>0.002505</td>\n","      <td>-0.002775</td>\n","      <td>-0.005242</td>\n","      <td>-0.002292</td>\n","      <td>-0.003917</td>\n","      <td>-0.161980</td>\n","      <td>0.001100</td>\n","      <td>0.000757</td>\n","      <td>0.000099</td>\n","      <td>0.000557</td>\n","      <td>-0.008148</td>\n","      <td>0.003172</td>\n","      <td>-0.000528</td>\n","      <td>-0.161796</td>\n","      <td>0.002252</td>\n","      <td>-0.000031</td>\n","      <td>0.002178</td>\n","      <td>0.004033</td>\n","      <td>-0.006913</td>\n","      <td>0.004784</td>\n","      <td>0.003306</td>\n","      <td>-0.161905</td>\n","      <td>0.003142</td>\n","      <td>0.000439</td>\n","      <td>0.003204</td>\n","      <td>0.002233</td>\n","      <td>-0.007201</td>\n","      <td>0.002412</td>\n","      <td>0.001061</td>\n","      <td>-0.159950</td>\n","      <td>0.001544</td>\n","      <td>-0.000863</td>\n","      <td>0.001243</td>\n","      <td>-0.000932</td>\n","      <td>-0.008265</td>\n","      <td>0.001221</td>\n","      <td>-0.002913</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.163335</td>\n","      <td>0.000869</td>\n","      <td>0.001174</td>\n","      <td>0.001355</td>\n","      <td>-0.000247</td>\n","      <td>-0.005565</td>\n","      <td>0.000800</td>\n","      <td>-0.002047</td>\n","      <td>-0.167812</td>\n","      <td>0.000722</td>\n","      <td>0.003012</td>\n","      <td>0.002608</td>\n","      <td>0.002528</td>\n","      <td>-0.003624</td>\n","      <td>-0.001645</td>\n","      <td>-0.001940</td>\n","      <td>-0.168452</td>\n","      <td>-0.000055</td>\n","      <td>0.002776</td>\n","      <td>0.001010</td>\n","      <td>0.005159</td>\n","      <td>-0.003967</td>\n","      <td>-0.003005</td>\n","      <td>-0.002587</td>\n","      <td>-0.167682</td>\n","      <td>-0.000373</td>\n","      <td>0.000736</td>\n","      <td>0.000366</td>\n","      <td>0.002997</td>\n","      <td>-0.004957</td>\n","      <td>-0.000761</td>\n","      <td>-0.002685</td>\n","      <td>-0.168107</td>\n","      <td>0.000368</td>\n","      <td>0.001886</td>\n","      <td>0.002167</td>\n","      <td>-0.001191</td>\n","      <td>-0.004203</td>\n","      <td>-0.000837</td>\n","      <td>-0.001478</td>\n","      <td>...</td>\n","      <td>0.002248</td>\n","      <td>-0.000013</td>\n","      <td>0.000883</td>\n","      <td>-0.002767</td>\n","      <td>-0.002525</td>\n","      <td>-0.001495</td>\n","      <td>-0.001562</td>\n","      <td>-0.163399</td>\n","      <td>0.002618</td>\n","      <td>0.000755</td>\n","      <td>-0.001831</td>\n","      <td>-0.004503</td>\n","      <td>-0.001419</td>\n","      <td>0.001009</td>\n","      <td>-0.000643</td>\n","      <td>-0.164305</td>\n","      <td>0.003215</td>\n","      <td>-0.000761</td>\n","      <td>-0.000325</td>\n","      <td>-0.006503</td>\n","      <td>-0.002184</td>\n","      <td>0.001949</td>\n","      <td>0.001019</td>\n","      <td>-0.162226</td>\n","      <td>0.002760</td>\n","      <td>0.000809</td>\n","      <td>0.001169</td>\n","      <td>-0.008526</td>\n","      <td>-0.004214</td>\n","      <td>0.000696</td>\n","      <td>0.000750</td>\n","      <td>-0.165586</td>\n","      <td>0.002841</td>\n","      <td>-0.001216</td>\n","      <td>0.000011</td>\n","      <td>-0.009128</td>\n","      <td>-0.005542</td>\n","      <td>0.001464</td>\n","      <td>-0.000352</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5237</th>\n","      <td>-0.123323</td>\n","      <td>0.011708</td>\n","      <td>-0.015872</td>\n","      <td>0.001893</td>\n","      <td>-0.007921</td>\n","      <td>-0.003909</td>\n","      <td>0.010664</td>\n","      <td>0.009093</td>\n","      <td>-0.132368</td>\n","      <td>0.004723</td>\n","      <td>0.020796</td>\n","      <td>0.012687</td>\n","      <td>-0.010886</td>\n","      <td>0.001478</td>\n","      <td>-0.009769</td>\n","      <td>0.023251</td>\n","      <td>-0.128945</td>\n","      <td>-0.001625</td>\n","      <td>-0.019217</td>\n","      <td>-0.012099</td>\n","      <td>-0.004849</td>\n","      <td>-0.006250</td>\n","      <td>-0.009011</td>\n","      <td>0.014378</td>\n","      <td>-0.124457</td>\n","      <td>0.007862</td>\n","      <td>-0.008469</td>\n","      <td>-0.001162</td>\n","      <td>0.003949</td>\n","      <td>-0.001677</td>\n","      <td>0.014390</td>\n","      <td>-0.008121</td>\n","      <td>-0.116724</td>\n","      <td>0.003275</td>\n","      <td>0.008706</td>\n","      <td>0.022851</td>\n","      <td>0.004543</td>\n","      <td>0.017937</td>\n","      <td>0.009708</td>\n","      <td>-0.008054</td>\n","      <td>...</td>\n","      <td>0.006764</td>\n","      <td>0.022062</td>\n","      <td>0.002909</td>\n","      <td>-0.016687</td>\n","      <td>0.019214</td>\n","      <td>0.005341</td>\n","      <td>0.003507</td>\n","      <td>-0.129746</td>\n","      <td>-0.004392</td>\n","      <td>-0.015033</td>\n","      <td>0.003139</td>\n","      <td>-0.018780</td>\n","      <td>-0.009052</td>\n","      <td>0.001839</td>\n","      <td>0.015397</td>\n","      <td>-0.133102</td>\n","      <td>0.002617</td>\n","      <td>0.017835</td>\n","      <td>-0.006547</td>\n","      <td>-0.007957</td>\n","      <td>0.011653</td>\n","      <td>-0.009322</td>\n","      <td>0.002333</td>\n","      <td>-0.127079</td>\n","      <td>0.006088</td>\n","      <td>-0.012833</td>\n","      <td>-0.001600</td>\n","      <td>0.004891</td>\n","      <td>-0.012083</td>\n","      <td>0.004911</td>\n","      <td>0.001659</td>\n","      <td>-0.133263</td>\n","      <td>0.004846</td>\n","      <td>0.017549</td>\n","      <td>0.002103</td>\n","      <td>0.010153</td>\n","      <td>0.001917</td>\n","      <td>-0.001392</td>\n","      <td>-0.032856</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5238</th>\n","      <td>-0.125465</td>\n","      <td>0.006367</td>\n","      <td>-0.013858</td>\n","      <td>-0.008680</td>\n","      <td>0.005420</td>\n","      <td>-0.010616</td>\n","      <td>0.014960</td>\n","      <td>-0.024482</td>\n","      <td>-0.130650</td>\n","      <td>0.003232</td>\n","      <td>0.016792</td>\n","      <td>0.011851</td>\n","      <td>0.001729</td>\n","      <td>-0.000255</td>\n","      <td>0.018948</td>\n","      <td>0.023184</td>\n","      <td>-0.116044</td>\n","      <td>0.000253</td>\n","      <td>0.008533</td>\n","      <td>-0.001289</td>\n","      <td>0.008936</td>\n","      <td>-0.000657</td>\n","      <td>-0.016553</td>\n","      <td>0.019480</td>\n","      <td>-0.127385</td>\n","      <td>-0.001020</td>\n","      <td>-0.002869</td>\n","      <td>-0.007037</td>\n","      <td>0.021905</td>\n","      <td>0.003335</td>\n","      <td>-0.017681</td>\n","      <td>-0.018924</td>\n","      <td>-0.127616</td>\n","      <td>0.000035</td>\n","      <td>0.011519</td>\n","      <td>0.011230</td>\n","      <td>0.027632</td>\n","      <td>-0.001655</td>\n","      <td>0.010558</td>\n","      <td>-0.024593</td>\n","      <td>...</td>\n","      <td>0.006536</td>\n","      <td>0.006157</td>\n","      <td>0.010287</td>\n","      <td>-0.014193</td>\n","      <td>0.009534</td>\n","      <td>0.014383</td>\n","      <td>-0.019410</td>\n","      <td>-0.133595</td>\n","      <td>0.009638</td>\n","      <td>0.001721</td>\n","      <td>-0.003439</td>\n","      <td>-0.011036</td>\n","      <td>-0.005229</td>\n","      <td>-0.016099</td>\n","      <td>-0.000688</td>\n","      <td>-0.132738</td>\n","      <td>0.002047</td>\n","      <td>-0.015523</td>\n","      <td>-0.009530</td>\n","      <td>-0.014699</td>\n","      <td>-0.007111</td>\n","      <td>-0.006940</td>\n","      <td>0.005145</td>\n","      <td>-0.137995</td>\n","      <td>0.007305</td>\n","      <td>0.015550</td>\n","      <td>0.005455</td>\n","      <td>-0.019516</td>\n","      <td>-0.003713</td>\n","      <td>0.016214</td>\n","      <td>0.023596</td>\n","      <td>-0.135669</td>\n","      <td>0.004414</td>\n","      <td>-0.010172</td>\n","      <td>0.012469</td>\n","      <td>-0.017215</td>\n","      <td>0.011313</td>\n","      <td>0.003129</td>\n","      <td>0.017917</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5239</th>\n","      <td>-0.126680</td>\n","      <td>-0.006094</td>\n","      <td>-0.005281</td>\n","      <td>0.002089</td>\n","      <td>-0.007206</td>\n","      <td>0.003140</td>\n","      <td>0.005827</td>\n","      <td>-0.027418</td>\n","      <td>-0.116564</td>\n","      <td>0.004497</td>\n","      <td>-0.003703</td>\n","      <td>-0.018580</td>\n","      <td>-0.003105</td>\n","      <td>-0.007849</td>\n","      <td>-0.003117</td>\n","      <td>-0.019313</td>\n","      <td>-0.121137</td>\n","      <td>0.009036</td>\n","      <td>0.000479</td>\n","      <td>0.023649</td>\n","      <td>-0.013413</td>\n","      <td>0.007609</td>\n","      <td>-0.013983</td>\n","      <td>0.015846</td>\n","      <td>-0.120875</td>\n","      <td>-0.013617</td>\n","      <td>0.005511</td>\n","      <td>-0.006930</td>\n","      <td>-0.027863</td>\n","      <td>-0.013508</td>\n","      <td>-0.000324</td>\n","      <td>0.023350</td>\n","      <td>-0.117792</td>\n","      <td>0.006729</td>\n","      <td>-0.012074</td>\n","      <td>-0.011879</td>\n","      <td>-0.027647</td>\n","      <td>0.019387</td>\n","      <td>0.005530</td>\n","      <td>-0.000082</td>\n","      <td>...</td>\n","      <td>0.001659</td>\n","      <td>0.004628</td>\n","      <td>-0.000793</td>\n","      <td>-0.011475</td>\n","      <td>0.002480</td>\n","      <td>0.008047</td>\n","      <td>-0.006694</td>\n","      <td>-0.135045</td>\n","      <td>0.001423</td>\n","      <td>0.002755</td>\n","      <td>-0.001704</td>\n","      <td>-0.020514</td>\n","      <td>0.006250</td>\n","      <td>0.005422</td>\n","      <td>0.007528</td>\n","      <td>-0.134989</td>\n","      <td>-0.000250</td>\n","      <td>0.004244</td>\n","      <td>0.004870</td>\n","      <td>-0.018350</td>\n","      <td>0.000783</td>\n","      <td>-0.001936</td>\n","      <td>0.007327</td>\n","      <td>-0.135578</td>\n","      <td>-0.003369</td>\n","      <td>0.000552</td>\n","      <td>0.000284</td>\n","      <td>-0.005503</td>\n","      <td>0.000314</td>\n","      <td>-0.010034</td>\n","      <td>-0.005985</td>\n","      <td>-0.143790</td>\n","      <td>-0.001823</td>\n","      <td>0.000380</td>\n","      <td>-0.001668</td>\n","      <td>0.003139</td>\n","      <td>0.010061</td>\n","      <td>-0.001652</td>\n","      <td>-0.000023</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5240</th>\n","      <td>-0.148313</td>\n","      <td>-0.000515</td>\n","      <td>0.005945</td>\n","      <td>-0.001898</td>\n","      <td>-0.000783</td>\n","      <td>0.002135</td>\n","      <td>-0.005286</td>\n","      <td>-0.005913</td>\n","      <td>-0.146091</td>\n","      <td>-0.000072</td>\n","      <td>0.002592</td>\n","      <td>0.004650</td>\n","      <td>-0.010798</td>\n","      <td>-0.007319</td>\n","      <td>0.006762</td>\n","      <td>0.008088</td>\n","      <td>-0.148327</td>\n","      <td>0.000263</td>\n","      <td>-0.000606</td>\n","      <td>-0.000578</td>\n","      <td>-0.012752</td>\n","      <td>-0.005163</td>\n","      <td>-0.005981</td>\n","      <td>-0.012983</td>\n","      <td>-0.143398</td>\n","      <td>0.003505</td>\n","      <td>0.004141</td>\n","      <td>0.003288</td>\n","      <td>-0.000138</td>\n","      <td>0.001633</td>\n","      <td>0.012056</td>\n","      <td>0.004175</td>\n","      <td>-0.142252</td>\n","      <td>-0.002209</td>\n","      <td>0.002962</td>\n","      <td>0.001466</td>\n","      <td>0.018086</td>\n","      <td>-0.021645</td>\n","      <td>0.017500</td>\n","      <td>0.032362</td>\n","      <td>...</td>\n","      <td>-0.003077</td>\n","      <td>0.000372</td>\n","      <td>0.010188</td>\n","      <td>0.003706</td>\n","      <td>0.005362</td>\n","      <td>-0.005220</td>\n","      <td>0.009712</td>\n","      <td>-0.126364</td>\n","      <td>-0.006477</td>\n","      <td>-0.007253</td>\n","      <td>-0.001261</td>\n","      <td>-0.004336</td>\n","      <td>0.006614</td>\n","      <td>-0.002397</td>\n","      <td>0.014997</td>\n","      <td>-0.133551</td>\n","      <td>0.007488</td>\n","      <td>0.009965</td>\n","      <td>-0.010922</td>\n","      <td>-0.012301</td>\n","      <td>0.018197</td>\n","      <td>-0.008521</td>\n","      <td>-0.004934</td>\n","      <td>-0.119387</td>\n","      <td>0.005726</td>\n","      <td>-0.003774</td>\n","      <td>0.010407</td>\n","      <td>-0.009342</td>\n","      <td>0.003060</td>\n","      <td>0.007007</td>\n","      <td>-0.010428</td>\n","      <td>-0.126046</td>\n","      <td>0.003818</td>\n","      <td>0.000713</td>\n","      <td>-0.000852</td>\n","      <td>-0.001560</td>\n","      <td>-0.009359</td>\n","      <td>0.000068</td>\n","      <td>-0.014431</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5241</th>\n","      <td>-0.118747</td>\n","      <td>0.011520</td>\n","      <td>-0.002606</td>\n","      <td>0.000275</td>\n","      <td>-0.000464</td>\n","      <td>-0.005497</td>\n","      <td>0.017506</td>\n","      <td>0.008467</td>\n","      <td>-0.120010</td>\n","      <td>0.007113</td>\n","      <td>0.007871</td>\n","      <td>0.005637</td>\n","      <td>-0.006648</td>\n","      <td>-0.010841</td>\n","      <td>0.008557</td>\n","      <td>0.013304</td>\n","      <td>-0.127499</td>\n","      <td>0.007743</td>\n","      <td>-0.002414</td>\n","      <td>-0.003172</td>\n","      <td>-0.014318</td>\n","      <td>-0.016348</td>\n","      <td>0.003157</td>\n","      <td>-0.009480</td>\n","      <td>-0.125709</td>\n","      <td>0.001285</td>\n","      <td>-0.009747</td>\n","      <td>-0.003861</td>\n","      <td>-0.014751</td>\n","      <td>0.004300</td>\n","      <td>0.007463</td>\n","      <td>0.006914</td>\n","      <td>-0.130866</td>\n","      <td>-0.007111</td>\n","      <td>0.014089</td>\n","      <td>0.010142</td>\n","      <td>-0.007868</td>\n","      <td>0.015033</td>\n","      <td>-0.008277</td>\n","      <td>-0.023813</td>\n","      <td>...</td>\n","      <td>-0.000083</td>\n","      <td>-0.018475</td>\n","      <td>-0.003680</td>\n","      <td>-0.008442</td>\n","      <td>-0.018580</td>\n","      <td>0.009457</td>\n","      <td>-0.008656</td>\n","      <td>-0.130674</td>\n","      <td>0.004990</td>\n","      <td>0.013824</td>\n","      <td>0.006489</td>\n","      <td>-0.028290</td>\n","      <td>0.008608</td>\n","      <td>0.018499</td>\n","      <td>-0.000676</td>\n","      <td>-0.136262</td>\n","      <td>-0.000186</td>\n","      <td>0.002069</td>\n","      <td>0.003083</td>\n","      <td>-0.021950</td>\n","      <td>-0.015593</td>\n","      <td>0.009267</td>\n","      <td>0.005407</td>\n","      <td>-0.137558</td>\n","      <td>-0.002226</td>\n","      <td>-0.006416</td>\n","      <td>-0.001993</td>\n","      <td>0.003753</td>\n","      <td>-0.003983</td>\n","      <td>-0.014695</td>\n","      <td>0.006082</td>\n","      <td>-0.145794</td>\n","      <td>-0.000457</td>\n","      <td>0.001986</td>\n","      <td>0.010800</td>\n","      <td>0.017456</td>\n","      <td>0.010865</td>\n","      <td>-0.001975</td>\n","      <td>-0.005641</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>52420 rows × 1601 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de725b47-67a3-4bf9-b3b2-43fa59d6a87e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-de725b47-67a3-4bf9-b3b2-43fa59d6a87e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-de725b47-67a3-4bf9-b3b2-43fa59d6a87e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["             0         1         2  ...      1598      1599  label\n","0    -0.166990  0.000503  0.000496  ... -0.006516 -0.006297      1\n","1    -0.170202 -0.001537 -0.000634  ...  0.011145 -0.001709      1\n","2    -0.165242  0.001490 -0.000380  ... -0.005305  0.002571      1\n","3    -0.163976 -0.002890  0.003787  ...  0.001221 -0.002913      1\n","4    -0.163335  0.000869  0.001174  ...  0.001464 -0.000352      1\n","...        ...       ...       ...  ...       ...       ...    ...\n","5237 -0.123323  0.011708 -0.015872  ... -0.001392 -0.032856      4\n","5238 -0.125465  0.006367 -0.013858  ...  0.003129  0.017917      4\n","5239 -0.126680 -0.006094 -0.005281  ... -0.001652 -0.000023      4\n","5240 -0.148313 -0.000515  0.005945  ...  0.000068 -0.014431      4\n","5241 -0.118747  0.011520 -0.002606  ... -0.001975 -0.005641      4\n","\n","[52420 rows x 1601 columns]"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["%%time\n","df = pd.read_csv('gearbox_1600.csv')"],"metadata":{"id":"3PVkIB4JxPUh","executionInfo":{"status":"ok","timestamp":1640159347216,"user_tz":-180,"elapsed":26114,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4fbfffe4-d564-4439-92de-717692fd5f13"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 22.2 s, sys: 1.69 s, total: 23.9 s\n","Wall time: 26 s\n"]}]},{"cell_type":"code","source":["df = df.iloc[:,1:]\n","df"],"metadata":{"id":"3z4ZK5tMcYrV","executionInfo":{"status":"ok","timestamp":1640159348667,"user_tz":-180,"elapsed":995,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"17afc2d1-c168-4082-80ee-b950a148c988","colab":{"base_uri":"https://localhost:8080/","height":488}},"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-f2c39f06-1c7c-4981-9efd-9e9da91f41d3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>...</th>\n","      <th>1561</th>\n","      <th>1562</th>\n","      <th>1563</th>\n","      <th>1564</th>\n","      <th>1565</th>\n","      <th>1566</th>\n","      <th>1567</th>\n","      <th>1568</th>\n","      <th>1569</th>\n","      <th>1570</th>\n","      <th>1571</th>\n","      <th>1572</th>\n","      <th>1573</th>\n","      <th>1574</th>\n","      <th>1575</th>\n","      <th>1576</th>\n","      <th>1577</th>\n","      <th>1578</th>\n","      <th>1579</th>\n","      <th>1580</th>\n","      <th>1581</th>\n","      <th>1582</th>\n","      <th>1583</th>\n","      <th>1584</th>\n","      <th>1585</th>\n","      <th>1586</th>\n","      <th>1587</th>\n","      <th>1588</th>\n","      <th>1589</th>\n","      <th>1590</th>\n","      <th>1591</th>\n","      <th>1592</th>\n","      <th>1593</th>\n","      <th>1594</th>\n","      <th>1595</th>\n","      <th>1596</th>\n","      <th>1597</th>\n","      <th>1598</th>\n","      <th>1599</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.166990</td>\n","      <td>0.000503</td>\n","      <td>0.000496</td>\n","      <td>0.001961</td>\n","      <td>-0.009605</td>\n","      <td>-0.001930</td>\n","      <td>-0.004188</td>\n","      <td>-0.003593</td>\n","      <td>-0.166672</td>\n","      <td>0.002112</td>\n","      <td>0.002393</td>\n","      <td>0.003843</td>\n","      <td>-0.012335</td>\n","      <td>-0.014278</td>\n","      <td>0.003805</td>\n","      <td>-0.003625</td>\n","      <td>-0.168072</td>\n","      <td>0.003276</td>\n","      <td>0.001824</td>\n","      <td>0.002321</td>\n","      <td>-0.013756</td>\n","      <td>-0.010800</td>\n","      <td>0.006691</td>\n","      <td>0.001322</td>\n","      <td>-0.167397</td>\n","      <td>0.002187</td>\n","      <td>0.000870</td>\n","      <td>0.005610</td>\n","      <td>-0.011922</td>\n","      <td>-0.006158</td>\n","      <td>0.006317</td>\n","      <td>0.004017</td>\n","      <td>-0.167269</td>\n","      <td>0.000864</td>\n","      <td>0.002501</td>\n","      <td>-0.000274</td>\n","      <td>-0.007973</td>\n","      <td>-0.003726</td>\n","      <td>0.000799</td>\n","      <td>-0.003133</td>\n","      <td>...</td>\n","      <td>0.004307</td>\n","      <td>-0.001523</td>\n","      <td>-0.001957</td>\n","      <td>0.007362</td>\n","      <td>-0.005063</td>\n","      <td>0.004883</td>\n","      <td>0.001014</td>\n","      <td>-0.165890</td>\n","      <td>0.003058</td>\n","      <td>0.000736</td>\n","      <td>0.003064</td>\n","      <td>0.007229</td>\n","      <td>-0.003247</td>\n","      <td>-0.000913</td>\n","      <td>0.001471</td>\n","      <td>-0.164526</td>\n","      <td>0.000125</td>\n","      <td>0.000404</td>\n","      <td>0.003482</td>\n","      <td>0.005091</td>\n","      <td>-0.000756</td>\n","      <td>-0.000482</td>\n","      <td>0.002694</td>\n","      <td>-0.167673</td>\n","      <td>-0.001067</td>\n","      <td>-0.000404</td>\n","      <td>-0.002841</td>\n","      <td>0.002593</td>\n","      <td>-0.002176</td>\n","      <td>-0.002798</td>\n","      <td>-0.003427</td>\n","      <td>-0.169846</td>\n","      <td>0.002413</td>\n","      <td>0.001577</td>\n","      <td>0.002810</td>\n","      <td>0.001550</td>\n","      <td>0.003215</td>\n","      <td>-0.006516</td>\n","      <td>-0.006297</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.170202</td>\n","      <td>-0.001537</td>\n","      <td>-0.000634</td>\n","      <td>0.002918</td>\n","      <td>0.003067</td>\n","      <td>-0.002054</td>\n","      <td>0.002491</td>\n","      <td>-0.001354</td>\n","      <td>-0.166199</td>\n","      <td>0.000958</td>\n","      <td>0.002571</td>\n","      <td>-0.003273</td>\n","      <td>0.002879</td>\n","      <td>-0.002738</td>\n","      <td>-0.001800</td>\n","      <td>0.004760</td>\n","      <td>-0.164349</td>\n","      <td>0.003797</td>\n","      <td>-0.002583</td>\n","      <td>0.004766</td>\n","      <td>-0.000319</td>\n","      <td>-0.005027</td>\n","      <td>-0.001099</td>\n","      <td>0.005931</td>\n","      <td>-0.162462</td>\n","      <td>0.000569</td>\n","      <td>0.003959</td>\n","      <td>0.004450</td>\n","      <td>-0.002919</td>\n","      <td>-0.008571</td>\n","      <td>0.004872</td>\n","      <td>0.002028</td>\n","      <td>-0.161756</td>\n","      <td>0.003053</td>\n","      <td>-0.004883</td>\n","      <td>-0.002912</td>\n","      <td>-0.000938</td>\n","      <td>-0.005434</td>\n","      <td>0.002531</td>\n","      <td>-0.002586</td>\n","      <td>...</td>\n","      <td>-0.003651</td>\n","      <td>-0.001613</td>\n","      <td>-0.008396</td>\n","      <td>0.009636</td>\n","      <td>0.003273</td>\n","      <td>-0.008202</td>\n","      <td>-0.023249</td>\n","      <td>-0.170549</td>\n","      <td>0.003635</td>\n","      <td>0.003405</td>\n","      <td>0.005028</td>\n","      <td>0.005492</td>\n","      <td>-0.003413</td>\n","      <td>0.001488</td>\n","      <td>0.001037</td>\n","      <td>-0.171037</td>\n","      <td>-0.000347</td>\n","      <td>0.001673</td>\n","      <td>0.000311</td>\n","      <td>0.011348</td>\n","      <td>-0.017080</td>\n","      <td>0.009515</td>\n","      <td>0.024073</td>\n","      <td>-0.169072</td>\n","      <td>0.003345</td>\n","      <td>-0.004230</td>\n","      <td>-0.000901</td>\n","      <td>0.019561</td>\n","      <td>-0.017601</td>\n","      <td>0.010616</td>\n","      <td>0.024786</td>\n","      <td>-0.163680</td>\n","      <td>0.005854</td>\n","      <td>-0.004432</td>\n","      <td>0.009999</td>\n","      <td>0.021507</td>\n","      <td>-0.018655</td>\n","      <td>0.011145</td>\n","      <td>-0.001709</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.165242</td>\n","      <td>0.001490</td>\n","      <td>-0.000380</td>\n","      <td>-0.000206</td>\n","      <td>0.014886</td>\n","      <td>-0.004308</td>\n","      <td>0.004696</td>\n","      <td>-0.017110</td>\n","      <td>-0.169846</td>\n","      <td>-0.001564</td>\n","      <td>-0.006975</td>\n","      <td>-0.006545</td>\n","      <td>0.007240</td>\n","      <td>0.013074</td>\n","      <td>-0.001839</td>\n","      <td>-0.008441</td>\n","      <td>-0.171285</td>\n","      <td>-0.001146</td>\n","      <td>0.008605</td>\n","      <td>-0.000291</td>\n","      <td>0.006317</td>\n","      <td>0.011560</td>\n","      <td>-0.012691</td>\n","      <td>0.000072</td>\n","      <td>-0.176054</td>\n","      <td>-0.001051</td>\n","      <td>-0.000072</td>\n","      <td>-0.005729</td>\n","      <td>0.010992</td>\n","      <td>0.003281</td>\n","      <td>-0.016693</td>\n","      <td>0.005032</td>\n","      <td>-0.177592</td>\n","      <td>-0.000731</td>\n","      <td>-0.001913</td>\n","      <td>-0.000349</td>\n","      <td>0.012566</td>\n","      <td>-0.000895</td>\n","      <td>-0.002148</td>\n","      <td>0.010576</td>\n","      <td>...</td>\n","      <td>-0.000643</td>\n","      <td>-0.001874</td>\n","      <td>0.002393</td>\n","      <td>-0.001413</td>\n","      <td>-0.010589</td>\n","      <td>0.002376</td>\n","      <td>0.000849</td>\n","      <td>-0.163919</td>\n","      <td>0.001248</td>\n","      <td>0.002267</td>\n","      <td>0.001622</td>\n","      <td>-0.003375</td>\n","      <td>-0.005691</td>\n","      <td>-0.000209</td>\n","      <td>-0.000100</td>\n","      <td>-0.165908</td>\n","      <td>-0.000538</td>\n","      <td>-0.002232</td>\n","      <td>0.005848</td>\n","      <td>-0.004001</td>\n","      <td>-0.005914</td>\n","      <td>0.004137</td>\n","      <td>0.000352</td>\n","      <td>-0.162795</td>\n","      <td>-0.003035</td>\n","      <td>0.002514</td>\n","      <td>-0.000581</td>\n","      <td>-0.002531</td>\n","      <td>-0.006424</td>\n","      <td>0.000945</td>\n","      <td>-0.002036</td>\n","      <td>-0.163901</td>\n","      <td>0.002298</td>\n","      <td>-0.000696</td>\n","      <td>0.002671</td>\n","      <td>0.001211</td>\n","      <td>-0.008192</td>\n","      <td>-0.005305</td>\n","      <td>0.002571</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.163976</td>\n","      <td>-0.002890</td>\n","      <td>0.003787</td>\n","      <td>0.004954</td>\n","      <td>0.001082</td>\n","      <td>-0.012310</td>\n","      <td>0.000126</td>\n","      <td>-0.001671</td>\n","      <td>-0.164812</td>\n","      <td>-0.002314</td>\n","      <td>0.001326</td>\n","      <td>0.002117</td>\n","      <td>-0.002290</td>\n","      <td>-0.004389</td>\n","      <td>0.003270</td>\n","      <td>-0.000780</td>\n","      <td>-0.163821</td>\n","      <td>-0.001932</td>\n","      <td>0.000757</td>\n","      <td>0.002918</td>\n","      <td>-0.003462</td>\n","      <td>-0.008807</td>\n","      <td>0.003046</td>\n","      <td>-0.009866</td>\n","      <td>-0.163902</td>\n","      <td>-0.000594</td>\n","      <td>0.006145</td>\n","      <td>0.005692</td>\n","      <td>-0.002066</td>\n","      <td>-0.001539</td>\n","      <td>-0.002145</td>\n","      <td>0.007930</td>\n","      <td>-0.166689</td>\n","      <td>-0.004939</td>\n","      <td>-0.003031</td>\n","      <td>-0.000076</td>\n","      <td>0.000179</td>\n","      <td>-0.013505</td>\n","      <td>-0.000051</td>\n","      <td>0.010740</td>\n","      <td>...</td>\n","      <td>0.001125</td>\n","      <td>0.002686</td>\n","      <td>0.002505</td>\n","      <td>-0.002775</td>\n","      <td>-0.005242</td>\n","      <td>-0.002292</td>\n","      <td>-0.003917</td>\n","      <td>-0.161980</td>\n","      <td>0.001100</td>\n","      <td>0.000757</td>\n","      <td>0.000099</td>\n","      <td>0.000557</td>\n","      <td>-0.008148</td>\n","      <td>0.003172</td>\n","      <td>-0.000528</td>\n","      <td>-0.161796</td>\n","      <td>0.002252</td>\n","      <td>-0.000031</td>\n","      <td>0.002178</td>\n","      <td>0.004033</td>\n","      <td>-0.006913</td>\n","      <td>0.004784</td>\n","      <td>0.003306</td>\n","      <td>-0.161905</td>\n","      <td>0.003142</td>\n","      <td>0.000439</td>\n","      <td>0.003204</td>\n","      <td>0.002233</td>\n","      <td>-0.007201</td>\n","      <td>0.002412</td>\n","      <td>0.001061</td>\n","      <td>-0.159950</td>\n","      <td>0.001544</td>\n","      <td>-0.000863</td>\n","      <td>0.001243</td>\n","      <td>-0.000932</td>\n","      <td>-0.008265</td>\n","      <td>0.001221</td>\n","      <td>-0.002913</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.163335</td>\n","      <td>0.000869</td>\n","      <td>0.001174</td>\n","      <td>0.001355</td>\n","      <td>-0.000247</td>\n","      <td>-0.005565</td>\n","      <td>0.000800</td>\n","      <td>-0.002047</td>\n","      <td>-0.167812</td>\n","      <td>0.000722</td>\n","      <td>0.003012</td>\n","      <td>0.002608</td>\n","      <td>0.002528</td>\n","      <td>-0.003624</td>\n","      <td>-0.001645</td>\n","      <td>-0.001940</td>\n","      <td>-0.168452</td>\n","      <td>-0.000055</td>\n","      <td>0.002776</td>\n","      <td>0.001010</td>\n","      <td>0.005159</td>\n","      <td>-0.003967</td>\n","      <td>-0.003005</td>\n","      <td>-0.002587</td>\n","      <td>-0.167682</td>\n","      <td>-0.000373</td>\n","      <td>0.000736</td>\n","      <td>0.000366</td>\n","      <td>0.002997</td>\n","      <td>-0.004957</td>\n","      <td>-0.000761</td>\n","      <td>-0.002685</td>\n","      <td>-0.168107</td>\n","      <td>0.000368</td>\n","      <td>0.001886</td>\n","      <td>0.002167</td>\n","      <td>-0.001191</td>\n","      <td>-0.004203</td>\n","      <td>-0.000837</td>\n","      <td>-0.001478</td>\n","      <td>...</td>\n","      <td>0.002248</td>\n","      <td>-0.000013</td>\n","      <td>0.000883</td>\n","      <td>-0.002767</td>\n","      <td>-0.002525</td>\n","      <td>-0.001495</td>\n","      <td>-0.001562</td>\n","      <td>-0.163399</td>\n","      <td>0.002618</td>\n","      <td>0.000755</td>\n","      <td>-0.001831</td>\n","      <td>-0.004503</td>\n","      <td>-0.001419</td>\n","      <td>0.001009</td>\n","      <td>-0.000643</td>\n","      <td>-0.164305</td>\n","      <td>0.003215</td>\n","      <td>-0.000761</td>\n","      <td>-0.000325</td>\n","      <td>-0.006503</td>\n","      <td>-0.002184</td>\n","      <td>0.001949</td>\n","      <td>0.001019</td>\n","      <td>-0.162226</td>\n","      <td>0.002760</td>\n","      <td>0.000809</td>\n","      <td>0.001169</td>\n","      <td>-0.008526</td>\n","      <td>-0.004214</td>\n","      <td>0.000696</td>\n","      <td>0.000750</td>\n","      <td>-0.165586</td>\n","      <td>0.002841</td>\n","      <td>-0.001216</td>\n","      <td>0.000011</td>\n","      <td>-0.009128</td>\n","      <td>-0.005542</td>\n","      <td>0.001464</td>\n","      <td>-0.000352</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>52423</th>\n","      <td>-0.133884</td>\n","      <td>-0.007319</td>\n","      <td>-0.004551</td>\n","      <td>0.013018</td>\n","      <td>-0.009048</td>\n","      <td>-0.008920</td>\n","      <td>0.025520</td>\n","      <td>0.009063</td>\n","      <td>-0.125099</td>\n","      <td>0.002398</td>\n","      <td>-0.012158</td>\n","      <td>0.002970</td>\n","      <td>0.005759</td>\n","      <td>-0.015758</td>\n","      <td>0.010376</td>\n","      <td>0.003910</td>\n","      <td>-0.125827</td>\n","      <td>-0.000345</td>\n","      <td>-0.005689</td>\n","      <td>0.007267</td>\n","      <td>0.013014</td>\n","      <td>-0.020455</td>\n","      <td>0.002749</td>\n","      <td>-0.012850</td>\n","      <td>-0.133075</td>\n","      <td>-0.005053</td>\n","      <td>0.003793</td>\n","      <td>-0.010034</td>\n","      <td>0.005614</td>\n","      <td>0.007324</td>\n","      <td>-0.018138</td>\n","      <td>0.008198</td>\n","      <td>-0.145936</td>\n","      <td>-0.004200</td>\n","      <td>-0.001205</td>\n","      <td>-0.002222</td>\n","      <td>-0.007105</td>\n","      <td>0.014406</td>\n","      <td>-0.019459</td>\n","      <td>0.006413</td>\n","      <td>...</td>\n","      <td>0.003585</td>\n","      <td>-0.007064</td>\n","      <td>-0.009247</td>\n","      <td>0.003647</td>\n","      <td>-0.012970</td>\n","      <td>-0.005640</td>\n","      <td>0.001590</td>\n","      <td>-0.123692</td>\n","      <td>0.002806</td>\n","      <td>-0.024389</td>\n","      <td>0.005999</td>\n","      <td>0.003490</td>\n","      <td>-0.003495</td>\n","      <td>0.022376</td>\n","      <td>0.006169</td>\n","      <td>-0.124871</td>\n","      <td>0.012615</td>\n","      <td>0.030969</td>\n","      <td>-0.000260</td>\n","      <td>-0.008674</td>\n","      <td>0.008056</td>\n","      <td>0.013080</td>\n","      <td>0.013970</td>\n","      <td>-0.110773</td>\n","      <td>0.001910</td>\n","      <td>-0.025624</td>\n","      <td>-0.004189</td>\n","      <td>-0.019664</td>\n","      <td>-0.016137</td>\n","      <td>0.008323</td>\n","      <td>-0.016136</td>\n","      <td>-0.115141</td>\n","      <td>0.001713</td>\n","      <td>0.004947</td>\n","      <td>0.010097</td>\n","      <td>-0.017345</td>\n","      <td>0.000744</td>\n","      <td>-0.002654</td>\n","      <td>-0.000268</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>52424</th>\n","      <td>-0.114887</td>\n","      <td>0.004121</td>\n","      <td>0.002460</td>\n","      <td>-0.009451</td>\n","      <td>-0.004926</td>\n","      <td>0.009969</td>\n","      <td>-0.008032</td>\n","      <td>0.002565</td>\n","      <td>-0.119314</td>\n","      <td>-0.003746</td>\n","      <td>0.002238</td>\n","      <td>-0.003728</td>\n","      <td>0.004107</td>\n","      <td>0.016222</td>\n","      <td>-0.013329</td>\n","      <td>-0.001526</td>\n","      <td>-0.116516</td>\n","      <td>-0.007343</td>\n","      <td>0.001680</td>\n","      <td>0.007081</td>\n","      <td>0.000490</td>\n","      <td>-0.001465</td>\n","      <td>0.000267</td>\n","      <td>-0.008368</td>\n","      <td>-0.123692</td>\n","      <td>-0.002625</td>\n","      <td>0.008317</td>\n","      <td>-0.003614</td>\n","      <td>-0.012057</td>\n","      <td>0.002532</td>\n","      <td>0.000144</td>\n","      <td>0.000246</td>\n","      <td>-0.122622</td>\n","      <td>0.002211</td>\n","      <td>-0.004033</td>\n","      <td>-0.006288</td>\n","      <td>-0.018046</td>\n","      <td>0.001113</td>\n","      <td>-0.013647</td>\n","      <td>0.001968</td>\n","      <td>...</td>\n","      <td>0.003105</td>\n","      <td>-0.003389</td>\n","      <td>-0.001321</td>\n","      <td>0.007119</td>\n","      <td>0.009278</td>\n","      <td>-0.000535</td>\n","      <td>-0.007225</td>\n","      <td>-0.139619</td>\n","      <td>0.002398</td>\n","      <td>0.011705</td>\n","      <td>0.006930</td>\n","      <td>0.010351</td>\n","      <td>0.002391</td>\n","      <td>0.004959</td>\n","      <td>0.000118</td>\n","      <td>-0.140377</td>\n","      <td>0.005000</td>\n","      <td>-0.003207</td>\n","      <td>-0.004851</td>\n","      <td>0.009700</td>\n","      <td>0.006052</td>\n","      <td>0.000409</td>\n","      <td>0.000918</td>\n","      <td>-0.140119</td>\n","      <td>0.008402</td>\n","      <td>-0.004250</td>\n","      <td>0.006412</td>\n","      <td>0.003599</td>\n","      <td>-0.008043</td>\n","      <td>0.004933</td>\n","      <td>0.010446</td>\n","      <td>-0.142535</td>\n","      <td>0.004085</td>\n","      <td>0.008047</td>\n","      <td>-0.004665</td>\n","      <td>-0.001495</td>\n","      <td>-0.008069</td>\n","      <td>0.003903</td>\n","      <td>0.000678</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>52425</th>\n","      <td>-0.146095</td>\n","      <td>0.004104</td>\n","      <td>-0.011237</td>\n","      <td>-0.000153</td>\n","      <td>-0.002531</td>\n","      <td>-0.000116</td>\n","      <td>0.006154</td>\n","      <td>-0.009300</td>\n","      <td>-0.145636</td>\n","      <td>0.005325</td>\n","      <td>0.010998</td>\n","      <td>0.009816</td>\n","      <td>-0.002608</td>\n","      <td>0.013866</td>\n","      <td>0.005634</td>\n","      <td>-0.002410</td>\n","      <td>-0.143781</td>\n","      <td>0.002681</td>\n","      <td>0.001969</td>\n","      <td>-0.002410</td>\n","      <td>-0.004863</td>\n","      <td>0.009921</td>\n","      <td>-0.011393</td>\n","      <td>0.012068</td>\n","      <td>-0.140610</td>\n","      <td>0.000817</td>\n","      <td>-0.010064</td>\n","      <td>-0.010190</td>\n","      <td>-0.010077</td>\n","      <td>0.006506</td>\n","      <td>-0.012884</td>\n","      <td>-0.008032</td>\n","      <td>-0.137352</td>\n","      <td>0.006789</td>\n","      <td>0.003873</td>\n","      <td>0.005405</td>\n","      <td>-0.013748</td>\n","      <td>0.008833</td>\n","      <td>0.006272</td>\n","      <td>-0.008688</td>\n","      <td>...</td>\n","      <td>-0.005578</td>\n","      <td>-0.001872</td>\n","      <td>0.027961</td>\n","      <td>-0.025156</td>\n","      <td>0.000181</td>\n","      <td>0.019243</td>\n","      <td>-0.008293</td>\n","      <td>-0.122758</td>\n","      <td>-0.010834</td>\n","      <td>0.012950</td>\n","      <td>-0.015323</td>\n","      <td>-0.032338</td>\n","      <td>0.001053</td>\n","      <td>0.000174</td>\n","      <td>-0.029979</td>\n","      <td>-0.110930</td>\n","      <td>0.008966</td>\n","      <td>-0.017023</td>\n","      <td>0.003482</td>\n","      <td>-0.022558</td>\n","      <td>-0.009429</td>\n","      <td>-0.000839</td>\n","      <td>0.012542</td>\n","      <td>-0.119169</td>\n","      <td>-0.000570</td>\n","      <td>0.028065</td>\n","      <td>0.008073</td>\n","      <td>-0.010248</td>\n","      <td>-0.015601</td>\n","      <td>-0.003679</td>\n","      <td>0.026633</td>\n","      <td>-0.113639</td>\n","      <td>0.001711</td>\n","      <td>-0.021820</td>\n","      <td>-0.016428</td>\n","      <td>-0.008463</td>\n","      <td>0.003728</td>\n","      <td>-0.003811</td>\n","      <td>0.007359</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>52426</th>\n","      <td>-0.123379</td>\n","      <td>0.000498</td>\n","      <td>-0.005875</td>\n","      <td>0.007786</td>\n","      <td>-0.015854</td>\n","      <td>0.006297</td>\n","      <td>0.021712</td>\n","      <td>-0.008541</td>\n","      <td>-0.125034</td>\n","      <td>0.006816</td>\n","      <td>0.020379</td>\n","      <td>0.010674</td>\n","      <td>-0.022967</td>\n","      <td>-0.013839</td>\n","      <td>0.003470</td>\n","      <td>-0.015262</td>\n","      <td>-0.131178</td>\n","      <td>-0.004838</td>\n","      <td>-0.026246</td>\n","      <td>-0.019711</td>\n","      <td>-0.022032</td>\n","      <td>-0.040072</td>\n","      <td>-0.003660</td>\n","      <td>0.004878</td>\n","      <td>-0.128555</td>\n","      <td>0.001209</td>\n","      <td>0.025786</td>\n","      <td>0.017120</td>\n","      <td>-0.014753</td>\n","      <td>0.030791</td>\n","      <td>-0.007240</td>\n","      <td>0.026824</td>\n","      <td>-0.132951</td>\n","      <td>-0.023751</td>\n","      <td>-0.006413</td>\n","      <td>-0.003221</td>\n","      <td>-0.011785</td>\n","      <td>0.006392</td>\n","      <td>0.007770</td>\n","      <td>-0.034904</td>\n","      <td>...</td>\n","      <td>0.008336</td>\n","      <td>0.004567</td>\n","      <td>0.013499</td>\n","      <td>0.036492</td>\n","      <td>0.044768</td>\n","      <td>-0.024010</td>\n","      <td>-0.013567</td>\n","      <td>-0.132849</td>\n","      <td>-0.007385</td>\n","      <td>0.012264</td>\n","      <td>0.019778</td>\n","      <td>0.043694</td>\n","      <td>0.009531</td>\n","      <td>0.024713</td>\n","      <td>-0.016054</td>\n","      <td>-0.136168</td>\n","      <td>-0.011840</td>\n","      <td>0.005816</td>\n","      <td>-0.026451</td>\n","      <td>0.046054</td>\n","      <td>-0.004201</td>\n","      <td>-0.019258</td>\n","      <td>-0.020134</td>\n","      <td>-0.137123</td>\n","      <td>0.013101</td>\n","      <td>-0.005193</td>\n","      <td>0.012482</td>\n","      <td>0.040122</td>\n","      <td>-0.006070</td>\n","      <td>-0.031953</td>\n","      <td>0.013517</td>\n","      <td>-0.146024</td>\n","      <td>-0.009161</td>\n","      <td>0.030073</td>\n","      <td>0.012389</td>\n","      <td>0.028231</td>\n","      <td>-0.000390</td>\n","      <td>0.007699</td>\n","      <td>0.020123</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>52427</th>\n","      <td>-0.146284</td>\n","      <td>-0.003848</td>\n","      <td>-0.010494</td>\n","      <td>-0.014169</td>\n","      <td>0.017254</td>\n","      <td>0.036317</td>\n","      <td>-0.000565</td>\n","      <td>-0.028473</td>\n","      <td>-0.145622</td>\n","      <td>0.007436</td>\n","      <td>-0.008081</td>\n","      <td>0.020510</td>\n","      <td>0.015386</td>\n","      <td>-0.002685</td>\n","      <td>0.025520</td>\n","      <td>-0.034846</td>\n","      <td>-0.143820</td>\n","      <td>0.009353</td>\n","      <td>0.023279</td>\n","      <td>-0.010918</td>\n","      <td>0.019301</td>\n","      <td>-0.046841</td>\n","      <td>-0.005099</td>\n","      <td>0.039110</td>\n","      <td>-0.147724</td>\n","      <td>0.012074</td>\n","      <td>-0.026226</td>\n","      <td>-0.002978</td>\n","      <td>0.020492</td>\n","      <td>0.023099</td>\n","      <td>-0.013957</td>\n","      <td>0.022862</td>\n","      <td>-0.148042</td>\n","      <td>-0.006185</td>\n","      <td>0.018896</td>\n","      <td>0.013063</td>\n","      <td>0.015377</td>\n","      <td>0.000759</td>\n","      <td>0.023229</td>\n","      <td>0.020442</td>\n","      <td>...</td>\n","      <td>0.001663</td>\n","      <td>0.009999</td>\n","      <td>0.009701</td>\n","      <td>0.010765</td>\n","      <td>-0.032554</td>\n","      <td>-0.004383</td>\n","      <td>0.030427</td>\n","      <td>-0.117769</td>\n","      <td>-0.003766</td>\n","      <td>-0.003173</td>\n","      <td>-0.008997</td>\n","      <td>0.008203</td>\n","      <td>-0.024344</td>\n","      <td>-0.001603</td>\n","      <td>0.023708</td>\n","      <td>-0.125676</td>\n","      <td>0.000100</td>\n","      <td>-0.006078</td>\n","      <td>0.007027</td>\n","      <td>-0.015857</td>\n","      <td>0.001858</td>\n","      <td>0.003486</td>\n","      <td>-0.038427</td>\n","      <td>-0.132912</td>\n","      <td>-0.008304</td>\n","      <td>0.009670</td>\n","      <td>0.005668</td>\n","      <td>-0.034431</td>\n","      <td>-0.006635</td>\n","      <td>0.024041</td>\n","      <td>-0.018816</td>\n","      <td>-0.124121</td>\n","      <td>-0.003865</td>\n","      <td>0.009844</td>\n","      <td>0.001152</td>\n","      <td>-0.021900</td>\n","      <td>0.007768</td>\n","      <td>-0.002160</td>\n","      <td>0.006992</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>52428 rows × 1601 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2c39f06-1c7c-4981-9efd-9e9da91f41d3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f2c39f06-1c7c-4981-9efd-9e9da91f41d3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f2c39f06-1c7c-4981-9efd-9e9da91f41d3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["              0         1         2  ...      1598      1599  label\n","0     -0.166990  0.000503  0.000496  ... -0.006516 -0.006297      1\n","1     -0.170202 -0.001537 -0.000634  ...  0.011145 -0.001709      1\n","2     -0.165242  0.001490 -0.000380  ... -0.005305  0.002571      1\n","3     -0.163976 -0.002890  0.003787  ...  0.001221 -0.002913      1\n","4     -0.163335  0.000869  0.001174  ...  0.001464 -0.000352      1\n","...         ...       ...       ...  ...       ...       ...    ...\n","52423 -0.133884 -0.007319 -0.004551  ... -0.002654 -0.000268      4\n","52424 -0.114887  0.004121  0.002460  ...  0.003903  0.000678      4\n","52425 -0.146095  0.004104 -0.011237  ... -0.003811  0.007359      4\n","52426 -0.123379  0.000498 -0.005875  ...  0.007699  0.020123      4\n","52427 -0.146284 -0.003848 -0.010494  ... -0.002160  0.006992      4\n","\n","[52428 rows x 1601 columns]"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["features = wkwkwk.columns[:-1]\n","labels = wkwkwk.columns[-1]\n","all_features = np.array(wkwkwk[features])\n","all_labels = np.array(wkwkwk[labels])\n","all_features.shape, all_labels.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hWiQyrRFdqOD","executionInfo":{"status":"ok","timestamp":1640159463333,"user_tz":-180,"elapsed":891,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"44eb37de-b13e-419d-9f72-f3a10739f7a4"},"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((52420, 1600), (52420,))"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["def mean(data,no_elements):\n","    X=np.zeros((data.shape[0],data.shape[1]))\n","    for i in range(data.shape[1]):\n","        if i == data.shape[1]-1:\n","            X[:,i]=data[:,i]\n","        elif i+no_elements > data.shape[1]:\n","            X[:,i]=np.mean(data[:,i:-1],axis=1)\n","        else:\n","            X[:,i]=np.mean(data[:,i:i+no_elements],axis=1)\n","    return X\n","def median(data,no_elements):\n","    X=np.zeros((data.shape[0],data.shape[1]))\n","    for i in range(data.shape[1]):\n","        if i == data.shape[1]-1:\n","            X[:,i]=data[:,i]\n","        elif i+no_elements > data.shape[1]:\n","            X[:,i]=np.median(data[:,i:-1],axis=1)\n","        else:\n","            X[:,i]=np.median(data[:,i:i+no_elements],axis=1)\n","    return X\n","def sig_image(data,size):\n","    X=np.zeros((data.shape[0],size,size))\n","    for i in range(data.shape[0]):\n","        X[i]=(data[i,:].reshape(size,size))\n","    return X.astype(np.float16)"],"metadata":{"id":"fZ9jZR9ahJmP","executionInfo":{"status":"ok","timestamp":1640159469456,"user_tz":-180,"elapsed":315,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["%%time\n","channel_mean = mean(all_features, 8)\n","channel_median = median(all_features, 8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JeJ6CCienYL7","executionInfo":{"status":"ok","timestamp":1640159491815,"user_tz":-180,"elapsed":21928,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"99c6789a-a762-4f6d-9cad-156db4a538d4"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 21.6 s, sys: 344 ms, total: 21.9 s\n","Wall time: 21.8 s\n"]}]},{"cell_type":"code","source":["%%time\n","x_n = sig_image(all_features, 40)\n","x_mean = sig_image(channel_mean, 40)\n","x_median = sig_image(channel_median, 40)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bs0v25wDhVC2","executionInfo":{"status":"ok","timestamp":1640159497943,"user_tz":-180,"elapsed":3908,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"03322d05-842f-4431-ecab-809ec96aa83a"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 2.94 s, sys: 621 ms, total: 3.56 s\n","Wall time: 3.56 s\n"]}]},{"cell_type":"code","source":["x_n.shape, x_mean.shape, x_median.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RV3zpJYcntLm","executionInfo":{"status":"ok","timestamp":1640159497944,"user_tz":-180,"elapsed":10,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"562b0e59-eb7e-45ce-cc43-9e08c5adc88a"},"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((52420, 40, 40), (52420, 40, 40), (52420, 40, 40))"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["%%time\n","X=np.stack((x_n,x_mean,x_median),axis=1).astype(np.float16)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"25qSbLJbnt6h","executionInfo":{"status":"ok","timestamp":1640159498501,"user_tz":-180,"elapsed":564,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"e7196cfe-93cc-4bf7-a2d7-664b6a9f935e"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 243 ms, sys: 141 ms, total: 384 ms\n","Wall time: 379 ms\n"]}]},{"cell_type":"code","source":["X.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bI8IPxHdn1oD","executionInfo":{"status":"ok","timestamp":1640159498502,"user_tz":-180,"elapsed":5,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"c6420ce8-1bed-479e-e0f3-cf0482a64cc2"},"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(52420, 3, 40, 40)"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["# all_features = np.expand_dims(all_features[:,:,:], 1)\n","# all_features.shape"],"metadata":{"id":"9hhct5iohyfh","executionInfo":{"status":"ok","timestamp":1640159498879,"user_tz":-180,"elapsed":2,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["%%time\n","from sklearn.model_selection import train_test_split\n","trainx, testx, trainlabel, testlabel = train_test_split(X, all_labels, test_size=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S61khCLNh6id","executionInfo":{"status":"ok","timestamp":1640159500891,"user_tz":-180,"elapsed":458,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"35f63901-22c8-4f45-c01e-5b1bbc6ae101"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 168 ms, sys: 1.33 ms, total: 169 ms\n","Wall time: 175 ms\n"]}]},{"cell_type":"code","source":["sig_train, sig_test = trainx,testx\n","lab_train, lab_test = trainlabel,testlabel\n","sig_train = torch.from_numpy(sig_train)\n","sig_test = torch.from_numpy(sig_test)\n","lab_train= torch.from_numpy(lab_train)\n","lab_test = torch.from_numpy(lab_test)"],"metadata":{"id":"MUU4HJvCh7Md","executionInfo":{"status":"ok","timestamp":1640159500892,"user_tz":-180,"elapsed":3,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"],"metadata":{"id":"apZt0rhIh_pD","executionInfo":{"status":"ok","timestamp":1640159502335,"user_tz":-180,"elapsed":1,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["label_t, count_t = lab_test.unique(return_counts = True)\n","print('Health: {:.4f}%, Chipped: {:.4f}%, Miss: {:.4f}%, Root: {:.4f}%, Surface: {:.4f}%'\n","        .format(count_t[0]/ np.sum(np.array(count_t)) * 100, \n","                count_t[1]/ np.sum(np.array(count_t)) * 100, \n","                count_t[2]/ np.sum(np.array(count_t)) * 100, \n","                count_t[3]/ np.sum(np.array(count_t)) * 100, \n","                count_t[4]/ np.sum(np.array(count_t)) * 100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uPgzfvBkiHko","executionInfo":{"status":"ok","timestamp":1640159502769,"user_tz":-180,"elapsed":4,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"8fda9e8e-2ea5-499c-dbb9-cacb32c0db14"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["Health: 20.0401%, Chipped: 19.9351%, Miss: 20.0782%, Root: 19.5918%, Surface: 20.3548%\n"]}]},{"cell_type":"code","source":["import torch.utils.data as data_utils\n","batch_size = 128 \n","train_tensor = data_utils.TensorDataset(sig_train, lab_train) \n","train_loader = data_utils.DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True)"],"metadata":{"id":"ytOxjcnviKuy","executionInfo":{"status":"ok","timestamp":1640159504443,"user_tz":-180,"elapsed":3,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["%%time\n","import torch.utils.data as data_utils\n","batch_size = 1024\n","test_tensor = data_utils.TensorDataset(sig_test.to(device), lab_test.to(device)) \n","test_loader = data_utils.DataLoader(dataset = test_tensor, batch_size = batch_size, shuffle = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ljP8byRciNzW","executionInfo":{"status":"ok","timestamp":1640159519002,"user_tz":-180,"elapsed":12735,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"12bd6aff-aa6e-43a9-da08-b8f0a6e3958c"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 2 s, sys: 1.8 s, total: 3.8 s\n","Wall time: 11.5 s\n"]}]},{"cell_type":"code","source":["del cnn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":166},"id":"S1g7oNSLimlR","executionInfo":{"status":"error","timestamp":1640099509983,"user_tz":-180,"elapsed":339,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"e94551c5-900b-4889-b45e-6e53b135a520"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-d54bfcad36c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'cnn' is not defined"]}]},{"cell_type":"code","source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        # self.conv1 = nn.Conv2d(1, 32, kernel_size=4,stride=1,padding = 1)\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=4,stride=1,padding = 1)\n","        self.mp1 = nn.MaxPool2d(kernel_size=4,stride=2)\n","        self.conv2 = nn.Conv2d(32,64, kernel_size=4,stride =1)\n","        self.mp2 = nn.MaxPool2d(kernel_size=4,stride=2)\n","        self.fc1= nn.Linear(2304,256)\n","        # self.fc1= nn.Linear(5184,256)\n","        self.dp1 = nn.Dropout(p=0.2)\n","        self.fc2 = nn.Linear(256,5)\n","\n","    def forward(self, x):\n","        in_size = x.size(0)\n","        x = F.relu(self.mp1(self.conv1(x)))\n","        x = F.relu(self.mp2(self.conv2(x)))\n","        x = x.view(in_size,-1)\n","        x = F.relu(self.fc1(x))\n","        x = self.dp1(x)\n","        x = self.fc2(x)\n","        \n","        return F.log_softmax(x, dim=1)"],"metadata":{"id":"ZK5-rRCgiP4P","executionInfo":{"status":"ok","timestamp":1640159523492,"user_tz":-180,"elapsed":470,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["%%time\n","cnn = CNN().double().to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vMZbPRFWicmG","executionInfo":{"status":"ok","timestamp":1640159526894,"user_tz":-180,"elapsed":449,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"e16f8f21-6b91-4e76-c6ee-0760389156e5"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 16.8 ms, sys: 7.47 ms, total: 24.3 ms\n","Wall time: 172 ms\n"]}]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n","num_epochs = 100"],"metadata":{"id":"AsPXM_uTiejZ","executionInfo":{"status":"ok","timestamp":1640159527282,"user_tz":-180,"elapsed":2,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["%%time\n","# 3 channels multisensors\n","total_step = len(train_loader)\n","loss_list = []\n","acc_list = []\n","for epoch in range(num_epochs):\n","    for i, (signals, labels) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        # Run the forward pass\n","        signals, labels = signals.to(device), labels.to(device)\n","        signals=signals\n","        labels=labels\n","        # outputs = cnn(signals.unsqueeze(1).double())\n","        outputs = cnn(signals.double())\n","        loss = criterion(outputs, labels.long())\n","        loss_list.append(loss.item())\n","\n","        # Backprop and perform Adam optimisation\n","        \n","        loss.backward()\n","        optimizer.step()\n","        # Track the accuracy\n","        total = labels.size(0)\n","        _, predicted = torch.max(outputs.data, 1)\n","        correct = (predicted == labels.long()).sum().item()\n","        acc_list.append(correct / total)\n","\n","        # if (epoch+1) % 5 == 0 or epoch==0:\n","        print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Train Accuracy: {:.2f}%'\n","              .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n","                      (correct / total) * 100))\n","        "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HMwfsS5aiiKo","outputId":"4ea3aca2-c8c5-44ef-a8db-7fa190e207dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch [68/100], Step [229/328], Loss: 0.0092, Train Accuracy: 99.22%\n","Epoch [68/100], Step [230/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [68/100], Step [231/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [68/100], Step [232/328], Loss: 0.0094, Train Accuracy: 100.00%\n","Epoch [68/100], Step [233/328], Loss: 0.0158, Train Accuracy: 99.22%\n","Epoch [68/100], Step [234/328], Loss: 0.0278, Train Accuracy: 99.22%\n","Epoch [68/100], Step [235/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [68/100], Step [236/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [68/100], Step [237/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [68/100], Step [238/328], Loss: 0.0064, Train Accuracy: 100.00%\n","Epoch [68/100], Step [239/328], Loss: 0.0060, Train Accuracy: 100.00%\n","Epoch [68/100], Step [240/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [68/100], Step [241/328], Loss: 0.0233, Train Accuracy: 98.44%\n","Epoch [68/100], Step [242/328], Loss: 0.0131, Train Accuracy: 99.22%\n","Epoch [68/100], Step [243/328], Loss: 0.0131, Train Accuracy: 99.22%\n","Epoch [68/100], Step [244/328], Loss: 0.0404, Train Accuracy: 97.66%\n","Epoch [68/100], Step [245/328], Loss: 0.0128, Train Accuracy: 99.22%\n","Epoch [68/100], Step [246/328], Loss: 0.0247, Train Accuracy: 99.22%\n","Epoch [68/100], Step [247/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [68/100], Step [248/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [68/100], Step [249/328], Loss: 0.0152, Train Accuracy: 99.22%\n","Epoch [68/100], Step [250/328], Loss: 0.0152, Train Accuracy: 99.22%\n","Epoch [68/100], Step [251/328], Loss: 0.0095, Train Accuracy: 99.22%\n","Epoch [68/100], Step [252/328], Loss: 0.0087, Train Accuracy: 99.22%\n","Epoch [68/100], Step [253/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [68/100], Step [254/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [68/100], Step [255/328], Loss: 0.0554, Train Accuracy: 99.22%\n","Epoch [68/100], Step [256/328], Loss: 0.0087, Train Accuracy: 100.00%\n","Epoch [68/100], Step [257/328], Loss: 0.0075, Train Accuracy: 99.22%\n","Epoch [68/100], Step [258/328], Loss: 0.0068, Train Accuracy: 100.00%\n","Epoch [68/100], Step [259/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [68/100], Step [260/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [68/100], Step [261/328], Loss: 0.0063, Train Accuracy: 100.00%\n","Epoch [68/100], Step [262/328], Loss: 0.0110, Train Accuracy: 100.00%\n","Epoch [68/100], Step [263/328], Loss: 0.0289, Train Accuracy: 99.22%\n","Epoch [68/100], Step [264/328], Loss: 0.0318, Train Accuracy: 99.22%\n","Epoch [68/100], Step [265/328], Loss: 0.0070, Train Accuracy: 100.00%\n","Epoch [68/100], Step [266/328], Loss: 0.0183, Train Accuracy: 99.22%\n","Epoch [68/100], Step [267/328], Loss: 0.0070, Train Accuracy: 100.00%\n","Epoch [68/100], Step [268/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [68/100], Step [269/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [68/100], Step [270/328], Loss: 0.0187, Train Accuracy: 99.22%\n","Epoch [68/100], Step [271/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [68/100], Step [272/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [68/100], Step [273/328], Loss: 0.0129, Train Accuracy: 99.22%\n","Epoch [68/100], Step [274/328], Loss: 0.0313, Train Accuracy: 98.44%\n","Epoch [68/100], Step [275/328], Loss: 0.0064, Train Accuracy: 100.00%\n","Epoch [68/100], Step [276/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [68/100], Step [277/328], Loss: 0.0136, Train Accuracy: 99.22%\n","Epoch [68/100], Step [278/328], Loss: 0.0130, Train Accuracy: 100.00%\n","Epoch [68/100], Step [279/328], Loss: 0.0518, Train Accuracy: 98.44%\n","Epoch [68/100], Step [280/328], Loss: 0.0082, Train Accuracy: 99.22%\n","Epoch [68/100], Step [281/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [68/100], Step [282/328], Loss: 0.0098, Train Accuracy: 100.00%\n","Epoch [68/100], Step [283/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [68/100], Step [284/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [68/100], Step [285/328], Loss: 0.0643, Train Accuracy: 98.44%\n","Epoch [68/100], Step [286/328], Loss: 0.0328, Train Accuracy: 99.22%\n","Epoch [68/100], Step [287/328], Loss: 0.0288, Train Accuracy: 98.44%\n","Epoch [68/100], Step [288/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [68/100], Step [289/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [68/100], Step [290/328], Loss: 0.0384, Train Accuracy: 98.44%\n","Epoch [68/100], Step [291/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [68/100], Step [292/328], Loss: 0.0183, Train Accuracy: 99.22%\n","Epoch [68/100], Step [293/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [68/100], Step [294/328], Loss: 0.0282, Train Accuracy: 99.22%\n","Epoch [68/100], Step [295/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [68/100], Step [296/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [68/100], Step [297/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [68/100], Step [298/328], Loss: 0.0133, Train Accuracy: 99.22%\n","Epoch [68/100], Step [299/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [68/100], Step [300/328], Loss: 0.0068, Train Accuracy: 99.22%\n","Epoch [68/100], Step [301/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [68/100], Step [302/328], Loss: 0.0244, Train Accuracy: 99.22%\n","Epoch [68/100], Step [303/328], Loss: 0.0497, Train Accuracy: 98.44%\n","Epoch [68/100], Step [304/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [68/100], Step [305/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [68/100], Step [306/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [68/100], Step [307/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [68/100], Step [308/328], Loss: 0.0126, Train Accuracy: 100.00%\n","Epoch [68/100], Step [309/328], Loss: 0.0390, Train Accuracy: 98.44%\n","Epoch [68/100], Step [310/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [68/100], Step [311/328], Loss: 0.0145, Train Accuracy: 99.22%\n","Epoch [68/100], Step [312/328], Loss: 0.0062, Train Accuracy: 99.22%\n","Epoch [68/100], Step [313/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [68/100], Step [314/328], Loss: 0.0100, Train Accuracy: 99.22%\n","Epoch [68/100], Step [315/328], Loss: 0.0203, Train Accuracy: 99.22%\n","Epoch [68/100], Step [316/328], Loss: 0.0259, Train Accuracy: 99.22%\n","Epoch [68/100], Step [317/328], Loss: 0.0204, Train Accuracy: 99.22%\n","Epoch [68/100], Step [318/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [68/100], Step [319/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [68/100], Step [320/328], Loss: 0.0199, Train Accuracy: 99.22%\n","Epoch [68/100], Step [321/328], Loss: 0.0109, Train Accuracy: 100.00%\n","Epoch [68/100], Step [322/328], Loss: 0.0271, Train Accuracy: 99.22%\n","Epoch [68/100], Step [323/328], Loss: 0.0067, Train Accuracy: 99.22%\n","Epoch [68/100], Step [324/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [68/100], Step [325/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [68/100], Step [326/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [68/100], Step [327/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [68/100], Step [328/328], Loss: 0.0214, Train Accuracy: 98.75%\n","Epoch [69/100], Step [1/328], Loss: 0.0095, Train Accuracy: 99.22%\n","Epoch [69/100], Step [2/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [69/100], Step [3/328], Loss: 0.0065, Train Accuracy: 99.22%\n","Epoch [69/100], Step [4/328], Loss: 0.0103, Train Accuracy: 100.00%\n","Epoch [69/100], Step [5/328], Loss: 0.0054, Train Accuracy: 100.00%\n","Epoch [69/100], Step [6/328], Loss: 0.0133, Train Accuracy: 100.00%\n","Epoch [69/100], Step [7/328], Loss: 0.0083, Train Accuracy: 100.00%\n","Epoch [69/100], Step [8/328], Loss: 0.0072, Train Accuracy: 99.22%\n","Epoch [69/100], Step [9/328], Loss: 0.0067, Train Accuracy: 100.00%\n","Epoch [69/100], Step [10/328], Loss: 0.0104, Train Accuracy: 100.00%\n","Epoch [69/100], Step [11/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [69/100], Step [12/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [69/100], Step [13/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [69/100], Step [14/328], Loss: 0.0180, Train Accuracy: 99.22%\n","Epoch [69/100], Step [15/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [69/100], Step [16/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [69/100], Step [17/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [69/100], Step [18/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [69/100], Step [19/328], Loss: 0.0108, Train Accuracy: 99.22%\n","Epoch [69/100], Step [20/328], Loss: 0.0224, Train Accuracy: 99.22%\n","Epoch [69/100], Step [21/328], Loss: 0.0054, Train Accuracy: 100.00%\n","Epoch [69/100], Step [22/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [69/100], Step [23/328], Loss: 0.0060, Train Accuracy: 100.00%\n","Epoch [69/100], Step [24/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [69/100], Step [25/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [69/100], Step [26/328], Loss: 0.0069, Train Accuracy: 100.00%\n","Epoch [69/100], Step [27/328], Loss: 0.0198, Train Accuracy: 99.22%\n","Epoch [69/100], Step [28/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [69/100], Step [29/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [69/100], Step [30/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [69/100], Step [31/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [69/100], Step [32/328], Loss: 0.0064, Train Accuracy: 100.00%\n","Epoch [69/100], Step [33/328], Loss: 0.0230, Train Accuracy: 99.22%\n","Epoch [69/100], Step [34/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [69/100], Step [35/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [69/100], Step [36/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [69/100], Step [37/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [69/100], Step [38/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [69/100], Step [39/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [69/100], Step [40/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [69/100], Step [41/328], Loss: 0.0486, Train Accuracy: 97.66%\n","Epoch [69/100], Step [42/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [69/100], Step [43/328], Loss: 0.0117, Train Accuracy: 99.22%\n","Epoch [69/100], Step [44/328], Loss: 0.0090, Train Accuracy: 100.00%\n","Epoch [69/100], Step [45/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [69/100], Step [46/328], Loss: 0.0235, Train Accuracy: 99.22%\n","Epoch [69/100], Step [47/328], Loss: 0.0160, Train Accuracy: 99.22%\n","Epoch [69/100], Step [48/328], Loss: 0.0343, Train Accuracy: 98.44%\n","Epoch [69/100], Step [49/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [69/100], Step [50/328], Loss: 0.0271, Train Accuracy: 99.22%\n","Epoch [69/100], Step [51/328], Loss: 0.0136, Train Accuracy: 100.00%\n","Epoch [69/100], Step [52/328], Loss: 0.0235, Train Accuracy: 99.22%\n","Epoch [69/100], Step [53/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [69/100], Step [54/328], Loss: 0.0182, Train Accuracy: 99.22%\n","Epoch [69/100], Step [55/328], Loss: 0.0410, Train Accuracy: 99.22%\n","Epoch [69/100], Step [56/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [69/100], Step [57/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [69/100], Step [58/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [69/100], Step [59/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [69/100], Step [60/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [69/100], Step [61/328], Loss: 0.0119, Train Accuracy: 99.22%\n","Epoch [69/100], Step [62/328], Loss: 0.0107, Train Accuracy: 99.22%\n","Epoch [69/100], Step [63/328], Loss: 0.0059, Train Accuracy: 100.00%\n","Epoch [69/100], Step [64/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [69/100], Step [65/328], Loss: 0.0245, Train Accuracy: 99.22%\n","Epoch [69/100], Step [66/328], Loss: 0.0240, Train Accuracy: 99.22%\n","Epoch [69/100], Step [67/328], Loss: 0.0171, Train Accuracy: 99.22%\n","Epoch [69/100], Step [68/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [69/100], Step [69/328], Loss: 0.0107, Train Accuracy: 100.00%\n","Epoch [69/100], Step [70/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [69/100], Step [71/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [69/100], Step [72/328], Loss: 0.0542, Train Accuracy: 99.22%\n","Epoch [69/100], Step [73/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [69/100], Step [74/328], Loss: 0.0387, Train Accuracy: 99.22%\n","Epoch [69/100], Step [75/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [69/100], Step [76/328], Loss: 0.0418, Train Accuracy: 98.44%\n","Epoch [69/100], Step [77/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [69/100], Step [78/328], Loss: 0.0095, Train Accuracy: 99.22%\n","Epoch [69/100], Step [79/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [69/100], Step [80/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [69/100], Step [81/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [69/100], Step [82/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [69/100], Step [83/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [69/100], Step [84/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [69/100], Step [85/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [69/100], Step [86/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [69/100], Step [87/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [69/100], Step [88/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [69/100], Step [89/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [69/100], Step [90/328], Loss: 0.0129, Train Accuracy: 99.22%\n","Epoch [69/100], Step [91/328], Loss: 0.0320, Train Accuracy: 98.44%\n","Epoch [69/100], Step [92/328], Loss: 0.0178, Train Accuracy: 99.22%\n","Epoch [69/100], Step [93/328], Loss: 0.0714, Train Accuracy: 97.66%\n","Epoch [69/100], Step [94/328], Loss: 0.0215, Train Accuracy: 99.22%\n","Epoch [69/100], Step [95/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [69/100], Step [96/328], Loss: 0.0069, Train Accuracy: 100.00%\n","Epoch [69/100], Step [97/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [69/100], Step [98/328], Loss: 0.0521, Train Accuracy: 98.44%\n","Epoch [69/100], Step [99/328], Loss: 0.0355, Train Accuracy: 99.22%\n","Epoch [69/100], Step [100/328], Loss: 0.0122, Train Accuracy: 99.22%\n","Epoch [69/100], Step [101/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [69/100], Step [102/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [69/100], Step [103/328], Loss: 0.0109, Train Accuracy: 99.22%\n","Epoch [69/100], Step [104/328], Loss: 0.0425, Train Accuracy: 99.22%\n","Epoch [69/100], Step [105/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [69/100], Step [106/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [69/100], Step [107/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [69/100], Step [108/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [69/100], Step [109/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [69/100], Step [110/328], Loss: 0.0122, Train Accuracy: 99.22%\n","Epoch [69/100], Step [111/328], Loss: 0.0710, Train Accuracy: 98.44%\n","Epoch [69/100], Step [112/328], Loss: 0.0079, Train Accuracy: 99.22%\n","Epoch [69/100], Step [113/328], Loss: 0.0075, Train Accuracy: 99.22%\n","Epoch [69/100], Step [114/328], Loss: 0.0359, Train Accuracy: 98.44%\n","Epoch [69/100], Step [115/328], Loss: 0.0185, Train Accuracy: 99.22%\n","Epoch [69/100], Step [116/328], Loss: 0.0078, Train Accuracy: 100.00%\n","Epoch [69/100], Step [117/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [69/100], Step [118/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [69/100], Step [119/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [69/100], Step [120/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [69/100], Step [121/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [69/100], Step [122/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [69/100], Step [123/328], Loss: 0.0212, Train Accuracy: 99.22%\n","Epoch [69/100], Step [124/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [69/100], Step [125/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [69/100], Step [126/328], Loss: 0.0138, Train Accuracy: 99.22%\n","Epoch [69/100], Step [127/328], Loss: 0.0072, Train Accuracy: 100.00%\n","Epoch [69/100], Step [128/328], Loss: 0.0204, Train Accuracy: 99.22%\n","Epoch [69/100], Step [129/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [69/100], Step [130/328], Loss: 0.0059, Train Accuracy: 100.00%\n","Epoch [69/100], Step [131/328], Loss: 0.0213, Train Accuracy: 98.44%\n","Epoch [69/100], Step [132/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [69/100], Step [133/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [69/100], Step [134/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [69/100], Step [135/328], Loss: 0.0114, Train Accuracy: 99.22%\n","Epoch [69/100], Step [136/328], Loss: 0.0078, Train Accuracy: 99.22%\n","Epoch [69/100], Step [137/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [69/100], Step [138/328], Loss: 0.0906, Train Accuracy: 99.22%\n","Epoch [69/100], Step [139/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [69/100], Step [140/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [69/100], Step [141/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [69/100], Step [142/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [69/100], Step [143/328], Loss: 0.0059, Train Accuracy: 100.00%\n","Epoch [69/100], Step [144/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [69/100], Step [145/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [69/100], Step [146/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [69/100], Step [147/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [69/100], Step [148/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [69/100], Step [149/328], Loss: 0.0212, Train Accuracy: 99.22%\n","Epoch [69/100], Step [150/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [69/100], Step [151/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [69/100], Step [152/328], Loss: 0.0113, Train Accuracy: 100.00%\n","Epoch [69/100], Step [153/328], Loss: 0.0085, Train Accuracy: 100.00%\n","Epoch [69/100], Step [154/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [69/100], Step [155/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [69/100], Step [156/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [69/100], Step [157/328], Loss: 0.0753, Train Accuracy: 98.44%\n","Epoch [69/100], Step [158/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [69/100], Step [159/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [69/100], Step [160/328], Loss: 0.0109, Train Accuracy: 100.00%\n","Epoch [69/100], Step [161/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [69/100], Step [162/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [69/100], Step [163/328], Loss: 0.0092, Train Accuracy: 99.22%\n","Epoch [69/100], Step [164/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [69/100], Step [165/328], Loss: 0.0352, Train Accuracy: 99.22%\n","Epoch [69/100], Step [166/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [69/100], Step [167/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [69/100], Step [168/328], Loss: 0.0674, Train Accuracy: 99.22%\n","Epoch [69/100], Step [169/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [69/100], Step [170/328], Loss: 0.0251, Train Accuracy: 98.44%\n","Epoch [69/100], Step [171/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [69/100], Step [172/328], Loss: 0.0078, Train Accuracy: 99.22%\n","Epoch [69/100], Step [173/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [69/100], Step [174/328], Loss: 0.0380, Train Accuracy: 99.22%\n","Epoch [69/100], Step [175/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [69/100], Step [176/328], Loss: 0.0261, Train Accuracy: 99.22%\n","Epoch [69/100], Step [177/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [69/100], Step [178/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [69/100], Step [179/328], Loss: 0.0559, Train Accuracy: 98.44%\n","Epoch [69/100], Step [180/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [69/100], Step [181/328], Loss: 0.0216, Train Accuracy: 98.44%\n","Epoch [69/100], Step [182/328], Loss: 0.0241, Train Accuracy: 99.22%\n","Epoch [69/100], Step [183/328], Loss: 0.0220, Train Accuracy: 99.22%\n","Epoch [69/100], Step [184/328], Loss: 0.0270, Train Accuracy: 99.22%\n","Epoch [69/100], Step [185/328], Loss: 0.0110, Train Accuracy: 100.00%\n","Epoch [69/100], Step [186/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [69/100], Step [187/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [69/100], Step [188/328], Loss: 0.0601, Train Accuracy: 98.44%\n","Epoch [69/100], Step [189/328], Loss: 0.0081, Train Accuracy: 99.22%\n","Epoch [69/100], Step [190/328], Loss: 0.0097, Train Accuracy: 99.22%\n","Epoch [69/100], Step [191/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [69/100], Step [192/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [69/100], Step [193/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [69/100], Step [194/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [69/100], Step [195/328], Loss: 0.0189, Train Accuracy: 99.22%\n","Epoch [69/100], Step [196/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [69/100], Step [197/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [69/100], Step [198/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [69/100], Step [199/328], Loss: 0.0069, Train Accuracy: 100.00%\n","Epoch [69/100], Step [200/328], Loss: 0.0059, Train Accuracy: 100.00%\n","Epoch [69/100], Step [201/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [69/100], Step [202/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [69/100], Step [203/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [69/100], Step [204/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [69/100], Step [205/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [69/100], Step [206/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [69/100], Step [207/328], Loss: 0.0101, Train Accuracy: 99.22%\n","Epoch [69/100], Step [208/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [69/100], Step [209/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [69/100], Step [210/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [69/100], Step [211/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [69/100], Step [212/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [69/100], Step [213/328], Loss: 0.0059, Train Accuracy: 100.00%\n","Epoch [69/100], Step [214/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [69/100], Step [215/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [69/100], Step [216/328], Loss: 0.0179, Train Accuracy: 99.22%\n","Epoch [69/100], Step [217/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [69/100], Step [218/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [69/100], Step [219/328], Loss: 0.0113, Train Accuracy: 99.22%\n","Epoch [69/100], Step [220/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [69/100], Step [221/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [69/100], Step [222/328], Loss: 0.0060, Train Accuracy: 100.00%\n","Epoch [69/100], Step [223/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [69/100], Step [224/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [69/100], Step [225/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [69/100], Step [226/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [69/100], Step [227/328], Loss: 0.0110, Train Accuracy: 99.22%\n","Epoch [69/100], Step [228/328], Loss: 0.0300, Train Accuracy: 99.22%\n","Epoch [69/100], Step [229/328], Loss: 0.0069, Train Accuracy: 99.22%\n","Epoch [69/100], Step [230/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [69/100], Step [231/328], Loss: 0.0150, Train Accuracy: 99.22%\n","Epoch [69/100], Step [232/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [69/100], Step [233/328], Loss: 0.0207, Train Accuracy: 99.22%\n","Epoch [69/100], Step [234/328], Loss: 0.0738, Train Accuracy: 97.66%\n","Epoch [69/100], Step [235/328], Loss: 0.0066, Train Accuracy: 100.00%\n","Epoch [69/100], Step [236/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [69/100], Step [237/328], Loss: 0.0153, Train Accuracy: 99.22%\n","Epoch [69/100], Step [238/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [69/100], Step [239/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [69/100], Step [240/328], Loss: 0.0106, Train Accuracy: 100.00%\n","Epoch [69/100], Step [241/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [69/100], Step [242/328], Loss: 0.0088, Train Accuracy: 100.00%\n","Epoch [69/100], Step [243/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [69/100], Step [244/328], Loss: 0.0140, Train Accuracy: 99.22%\n","Epoch [69/100], Step [245/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [69/100], Step [246/328], Loss: 0.0432, Train Accuracy: 98.44%\n","Epoch [69/100], Step [247/328], Loss: 0.0441, Train Accuracy: 98.44%\n","Epoch [69/100], Step [248/328], Loss: 0.0256, Train Accuracy: 98.44%\n","Epoch [69/100], Step [249/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [69/100], Step [250/328], Loss: 0.0076, Train Accuracy: 100.00%\n","Epoch [69/100], Step [251/328], Loss: 0.0092, Train Accuracy: 100.00%\n","Epoch [69/100], Step [252/328], Loss: 0.0317, Train Accuracy: 99.22%\n","Epoch [69/100], Step [253/328], Loss: 0.0471, Train Accuracy: 99.22%\n","Epoch [69/100], Step [254/328], Loss: 0.0587, Train Accuracy: 98.44%\n","Epoch [69/100], Step [255/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [69/100], Step [256/328], Loss: 0.0189, Train Accuracy: 98.44%\n","Epoch [69/100], Step [257/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [69/100], Step [258/328], Loss: 0.0224, Train Accuracy: 99.22%\n","Epoch [69/100], Step [259/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [69/100], Step [260/328], Loss: 0.1026, Train Accuracy: 97.66%\n","Epoch [69/100], Step [261/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [69/100], Step [262/328], Loss: 0.0150, Train Accuracy: 99.22%\n","Epoch [69/100], Step [263/328], Loss: 0.0282, Train Accuracy: 98.44%\n","Epoch [69/100], Step [264/328], Loss: 0.0162, Train Accuracy: 98.44%\n","Epoch [69/100], Step [265/328], Loss: 0.0251, Train Accuracy: 98.44%\n","Epoch [69/100], Step [266/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [69/100], Step [267/328], Loss: 0.0167, Train Accuracy: 99.22%\n","Epoch [69/100], Step [268/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [69/100], Step [269/328], Loss: 0.0100, Train Accuracy: 100.00%\n","Epoch [69/100], Step [270/328], Loss: 0.0224, Train Accuracy: 99.22%\n","Epoch [69/100], Step [271/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [69/100], Step [272/328], Loss: 0.0065, Train Accuracy: 100.00%\n","Epoch [69/100], Step [273/328], Loss: 0.0887, Train Accuracy: 99.22%\n","Epoch [69/100], Step [274/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [69/100], Step [275/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [69/100], Step [276/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [69/100], Step [277/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [69/100], Step [278/328], Loss: 0.0178, Train Accuracy: 99.22%\n","Epoch [69/100], Step [279/328], Loss: 0.0636, Train Accuracy: 96.88%\n","Epoch [69/100], Step [280/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [69/100], Step [281/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [69/100], Step [282/328], Loss: 0.0179, Train Accuracy: 99.22%\n","Epoch [69/100], Step [283/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [69/100], Step [284/328], Loss: 0.0101, Train Accuracy: 99.22%\n","Epoch [69/100], Step [285/328], Loss: 0.0068, Train Accuracy: 100.00%\n","Epoch [69/100], Step [286/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [69/100], Step [287/328], Loss: 0.0239, Train Accuracy: 99.22%\n","Epoch [69/100], Step [288/328], Loss: 0.0071, Train Accuracy: 100.00%\n","Epoch [69/100], Step [289/328], Loss: 0.0704, Train Accuracy: 98.44%\n","Epoch [69/100], Step [290/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [69/100], Step [291/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [69/100], Step [292/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [69/100], Step [293/328], Loss: 0.0352, Train Accuracy: 98.44%\n","Epoch [69/100], Step [294/328], Loss: 0.0576, Train Accuracy: 97.66%\n","Epoch [69/100], Step [295/328], Loss: 0.0087, Train Accuracy: 100.00%\n","Epoch [69/100], Step [296/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [69/100], Step [297/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [69/100], Step [298/328], Loss: 0.0298, Train Accuracy: 99.22%\n","Epoch [69/100], Step [299/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [69/100], Step [300/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [69/100], Step [301/328], Loss: 0.0065, Train Accuracy: 100.00%\n","Epoch [69/100], Step [302/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [69/100], Step [303/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [69/100], Step [304/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [69/100], Step [305/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [69/100], Step [306/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [69/100], Step [307/328], Loss: 0.0076, Train Accuracy: 100.00%\n","Epoch [69/100], Step [308/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [69/100], Step [309/328], Loss: 0.0094, Train Accuracy: 99.22%\n","Epoch [69/100], Step [310/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [69/100], Step [311/328], Loss: 0.0099, Train Accuracy: 100.00%\n","Epoch [69/100], Step [312/328], Loss: 0.0135, Train Accuracy: 99.22%\n","Epoch [69/100], Step [313/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [69/100], Step [314/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [69/100], Step [315/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [69/100], Step [316/328], Loss: 0.0075, Train Accuracy: 100.00%\n","Epoch [69/100], Step [317/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [69/100], Step [318/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [69/100], Step [319/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [69/100], Step [320/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [69/100], Step [321/328], Loss: 0.0218, Train Accuracy: 99.22%\n","Epoch [69/100], Step [322/328], Loss: 0.0067, Train Accuracy: 100.00%\n","Epoch [69/100], Step [323/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [69/100], Step [324/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [69/100], Step [325/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [69/100], Step [326/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [69/100], Step [327/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [69/100], Step [328/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [70/100], Step [1/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [70/100], Step [2/328], Loss: 0.0126, Train Accuracy: 99.22%\n","Epoch [70/100], Step [3/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [70/100], Step [4/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [70/100], Step [5/328], Loss: 0.0139, Train Accuracy: 99.22%\n","Epoch [70/100], Step [6/328], Loss: 0.0146, Train Accuracy: 99.22%\n","Epoch [70/100], Step [7/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [70/100], Step [8/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [70/100], Step [9/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [70/100], Step [10/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [70/100], Step [11/328], Loss: 0.0077, Train Accuracy: 100.00%\n","Epoch [70/100], Step [12/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [70/100], Step [13/328], Loss: 0.0186, Train Accuracy: 99.22%\n","Epoch [70/100], Step [14/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [70/100], Step [15/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [70/100], Step [16/328], Loss: 0.0105, Train Accuracy: 100.00%\n","Epoch [70/100], Step [17/328], Loss: 0.0146, Train Accuracy: 99.22%\n","Epoch [70/100], Step [18/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [70/100], Step [19/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [70/100], Step [20/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [70/100], Step [21/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [70/100], Step [22/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [70/100], Step [23/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [70/100], Step [24/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [70/100], Step [25/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [70/100], Step [26/328], Loss: 0.0131, Train Accuracy: 99.22%\n","Epoch [70/100], Step [27/328], Loss: 0.0158, Train Accuracy: 99.22%\n","Epoch [70/100], Step [28/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [70/100], Step [29/328], Loss: 0.0302, Train Accuracy: 99.22%\n","Epoch [70/100], Step [30/328], Loss: 0.0071, Train Accuracy: 100.00%\n","Epoch [70/100], Step [31/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [70/100], Step [32/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [70/100], Step [33/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [70/100], Step [34/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [70/100], Step [35/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [70/100], Step [36/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [70/100], Step [37/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [70/100], Step [38/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [70/100], Step [39/328], Loss: 0.0311, Train Accuracy: 98.44%\n","Epoch [70/100], Step [40/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [70/100], Step [41/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [70/100], Step [42/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [70/100], Step [43/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [70/100], Step [44/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [70/100], Step [45/328], Loss: 0.0070, Train Accuracy: 99.22%\n","Epoch [70/100], Step [46/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [70/100], Step [47/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [70/100], Step [48/328], Loss: 0.0094, Train Accuracy: 99.22%\n","Epoch [70/100], Step [49/328], Loss: 0.0357, Train Accuracy: 99.22%\n","Epoch [70/100], Step [50/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [70/100], Step [51/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [70/100], Step [52/328], Loss: 0.0618, Train Accuracy: 99.22%\n","Epoch [70/100], Step [53/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [70/100], Step [54/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [70/100], Step [55/328], Loss: 0.0285, Train Accuracy: 99.22%\n","Epoch [70/100], Step [56/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [70/100], Step [57/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [70/100], Step [58/328], Loss: 0.0096, Train Accuracy: 99.22%\n","Epoch [70/100], Step [59/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [70/100], Step [60/328], Loss: 0.0321, Train Accuracy: 99.22%\n","Epoch [70/100], Step [61/328], Loss: 0.0105, Train Accuracy: 99.22%\n","Epoch [70/100], Step [62/328], Loss: 0.0074, Train Accuracy: 100.00%\n","Epoch [70/100], Step [63/328], Loss: 0.0079, Train Accuracy: 100.00%\n","Epoch [70/100], Step [64/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [70/100], Step [65/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [70/100], Step [66/328], Loss: 0.0072, Train Accuracy: 100.00%\n","Epoch [70/100], Step [67/328], Loss: 0.0059, Train Accuracy: 100.00%\n","Epoch [70/100], Step [68/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [70/100], Step [69/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [70/100], Step [70/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [70/100], Step [71/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [70/100], Step [72/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [70/100], Step [73/328], Loss: 0.0146, Train Accuracy: 99.22%\n","Epoch [70/100], Step [74/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [70/100], Step [75/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [70/100], Step [76/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [70/100], Step [77/328], Loss: 0.0070, Train Accuracy: 100.00%\n","Epoch [70/100], Step [78/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [70/100], Step [79/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [70/100], Step [80/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [70/100], Step [81/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [70/100], Step [82/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [70/100], Step [83/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [70/100], Step [84/328], Loss: 0.0118, Train Accuracy: 99.22%\n","Epoch [70/100], Step [85/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [70/100], Step [86/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [70/100], Step [87/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [70/100], Step [88/328], Loss: 0.0063, Train Accuracy: 99.22%\n","Epoch [70/100], Step [89/328], Loss: 0.0060, Train Accuracy: 100.00%\n","Epoch [70/100], Step [90/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [70/100], Step [91/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [70/100], Step [92/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [70/100], Step [93/328], Loss: 0.0115, Train Accuracy: 99.22%\n","Epoch [70/100], Step [94/328], Loss: 0.0141, Train Accuracy: 99.22%\n","Epoch [70/100], Step [95/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [70/100], Step [96/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [70/100], Step [97/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [70/100], Step [98/328], Loss: 0.0206, Train Accuracy: 98.44%\n","Epoch [70/100], Step [99/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [70/100], Step [100/328], Loss: 0.0091, Train Accuracy: 99.22%\n","Epoch [70/100], Step [101/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [70/100], Step [102/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [70/100], Step [103/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [70/100], Step [104/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [70/100], Step [105/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [70/100], Step [106/328], Loss: 0.0127, Train Accuracy: 99.22%\n","Epoch [70/100], Step [107/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [70/100], Step [108/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [70/100], Step [109/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [70/100], Step [110/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [70/100], Step [111/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [70/100], Step [112/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [70/100], Step [113/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [70/100], Step [114/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [70/100], Step [115/328], Loss: 0.0101, Train Accuracy: 99.22%\n","Epoch [70/100], Step [116/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [70/100], Step [117/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [70/100], Step [118/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [70/100], Step [119/328], Loss: 0.0154, Train Accuracy: 99.22%\n","Epoch [70/100], Step [120/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [70/100], Step [121/328], Loss: 0.0073, Train Accuracy: 100.00%\n","Epoch [70/100], Step [122/328], Loss: 0.0102, Train Accuracy: 100.00%\n","Epoch [70/100], Step [123/328], Loss: 0.0219, Train Accuracy: 99.22%\n","Epoch [70/100], Step [124/328], Loss: 0.0127, Train Accuracy: 99.22%\n","Epoch [70/100], Step [125/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [70/100], Step [126/328], Loss: 0.0229, Train Accuracy: 98.44%\n","Epoch [70/100], Step [127/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [70/100], Step [128/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [70/100], Step [129/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [70/100], Step [130/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [70/100], Step [131/328], Loss: 0.0221, Train Accuracy: 99.22%\n","Epoch [70/100], Step [132/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [70/100], Step [133/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [70/100], Step [134/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [70/100], Step [135/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [70/100], Step [136/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [70/100], Step [137/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [70/100], Step [138/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [70/100], Step [139/328], Loss: 0.0067, Train Accuracy: 100.00%\n","Epoch [70/100], Step [140/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [70/100], Step [141/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [70/100], Step [142/328], Loss: 0.0170, Train Accuracy: 99.22%\n","Epoch [70/100], Step [143/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [70/100], Step [144/328], Loss: 0.0244, Train Accuracy: 98.44%\n","Epoch [70/100], Step [145/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [70/100], Step [146/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [70/100], Step [147/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [70/100], Step [148/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [70/100], Step [149/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [70/100], Step [150/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [70/100], Step [151/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [70/100], Step [152/328], Loss: 0.0139, Train Accuracy: 99.22%\n","Epoch [70/100], Step [153/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [70/100], Step [154/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [70/100], Step [155/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [70/100], Step [156/328], Loss: 0.0149, Train Accuracy: 99.22%\n","Epoch [70/100], Step [157/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [70/100], Step [158/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [70/100], Step [159/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [70/100], Step [160/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [70/100], Step [161/328], Loss: 0.0110, Train Accuracy: 99.22%\n","Epoch [70/100], Step [162/328], Loss: 0.0234, Train Accuracy: 98.44%\n","Epoch [70/100], Step [163/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [70/100], Step [164/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [70/100], Step [165/328], Loss: 0.0115, Train Accuracy: 99.22%\n","Epoch [70/100], Step [166/328], Loss: 0.0098, Train Accuracy: 99.22%\n","Epoch [70/100], Step [167/328], Loss: 0.0308, Train Accuracy: 99.22%\n","Epoch [70/100], Step [168/328], Loss: 0.0325, Train Accuracy: 99.22%\n","Epoch [70/100], Step [169/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [70/100], Step [170/328], Loss: 0.0060, Train Accuracy: 100.00%\n","Epoch [70/100], Step [171/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [70/100], Step [172/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [70/100], Step [173/328], Loss: 0.0059, Train Accuracy: 100.00%\n","Epoch [70/100], Step [174/328], Loss: 0.0466, Train Accuracy: 99.22%\n","Epoch [70/100], Step [175/328], Loss: 0.0071, Train Accuracy: 99.22%\n","Epoch [70/100], Step [176/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [70/100], Step [177/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [70/100], Step [178/328], Loss: 0.0104, Train Accuracy: 99.22%\n","Epoch [70/100], Step [179/328], Loss: 0.0141, Train Accuracy: 99.22%\n","Epoch [70/100], Step [180/328], Loss: 0.0162, Train Accuracy: 98.44%\n","Epoch [70/100], Step [181/328], Loss: 0.0514, Train Accuracy: 97.66%\n","Epoch [70/100], Step [182/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [70/100], Step [183/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [70/100], Step [184/328], Loss: 0.0488, Train Accuracy: 98.44%\n","Epoch [70/100], Step [185/328], Loss: 0.0521, Train Accuracy: 97.66%\n","Epoch [70/100], Step [186/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [70/100], Step [187/328], Loss: 0.0349, Train Accuracy: 98.44%\n","Epoch [70/100], Step [188/328], Loss: 0.0618, Train Accuracy: 98.44%\n","Epoch [70/100], Step [189/328], Loss: 0.0339, Train Accuracy: 99.22%\n","Epoch [70/100], Step [190/328], Loss: 0.0168, Train Accuracy: 99.22%\n","Epoch [70/100], Step [191/328], Loss: 0.0298, Train Accuracy: 99.22%\n","Epoch [70/100], Step [192/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [70/100], Step [193/328], Loss: 0.0072, Train Accuracy: 100.00%\n","Epoch [70/100], Step [194/328], Loss: 0.0054, Train Accuracy: 100.00%\n","Epoch [70/100], Step [195/328], Loss: 0.0699, Train Accuracy: 96.88%\n","Epoch [70/100], Step [196/328], Loss: 0.0104, Train Accuracy: 100.00%\n","Epoch [70/100], Step [197/328], Loss: 0.0148, Train Accuracy: 99.22%\n","Epoch [70/100], Step [198/328], Loss: 0.0168, Train Accuracy: 99.22%\n","Epoch [70/100], Step [199/328], Loss: 0.0218, Train Accuracy: 99.22%\n","Epoch [70/100], Step [200/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [70/100], Step [201/328], Loss: 0.0807, Train Accuracy: 96.88%\n","Epoch [70/100], Step [202/328], Loss: 0.0365, Train Accuracy: 99.22%\n","Epoch [70/100], Step [203/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [70/100], Step [204/328], Loss: 0.0209, Train Accuracy: 99.22%\n","Epoch [70/100], Step [205/328], Loss: 0.0206, Train Accuracy: 99.22%\n","Epoch [70/100], Step [206/328], Loss: 0.0337, Train Accuracy: 98.44%\n","Epoch [70/100], Step [207/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [70/100], Step [208/328], Loss: 0.0213, Train Accuracy: 99.22%\n","Epoch [70/100], Step [209/328], Loss: 0.0304, Train Accuracy: 98.44%\n","Epoch [70/100], Step [210/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [70/100], Step [211/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [70/100], Step [212/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [70/100], Step [213/328], Loss: 0.0593, Train Accuracy: 98.44%\n","Epoch [70/100], Step [214/328], Loss: 0.0836, Train Accuracy: 97.66%\n","Epoch [70/100], Step [215/328], Loss: 0.0080, Train Accuracy: 99.22%\n","Epoch [70/100], Step [216/328], Loss: 0.0356, Train Accuracy: 98.44%\n","Epoch [70/100], Step [217/328], Loss: 0.0569, Train Accuracy: 98.44%\n","Epoch [70/100], Step [218/328], Loss: 0.0255, Train Accuracy: 99.22%\n","Epoch [70/100], Step [219/328], Loss: 0.0303, Train Accuracy: 98.44%\n","Epoch [70/100], Step [220/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [70/100], Step [221/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [70/100], Step [222/328], Loss: 0.0069, Train Accuracy: 99.22%\n","Epoch [70/100], Step [223/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [70/100], Step [224/328], Loss: 0.0807, Train Accuracy: 96.88%\n","Epoch [70/100], Step [225/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [70/100], Step [226/328], Loss: 0.0115, Train Accuracy: 100.00%\n","Epoch [70/100], Step [227/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [70/100], Step [228/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [70/100], Step [229/328], Loss: 0.0398, Train Accuracy: 97.66%\n","Epoch [70/100], Step [230/328], Loss: 0.0421, Train Accuracy: 98.44%\n","Epoch [70/100], Step [231/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [70/100], Step [232/328], Loss: 0.0299, Train Accuracy: 99.22%\n","Epoch [70/100], Step [233/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [70/100], Step [234/328], Loss: 0.0298, Train Accuracy: 98.44%\n","Epoch [70/100], Step [235/328], Loss: 0.0339, Train Accuracy: 98.44%\n","Epoch [70/100], Step [236/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [70/100], Step [237/328], Loss: 0.0099, Train Accuracy: 100.00%\n","Epoch [70/100], Step [238/328], Loss: 0.0113, Train Accuracy: 99.22%\n","Epoch [70/100], Step [239/328], Loss: 0.0312, Train Accuracy: 97.66%\n","Epoch [70/100], Step [240/328], Loss: 0.0131, Train Accuracy: 100.00%\n","Epoch [70/100], Step [241/328], Loss: 0.0085, Train Accuracy: 100.00%\n","Epoch [70/100], Step [242/328], Loss: 0.0078, Train Accuracy: 99.22%\n","Epoch [70/100], Step [243/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [70/100], Step [244/328], Loss: 0.0678, Train Accuracy: 96.88%\n","Epoch [70/100], Step [245/328], Loss: 0.0497, Train Accuracy: 97.66%\n","Epoch [70/100], Step [246/328], Loss: 0.0201, Train Accuracy: 98.44%\n","Epoch [70/100], Step [247/328], Loss: 0.0216, Train Accuracy: 99.22%\n","Epoch [70/100], Step [248/328], Loss: 0.0544, Train Accuracy: 98.44%\n","Epoch [70/100], Step [249/328], Loss: 0.0146, Train Accuracy: 99.22%\n","Epoch [70/100], Step [250/328], Loss: 0.0485, Train Accuracy: 97.66%\n","Epoch [70/100], Step [251/328], Loss: 0.0130, Train Accuracy: 99.22%\n","Epoch [70/100], Step [252/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [70/100], Step [253/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [70/100], Step [254/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [70/100], Step [255/328], Loss: 0.1228, Train Accuracy: 98.44%\n","Epoch [70/100], Step [256/328], Loss: 0.0196, Train Accuracy: 99.22%\n","Epoch [70/100], Step [257/328], Loss: 0.0375, Train Accuracy: 98.44%\n","Epoch [70/100], Step [258/328], Loss: 0.1114, Train Accuracy: 96.09%\n","Epoch [70/100], Step [259/328], Loss: 0.0100, Train Accuracy: 100.00%\n","Epoch [70/100], Step [260/328], Loss: 0.0101, Train Accuracy: 99.22%\n","Epoch [70/100], Step [261/328], Loss: 0.0225, Train Accuracy: 99.22%\n","Epoch [70/100], Step [262/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [70/100], Step [263/328], Loss: 0.0158, Train Accuracy: 99.22%\n","Epoch [70/100], Step [264/328], Loss: 0.0063, Train Accuracy: 100.00%\n","Epoch [70/100], Step [265/328], Loss: 0.0382, Train Accuracy: 99.22%\n","Epoch [70/100], Step [266/328], Loss: 0.0409, Train Accuracy: 98.44%\n","Epoch [70/100], Step [267/328], Loss: 0.0154, Train Accuracy: 99.22%\n","Epoch [70/100], Step [268/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [70/100], Step [269/328], Loss: 0.0220, Train Accuracy: 99.22%\n","Epoch [70/100], Step [270/328], Loss: 0.0187, Train Accuracy: 99.22%\n","Epoch [70/100], Step [271/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [70/100], Step [272/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [70/100], Step [273/328], Loss: 0.0086, Train Accuracy: 99.22%\n","Epoch [70/100], Step [274/328], Loss: 0.0269, Train Accuracy: 99.22%\n","Epoch [70/100], Step [275/328], Loss: 0.0071, Train Accuracy: 100.00%\n","Epoch [70/100], Step [276/328], Loss: 0.0270, Train Accuracy: 99.22%\n","Epoch [70/100], Step [277/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [70/100], Step [278/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [70/100], Step [279/328], Loss: 0.0090, Train Accuracy: 99.22%\n","Epoch [70/100], Step [280/328], Loss: 0.0359, Train Accuracy: 99.22%\n","Epoch [70/100], Step [281/328], Loss: 0.0192, Train Accuracy: 99.22%\n","Epoch [70/100], Step [282/328], Loss: 0.0376, Train Accuracy: 98.44%\n","Epoch [70/100], Step [283/328], Loss: 0.0120, Train Accuracy: 99.22%\n","Epoch [70/100], Step [284/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [70/100], Step [285/328], Loss: 0.0144, Train Accuracy: 99.22%\n","Epoch [70/100], Step [286/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [70/100], Step [287/328], Loss: 0.0060, Train Accuracy: 100.00%\n","Epoch [70/100], Step [288/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [70/100], Step [289/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [70/100], Step [290/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [70/100], Step [291/328], Loss: 0.0099, Train Accuracy: 99.22%\n","Epoch [70/100], Step [292/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [70/100], Step [293/328], Loss: 0.0234, Train Accuracy: 98.44%\n","Epoch [70/100], Step [294/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [70/100], Step [295/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [70/100], Step [296/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [70/100], Step [297/328], Loss: 0.0510, Train Accuracy: 99.22%\n","Epoch [70/100], Step [298/328], Loss: 0.0338, Train Accuracy: 98.44%\n","Epoch [70/100], Step [299/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [70/100], Step [300/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [70/100], Step [301/328], Loss: 0.0335, Train Accuracy: 98.44%\n","Epoch [70/100], Step [302/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [70/100], Step [303/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [70/100], Step [304/328], Loss: 0.0123, Train Accuracy: 99.22%\n","Epoch [70/100], Step [305/328], Loss: 0.0359, Train Accuracy: 98.44%\n","Epoch [70/100], Step [306/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [70/100], Step [307/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [70/100], Step [308/328], Loss: 0.0929, Train Accuracy: 97.66%\n","Epoch [70/100], Step [309/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [70/100], Step [310/328], Loss: 0.0534, Train Accuracy: 99.22%\n","Epoch [70/100], Step [311/328], Loss: 0.0204, Train Accuracy: 98.44%\n","Epoch [70/100], Step [312/328], Loss: 0.0112, Train Accuracy: 100.00%\n","Epoch [70/100], Step [313/328], Loss: 0.2612, Train Accuracy: 94.53%\n","Epoch [70/100], Step [314/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [70/100], Step [315/328], Loss: 0.0195, Train Accuracy: 99.22%\n","Epoch [70/100], Step [316/328], Loss: 0.8081, Train Accuracy: 84.38%\n","Epoch [70/100], Step [317/328], Loss: 0.0556, Train Accuracy: 97.66%\n","Epoch [70/100], Step [318/328], Loss: 0.1774, Train Accuracy: 95.31%\n","Epoch [70/100], Step [319/328], Loss: 0.2212, Train Accuracy: 94.53%\n","Epoch [70/100], Step [320/328], Loss: 0.1121, Train Accuracy: 95.31%\n","Epoch [70/100], Step [321/328], Loss: 0.1663, Train Accuracy: 96.09%\n","Epoch [70/100], Step [322/328], Loss: 0.2372, Train Accuracy: 94.53%\n","Epoch [70/100], Step [323/328], Loss: 0.5920, Train Accuracy: 83.59%\n","Epoch [70/100], Step [324/328], Loss: 0.2653, Train Accuracy: 91.41%\n","Epoch [70/100], Step [325/328], Loss: 0.1774, Train Accuracy: 96.88%\n","Epoch [70/100], Step [326/328], Loss: 0.0255, Train Accuracy: 99.22%\n","Epoch [70/100], Step [327/328], Loss: 0.0646, Train Accuracy: 96.88%\n","Epoch [70/100], Step [328/328], Loss: 0.0628, Train Accuracy: 96.25%\n","Epoch [71/100], Step [1/328], Loss: 0.0935, Train Accuracy: 94.53%\n","Epoch [71/100], Step [2/328], Loss: 0.0386, Train Accuracy: 99.22%\n","Epoch [71/100], Step [3/328], Loss: 0.1541, Train Accuracy: 96.09%\n","Epoch [71/100], Step [4/328], Loss: 0.0831, Train Accuracy: 96.88%\n","Epoch [71/100], Step [5/328], Loss: 0.0240, Train Accuracy: 99.22%\n","Epoch [71/100], Step [6/328], Loss: 0.0073, Train Accuracy: 100.00%\n","Epoch [71/100], Step [7/328], Loss: 0.0079, Train Accuracy: 100.00%\n","Epoch [71/100], Step [8/328], Loss: 0.0145, Train Accuracy: 99.22%\n","Epoch [71/100], Step [9/328], Loss: 0.0413, Train Accuracy: 98.44%\n","Epoch [71/100], Step [10/328], Loss: 0.0269, Train Accuracy: 99.22%\n","Epoch [71/100], Step [11/328], Loss: 0.0137, Train Accuracy: 99.22%\n","Epoch [71/100], Step [12/328], Loss: 0.0168, Train Accuracy: 99.22%\n","Epoch [71/100], Step [13/328], Loss: 0.0375, Train Accuracy: 98.44%\n","Epoch [71/100], Step [14/328], Loss: 0.0549, Train Accuracy: 98.44%\n","Epoch [71/100], Step [15/328], Loss: 0.0440, Train Accuracy: 99.22%\n","Epoch [71/100], Step [16/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [71/100], Step [17/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [71/100], Step [18/328], Loss: 0.0091, Train Accuracy: 100.00%\n","Epoch [71/100], Step [19/328], Loss: 0.0074, Train Accuracy: 100.00%\n","Epoch [71/100], Step [20/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [71/100], Step [21/328], Loss: 0.0066, Train Accuracy: 99.22%\n","Epoch [71/100], Step [22/328], Loss: 0.0541, Train Accuracy: 98.44%\n","Epoch [71/100], Step [23/328], Loss: 0.0082, Train Accuracy: 100.00%\n","Epoch [71/100], Step [24/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [71/100], Step [25/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [71/100], Step [26/328], Loss: 0.0256, Train Accuracy: 98.44%\n","Epoch [71/100], Step [27/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [71/100], Step [28/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [71/100], Step [29/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [71/100], Step [30/328], Loss: 0.0146, Train Accuracy: 99.22%\n","Epoch [71/100], Step [31/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [71/100], Step [32/328], Loss: 0.0077, Train Accuracy: 100.00%\n","Epoch [71/100], Step [33/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [71/100], Step [34/328], Loss: 0.0144, Train Accuracy: 99.22%\n","Epoch [71/100], Step [35/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [71/100], Step [36/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [71/100], Step [37/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [71/100], Step [38/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [71/100], Step [39/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [71/100], Step [40/328], Loss: 0.0233, Train Accuracy: 99.22%\n","Epoch [71/100], Step [41/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [71/100], Step [42/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [71/100], Step [43/328], Loss: 0.0182, Train Accuracy: 99.22%\n","Epoch [71/100], Step [44/328], Loss: 0.0048, Train Accuracy: 100.00%\n","Epoch [71/100], Step [45/328], Loss: 0.0255, Train Accuracy: 99.22%\n","Epoch [71/100], Step [46/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [71/100], Step [47/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [71/100], Step [48/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [71/100], Step [49/328], Loss: 0.0126, Train Accuracy: 99.22%\n","Epoch [71/100], Step [50/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [71/100], Step [51/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [71/100], Step [52/328], Loss: 0.0174, Train Accuracy: 99.22%\n","Epoch [71/100], Step [53/328], Loss: 0.0214, Train Accuracy: 99.22%\n","Epoch [71/100], Step [54/328], Loss: 0.0275, Train Accuracy: 99.22%\n","Epoch [71/100], Step [55/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [71/100], Step [56/328], Loss: 0.0071, Train Accuracy: 100.00%\n","Epoch [71/100], Step [57/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [71/100], Step [58/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [71/100], Step [59/328], Loss: 0.0261, Train Accuracy: 98.44%\n","Epoch [71/100], Step [60/328], Loss: 0.0134, Train Accuracy: 100.00%\n","Epoch [71/100], Step [61/328], Loss: 0.0150, Train Accuracy: 99.22%\n","Epoch [71/100], Step [62/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [71/100], Step [63/328], Loss: 0.0521, Train Accuracy: 98.44%\n","Epoch [71/100], Step [64/328], Loss: 0.0101, Train Accuracy: 99.22%\n","Epoch [71/100], Step [65/328], Loss: 0.0065, Train Accuracy: 100.00%\n","Epoch [71/100], Step [66/328], Loss: 0.0122, Train Accuracy: 100.00%\n","Epoch [71/100], Step [67/328], Loss: 0.0162, Train Accuracy: 99.22%\n","Epoch [71/100], Step [68/328], Loss: 0.0217, Train Accuracy: 99.22%\n","Epoch [71/100], Step [69/328], Loss: 0.0068, Train Accuracy: 100.00%\n","Epoch [71/100], Step [70/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [71/100], Step [71/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [71/100], Step [72/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [71/100], Step [73/328], Loss: 0.0367, Train Accuracy: 99.22%\n","Epoch [71/100], Step [74/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [71/100], Step [75/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [71/100], Step [76/328], Loss: 0.0172, Train Accuracy: 99.22%\n","Epoch [71/100], Step [77/328], Loss: 0.0195, Train Accuracy: 99.22%\n","Epoch [71/100], Step [78/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [71/100], Step [79/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [71/100], Step [80/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [71/100], Step [81/328], Loss: 0.0202, Train Accuracy: 99.22%\n","Epoch [71/100], Step [82/328], Loss: 0.0125, Train Accuracy: 100.00%\n","Epoch [71/100], Step [83/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [71/100], Step [84/328], Loss: 0.0122, Train Accuracy: 99.22%\n","Epoch [71/100], Step [85/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [71/100], Step [86/328], Loss: 0.0101, Train Accuracy: 99.22%\n","Epoch [71/100], Step [87/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [71/100], Step [88/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [71/100], Step [89/328], Loss: 0.0638, Train Accuracy: 98.44%\n","Epoch [71/100], Step [90/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [71/100], Step [91/328], Loss: 0.0101, Train Accuracy: 100.00%\n","Epoch [71/100], Step [92/328], Loss: 0.0404, Train Accuracy: 99.22%\n","Epoch [71/100], Step [93/328], Loss: 0.0645, Train Accuracy: 98.44%\n","Epoch [71/100], Step [94/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [71/100], Step [95/328], Loss: 0.0083, Train Accuracy: 99.22%\n","Epoch [71/100], Step [96/328], Loss: 0.0142, Train Accuracy: 99.22%\n","Epoch [71/100], Step [97/328], Loss: 0.0250, Train Accuracy: 98.44%\n","Epoch [71/100], Step [98/328], Loss: 0.0458, Train Accuracy: 98.44%\n","Epoch [71/100], Step [99/328], Loss: 0.0135, Train Accuracy: 99.22%\n","Epoch [71/100], Step [100/328], Loss: 0.0128, Train Accuracy: 99.22%\n","Epoch [71/100], Step [101/328], Loss: 0.0336, Train Accuracy: 99.22%\n","Epoch [71/100], Step [102/328], Loss: 0.0370, Train Accuracy: 99.22%\n","Epoch [71/100], Step [103/328], Loss: 0.0335, Train Accuracy: 98.44%\n","Epoch [71/100], Step [104/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [71/100], Step [105/328], Loss: 0.0074, Train Accuracy: 100.00%\n","Epoch [71/100], Step [106/328], Loss: 0.0074, Train Accuracy: 100.00%\n","Epoch [71/100], Step [107/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [71/100], Step [108/328], Loss: 0.0098, Train Accuracy: 100.00%\n","Epoch [71/100], Step [109/328], Loss: 0.0379, Train Accuracy: 98.44%\n","Epoch [71/100], Step [110/328], Loss: 0.0602, Train Accuracy: 98.44%\n","Epoch [71/100], Step [111/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [71/100], Step [112/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [71/100], Step [113/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [71/100], Step [114/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [71/100], Step [115/328], Loss: 0.0076, Train Accuracy: 100.00%\n","Epoch [71/100], Step [116/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [71/100], Step [117/328], Loss: 0.0219, Train Accuracy: 98.44%\n","Epoch [71/100], Step [118/328], Loss: 0.0100, Train Accuracy: 100.00%\n","Epoch [71/100], Step [119/328], Loss: 0.0129, Train Accuracy: 100.00%\n","Epoch [71/100], Step [120/328], Loss: 0.0295, Train Accuracy: 99.22%\n","Epoch [71/100], Step [121/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [71/100], Step [122/328], Loss: 0.0142, Train Accuracy: 100.00%\n","Epoch [71/100], Step [123/328], Loss: 0.0083, Train Accuracy: 100.00%\n","Epoch [71/100], Step [124/328], Loss: 0.0171, Train Accuracy: 100.00%\n","Epoch [71/100], Step [125/328], Loss: 0.0297, Train Accuracy: 98.44%\n","Epoch [71/100], Step [126/328], Loss: 0.0335, Train Accuracy: 98.44%\n","Epoch [71/100], Step [127/328], Loss: 0.0182, Train Accuracy: 99.22%\n","Epoch [71/100], Step [128/328], Loss: 0.0135, Train Accuracy: 99.22%\n","Epoch [71/100], Step [129/328], Loss: 0.0129, Train Accuracy: 99.22%\n","Epoch [71/100], Step [130/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [71/100], Step [131/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [71/100], Step [132/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [71/100], Step [133/328], Loss: 0.0379, Train Accuracy: 98.44%\n","Epoch [71/100], Step [134/328], Loss: 0.0227, Train Accuracy: 99.22%\n","Epoch [71/100], Step [135/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [71/100], Step [136/328], Loss: 0.0139, Train Accuracy: 100.00%\n","Epoch [71/100], Step [137/328], Loss: 0.0071, Train Accuracy: 100.00%\n","Epoch [71/100], Step [138/328], Loss: 0.0245, Train Accuracy: 98.44%\n","Epoch [71/100], Step [139/328], Loss: 0.0139, Train Accuracy: 99.22%\n","Epoch [71/100], Step [140/328], Loss: 0.0094, Train Accuracy: 100.00%\n","Epoch [71/100], Step [141/328], Loss: 0.0147, Train Accuracy: 99.22%\n","Epoch [71/100], Step [142/328], Loss: 0.0074, Train Accuracy: 99.22%\n","Epoch [71/100], Step [143/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [71/100], Step [144/328], Loss: 0.0210, Train Accuracy: 99.22%\n","Epoch [71/100], Step [145/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [71/100], Step [146/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [71/100], Step [147/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [71/100], Step [148/328], Loss: 0.0325, Train Accuracy: 98.44%\n","Epoch [71/100], Step [149/328], Loss: 0.0320, Train Accuracy: 98.44%\n","Epoch [71/100], Step [150/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [71/100], Step [151/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [71/100], Step [152/328], Loss: 0.0104, Train Accuracy: 100.00%\n","Epoch [71/100], Step [153/328], Loss: 0.0107, Train Accuracy: 100.00%\n","Epoch [71/100], Step [154/328], Loss: 0.0128, Train Accuracy: 99.22%\n","Epoch [71/100], Step [155/328], Loss: 0.0071, Train Accuracy: 100.00%\n","Epoch [71/100], Step [156/328], Loss: 0.0150, Train Accuracy: 99.22%\n","Epoch [71/100], Step [157/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [71/100], Step [158/328], Loss: 0.0331, Train Accuracy: 99.22%\n","Epoch [71/100], Step [159/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [71/100], Step [160/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [71/100], Step [161/328], Loss: 0.0233, Train Accuracy: 99.22%\n","Epoch [71/100], Step [162/328], Loss: 0.0117, Train Accuracy: 99.22%\n","Epoch [71/100], Step [163/328], Loss: 0.0309, Train Accuracy: 98.44%\n","Epoch [71/100], Step [164/328], Loss: 0.0095, Train Accuracy: 99.22%\n","Epoch [71/100], Step [165/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [71/100], Step [166/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [71/100], Step [167/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [71/100], Step [168/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [71/100], Step [169/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [71/100], Step [170/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [71/100], Step [171/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [71/100], Step [172/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [71/100], Step [173/328], Loss: 0.0173, Train Accuracy: 98.44%\n","Epoch [71/100], Step [174/328], Loss: 0.0076, Train Accuracy: 100.00%\n","Epoch [71/100], Step [175/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [71/100], Step [176/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [71/100], Step [177/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [71/100], Step [178/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [71/100], Step [179/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [71/100], Step [180/328], Loss: 0.0105, Train Accuracy: 99.22%\n","Epoch [71/100], Step [181/328], Loss: 0.0253, Train Accuracy: 99.22%\n","Epoch [71/100], Step [182/328], Loss: 0.0187, Train Accuracy: 99.22%\n","Epoch [71/100], Step [183/328], Loss: 0.0147, Train Accuracy: 99.22%\n","Epoch [71/100], Step [184/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [71/100], Step [185/328], Loss: 0.0150, Train Accuracy: 99.22%\n","Epoch [71/100], Step [186/328], Loss: 0.0329, Train Accuracy: 98.44%\n","Epoch [71/100], Step [187/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [71/100], Step [188/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [71/100], Step [189/328], Loss: 0.0082, Train Accuracy: 100.00%\n","Epoch [71/100], Step [190/328], Loss: 0.0206, Train Accuracy: 99.22%\n","Epoch [71/100], Step [191/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [71/100], Step [192/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [71/100], Step [193/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [71/100], Step [194/328], Loss: 0.0120, Train Accuracy: 99.22%\n","Epoch [71/100], Step [195/328], Loss: 0.0142, Train Accuracy: 99.22%\n","Epoch [71/100], Step [196/328], Loss: 0.0113, Train Accuracy: 99.22%\n","Epoch [71/100], Step [197/328], Loss: 0.0125, Train Accuracy: 99.22%\n","Epoch [71/100], Step [198/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [71/100], Step [199/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [71/100], Step [200/328], Loss: 0.0176, Train Accuracy: 99.22%\n","Epoch [71/100], Step [201/328], Loss: 0.0132, Train Accuracy: 99.22%\n","Epoch [71/100], Step [202/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [71/100], Step [203/328], Loss: 0.0065, Train Accuracy: 100.00%\n","Epoch [71/100], Step [204/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [71/100], Step [205/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [71/100], Step [206/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [71/100], Step [207/328], Loss: 0.0355, Train Accuracy: 99.22%\n","Epoch [71/100], Step [208/328], Loss: 0.0305, Train Accuracy: 99.22%\n","Epoch [71/100], Step [209/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [71/100], Step [210/328], Loss: 0.0090, Train Accuracy: 100.00%\n","Epoch [71/100], Step [211/328], Loss: 0.0180, Train Accuracy: 99.22%\n","Epoch [71/100], Step [212/328], Loss: 0.0082, Train Accuracy: 100.00%\n","Epoch [71/100], Step [213/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [71/100], Step [214/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [71/100], Step [215/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [71/100], Step [216/328], Loss: 0.0082, Train Accuracy: 100.00%\n","Epoch [71/100], Step [217/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [71/100], Step [218/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [71/100], Step [219/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [71/100], Step [220/328], Loss: 0.0152, Train Accuracy: 99.22%\n","Epoch [71/100], Step [221/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [71/100], Step [222/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [71/100], Step [223/328], Loss: 0.0070, Train Accuracy: 100.00%\n","Epoch [71/100], Step [224/328], Loss: 0.0171, Train Accuracy: 99.22%\n","Epoch [71/100], Step [225/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [71/100], Step [226/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [71/100], Step [227/328], Loss: 0.0186, Train Accuracy: 99.22%\n","Epoch [71/100], Step [228/328], Loss: 0.0197, Train Accuracy: 98.44%\n","Epoch [71/100], Step [229/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [71/100], Step [230/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [71/100], Step [231/328], Loss: 0.0084, Train Accuracy: 99.22%\n","Epoch [71/100], Step [232/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [71/100], Step [233/328], Loss: 0.0082, Train Accuracy: 100.00%\n","Epoch [71/100], Step [234/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [71/100], Step [235/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [71/100], Step [236/328], Loss: 0.0088, Train Accuracy: 99.22%\n","Epoch [71/100], Step [237/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [71/100], Step [238/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [71/100], Step [239/328], Loss: 0.0167, Train Accuracy: 99.22%\n","Epoch [71/100], Step [240/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [71/100], Step [241/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [71/100], Step [242/328], Loss: 0.0097, Train Accuracy: 99.22%\n","Epoch [71/100], Step [243/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [71/100], Step [244/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [71/100], Step [245/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [71/100], Step [246/328], Loss: 0.0100, Train Accuracy: 99.22%\n","Epoch [71/100], Step [247/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [71/100], Step [248/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [71/100], Step [249/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [71/100], Step [250/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [71/100], Step [251/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [71/100], Step [252/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [71/100], Step [253/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [71/100], Step [254/328], Loss: 0.0048, Train Accuracy: 100.00%\n","Epoch [71/100], Step [255/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [71/100], Step [256/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [71/100], Step [257/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [71/100], Step [258/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [71/100], Step [259/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [71/100], Step [260/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [71/100], Step [261/328], Loss: 0.0509, Train Accuracy: 98.44%\n","Epoch [71/100], Step [262/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [71/100], Step [263/328], Loss: 0.0180, Train Accuracy: 99.22%\n","Epoch [71/100], Step [264/328], Loss: 0.0148, Train Accuracy: 99.22%\n","Epoch [71/100], Step [265/328], Loss: 0.0243, Train Accuracy: 99.22%\n","Epoch [71/100], Step [266/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [71/100], Step [267/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [71/100], Step [268/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [71/100], Step [269/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [71/100], Step [270/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [71/100], Step [271/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [71/100], Step [272/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [71/100], Step [273/328], Loss: 0.0092, Train Accuracy: 100.00%\n","Epoch [71/100], Step [274/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [71/100], Step [275/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [71/100], Step [276/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [71/100], Step [277/328], Loss: 0.0091, Train Accuracy: 99.22%\n","Epoch [71/100], Step [278/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [71/100], Step [279/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [71/100], Step [280/328], Loss: 0.0064, Train Accuracy: 100.00%\n","Epoch [71/100], Step [281/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [71/100], Step [282/328], Loss: 0.0121, Train Accuracy: 99.22%\n","Epoch [71/100], Step [283/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [71/100], Step [284/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [71/100], Step [285/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [71/100], Step [286/328], Loss: 0.0263, Train Accuracy: 99.22%\n","Epoch [71/100], Step [287/328], Loss: 0.0130, Train Accuracy: 99.22%\n","Epoch [71/100], Step [288/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [71/100], Step [289/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [71/100], Step [290/328], Loss: 0.0059, Train Accuracy: 100.00%\n","Epoch [71/100], Step [291/328], Loss: 0.0085, Train Accuracy: 99.22%\n","Epoch [71/100], Step [292/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [71/100], Step [293/328], Loss: 0.0273, Train Accuracy: 99.22%\n","Epoch [71/100], Step [294/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [71/100], Step [295/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [71/100], Step [296/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [71/100], Step [297/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [71/100], Step [298/328], Loss: 0.0090, Train Accuracy: 99.22%\n","Epoch [71/100], Step [299/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [71/100], Step [300/328], Loss: 0.0168, Train Accuracy: 98.44%\n","Epoch [71/100], Step [301/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [71/100], Step [302/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [71/100], Step [303/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [71/100], Step [304/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [71/100], Step [305/328], Loss: 0.0073, Train Accuracy: 100.00%\n","Epoch [71/100], Step [306/328], Loss: 0.0245, Train Accuracy: 99.22%\n","Epoch [71/100], Step [307/328], Loss: 0.0048, Train Accuracy: 100.00%\n","Epoch [71/100], Step [308/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [71/100], Step [309/328], Loss: 0.0120, Train Accuracy: 100.00%\n","Epoch [71/100], Step [310/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [71/100], Step [311/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [71/100], Step [312/328], Loss: 0.0197, Train Accuracy: 99.22%\n","Epoch [71/100], Step [313/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [71/100], Step [314/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [71/100], Step [315/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [71/100], Step [316/328], Loss: 0.0067, Train Accuracy: 100.00%\n","Epoch [71/100], Step [317/328], Loss: 0.0071, Train Accuracy: 100.00%\n","Epoch [71/100], Step [318/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [71/100], Step [319/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [71/100], Step [320/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [71/100], Step [321/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [71/100], Step [322/328], Loss: 0.0091, Train Accuracy: 99.22%\n","Epoch [71/100], Step [323/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [71/100], Step [324/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [71/100], Step [325/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [71/100], Step [326/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [71/100], Step [327/328], Loss: 0.0218, Train Accuracy: 99.22%\n","Epoch [71/100], Step [328/328], Loss: 0.0117, Train Accuracy: 100.00%\n","Epoch [72/100], Step [1/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [72/100], Step [2/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [72/100], Step [3/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [72/100], Step [4/328], Loss: 0.0240, Train Accuracy: 98.44%\n","Epoch [72/100], Step [5/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [72/100], Step [6/328], Loss: 0.0060, Train Accuracy: 100.00%\n","Epoch [72/100], Step [7/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [72/100], Step [8/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [72/100], Step [9/328], Loss: 0.0088, Train Accuracy: 99.22%\n","Epoch [72/100], Step [10/328], Loss: 0.0161, Train Accuracy: 99.22%\n","Epoch [72/100], Step [11/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [72/100], Step [12/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [72/100], Step [13/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [72/100], Step [14/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [72/100], Step [15/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [72/100], Step [16/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [72/100], Step [17/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [72/100], Step [18/328], Loss: 0.0084, Train Accuracy: 99.22%\n","Epoch [72/100], Step [19/328], Loss: 0.0276, Train Accuracy: 99.22%\n","Epoch [72/100], Step [20/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [72/100], Step [21/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [72/100], Step [22/328], Loss: 0.0133, Train Accuracy: 99.22%\n","Epoch [72/100], Step [23/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [72/100], Step [24/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [72/100], Step [25/328], Loss: 0.0308, Train Accuracy: 98.44%\n","Epoch [72/100], Step [26/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [72/100], Step [27/328], Loss: 0.0129, Train Accuracy: 99.22%\n","Epoch [72/100], Step [28/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [72/100], Step [29/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [72/100], Step [30/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [72/100], Step [31/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [72/100], Step [32/328], Loss: 0.0094, Train Accuracy: 99.22%\n","Epoch [72/100], Step [33/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [72/100], Step [34/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [72/100], Step [35/328], Loss: 0.0143, Train Accuracy: 99.22%\n","Epoch [72/100], Step [36/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [72/100], Step [37/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [72/100], Step [38/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [72/100], Step [39/328], Loss: 0.0083, Train Accuracy: 100.00%\n","Epoch [72/100], Step [40/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [72/100], Step [41/328], Loss: 0.0176, Train Accuracy: 98.44%\n","Epoch [72/100], Step [42/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [72/100], Step [43/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [72/100], Step [44/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [72/100], Step [45/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [72/100], Step [46/328], Loss: 0.0060, Train Accuracy: 99.22%\n","Epoch [72/100], Step [47/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [72/100], Step [48/328], Loss: 0.0072, Train Accuracy: 100.00%\n","Epoch [72/100], Step [49/328], Loss: 0.0160, Train Accuracy: 99.22%\n","Epoch [72/100], Step [50/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [72/100], Step [51/328], Loss: 0.0082, Train Accuracy: 99.22%\n","Epoch [72/100], Step [52/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [72/100], Step [53/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [72/100], Step [54/328], Loss: 0.0065, Train Accuracy: 99.22%\n","Epoch [72/100], Step [55/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [72/100], Step [56/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [72/100], Step [57/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [72/100], Step [58/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [72/100], Step [59/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [72/100], Step [60/328], Loss: 0.0093, Train Accuracy: 99.22%\n","Epoch [72/100], Step [61/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [72/100], Step [62/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [72/100], Step [63/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [72/100], Step [64/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [72/100], Step [65/328], Loss: 0.0118, Train Accuracy: 99.22%\n","Epoch [72/100], Step [66/328], Loss: 0.0060, Train Accuracy: 100.00%\n","Epoch [72/100], Step [67/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [72/100], Step [68/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [72/100], Step [69/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [72/100], Step [70/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [72/100], Step [71/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [72/100], Step [72/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [72/100], Step [73/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [72/100], Step [74/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [72/100], Step [75/328], Loss: 0.0355, Train Accuracy: 99.22%\n","Epoch [72/100], Step [76/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [72/100], Step [77/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [72/100], Step [78/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [72/100], Step [79/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [72/100], Step [80/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [72/100], Step [81/328], Loss: 0.0078, Train Accuracy: 100.00%\n","Epoch [72/100], Step [82/328], Loss: 0.0091, Train Accuracy: 100.00%\n","Epoch [72/100], Step [83/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [72/100], Step [84/328], Loss: 0.0077, Train Accuracy: 100.00%\n","Epoch [72/100], Step [85/328], Loss: 0.0078, Train Accuracy: 100.00%\n","Epoch [72/100], Step [86/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [72/100], Step [87/328], Loss: 0.0154, Train Accuracy: 99.22%\n","Epoch [72/100], Step [88/328], Loss: 0.0423, Train Accuracy: 99.22%\n","Epoch [72/100], Step [89/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [72/100], Step [90/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [72/100], Step [91/328], Loss: 0.0117, Train Accuracy: 99.22%\n","Epoch [72/100], Step [92/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [72/100], Step [93/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [72/100], Step [94/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [72/100], Step [95/328], Loss: 0.0213, Train Accuracy: 98.44%\n","Epoch [72/100], Step [96/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [72/100], Step [97/328], Loss: 0.0324, Train Accuracy: 98.44%\n","Epoch [72/100], Step [98/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [72/100], Step [99/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [72/100], Step [100/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [72/100], Step [101/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [72/100], Step [102/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [72/100], Step [103/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [72/100], Step [104/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [72/100], Step [105/328], Loss: 0.0155, Train Accuracy: 99.22%\n","Epoch [72/100], Step [106/328], Loss: 0.0136, Train Accuracy: 99.22%\n","Epoch [72/100], Step [107/328], Loss: 0.0248, Train Accuracy: 99.22%\n","Epoch [72/100], Step [108/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [72/100], Step [109/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [72/100], Step [110/328], Loss: 0.0437, Train Accuracy: 98.44%\n","Epoch [72/100], Step [111/328], Loss: 0.0081, Train Accuracy: 100.00%\n","Epoch [72/100], Step [112/328], Loss: 0.0134, Train Accuracy: 99.22%\n","Epoch [72/100], Step [113/328], Loss: 0.0068, Train Accuracy: 100.00%\n","Epoch [72/100], Step [114/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [72/100], Step [115/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [72/100], Step [116/328], Loss: 0.0054, Train Accuracy: 100.00%\n","Epoch [72/100], Step [117/328], Loss: 0.0062, Train Accuracy: 100.00%\n","Epoch [72/100], Step [118/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [72/100], Step [119/328], Loss: 0.0659, Train Accuracy: 96.88%\n","Epoch [72/100], Step [120/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [72/100], Step [121/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [72/100], Step [122/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [72/100], Step [123/328], Loss: 0.0124, Train Accuracy: 100.00%\n","Epoch [72/100], Step [124/328], Loss: 0.0468, Train Accuracy: 98.44%\n","Epoch [72/100], Step [125/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [72/100], Step [126/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [72/100], Step [127/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [72/100], Step [128/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [72/100], Step [129/328], Loss: 0.0371, Train Accuracy: 98.44%\n","Epoch [72/100], Step [130/328], Loss: 0.0429, Train Accuracy: 97.66%\n","Epoch [72/100], Step [131/328], Loss: 0.0271, Train Accuracy: 98.44%\n","Epoch [72/100], Step [132/328], Loss: 0.0067, Train Accuracy: 100.00%\n","Epoch [72/100], Step [133/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [72/100], Step [134/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [72/100], Step [135/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [72/100], Step [136/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [72/100], Step [137/328], Loss: 0.0385, Train Accuracy: 97.66%\n","Epoch [72/100], Step [138/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [72/100], Step [139/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [72/100], Step [140/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [72/100], Step [141/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [72/100], Step [142/328], Loss: 0.0190, Train Accuracy: 99.22%\n","Epoch [72/100], Step [143/328], Loss: 0.0118, Train Accuracy: 100.00%\n","Epoch [72/100], Step [144/328], Loss: 0.0760, Train Accuracy: 96.88%\n","Epoch [72/100], Step [145/328], Loss: 0.0087, Train Accuracy: 99.22%\n","Epoch [72/100], Step [146/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [72/100], Step [147/328], Loss: 0.0076, Train Accuracy: 100.00%\n","Epoch [72/100], Step [148/328], Loss: 0.0230, Train Accuracy: 99.22%\n","Epoch [72/100], Step [149/328], Loss: 0.0710, Train Accuracy: 96.88%\n","Epoch [72/100], Step [150/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [72/100], Step [151/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [72/100], Step [152/328], Loss: 0.0076, Train Accuracy: 99.22%\n","Epoch [72/100], Step [153/328], Loss: 0.0161, Train Accuracy: 99.22%\n","Epoch [72/100], Step [154/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [72/100], Step [155/328], Loss: 0.0403, Train Accuracy: 97.66%\n","Epoch [72/100], Step [156/328], Loss: 0.0263, Train Accuracy: 99.22%\n","Epoch [72/100], Step [157/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [72/100], Step [158/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [72/100], Step [159/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [72/100], Step [160/328], Loss: 0.0060, Train Accuracy: 100.00%\n","Epoch [72/100], Step [161/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [72/100], Step [162/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [72/100], Step [163/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [72/100], Step [164/328], Loss: 0.0063, Train Accuracy: 100.00%\n","Epoch [72/100], Step [165/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [72/100], Step [166/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [72/100], Step [167/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [72/100], Step [168/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [72/100], Step [169/328], Loss: 0.0266, Train Accuracy: 99.22%\n","Epoch [72/100], Step [170/328], Loss: 0.0059, Train Accuracy: 100.00%\n","Epoch [72/100], Step [171/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [72/100], Step [172/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [72/100], Step [173/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [72/100], Step [174/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [72/100], Step [175/328], Loss: 0.0127, Train Accuracy: 99.22%\n","Epoch [72/100], Step [176/328], Loss: 0.0279, Train Accuracy: 98.44%\n","Epoch [72/100], Step [177/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [72/100], Step [178/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [72/100], Step [179/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [72/100], Step [180/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [72/100], Step [181/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [72/100], Step [182/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [72/100], Step [183/328], Loss: 0.0157, Train Accuracy: 99.22%\n","Epoch [72/100], Step [184/328], Loss: 0.0110, Train Accuracy: 99.22%\n","Epoch [72/100], Step [185/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [72/100], Step [186/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [72/100], Step [187/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [72/100], Step [188/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [72/100], Step [189/328], Loss: 0.0352, Train Accuracy: 99.22%\n","Epoch [72/100], Step [190/328], Loss: 0.0226, Train Accuracy: 98.44%\n","Epoch [72/100], Step [191/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [72/100], Step [192/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [72/100], Step [193/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [72/100], Step [194/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [72/100], Step [195/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [72/100], Step [196/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [72/100], Step [197/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [72/100], Step [198/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [72/100], Step [199/328], Loss: 0.0101, Train Accuracy: 100.00%\n","Epoch [72/100], Step [200/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [72/100], Step [201/328], Loss: 0.0062, Train Accuracy: 100.00%\n","Epoch [72/100], Step [202/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [72/100], Step [203/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [72/100], Step [204/328], Loss: 0.0092, Train Accuracy: 100.00%\n","Epoch [72/100], Step [205/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [72/100], Step [206/328], Loss: 0.0070, Train Accuracy: 100.00%\n","Epoch [72/100], Step [207/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [72/100], Step [208/328], Loss: 0.0526, Train Accuracy: 99.22%\n","Epoch [72/100], Step [209/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [72/100], Step [210/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [72/100], Step [211/328], Loss: 0.0108, Train Accuracy: 100.00%\n","Epoch [72/100], Step [212/328], Loss: 0.0076, Train Accuracy: 100.00%\n","Epoch [72/100], Step [213/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [72/100], Step [214/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [72/100], Step [215/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [72/100], Step [216/328], Loss: 0.0077, Train Accuracy: 100.00%\n","Epoch [72/100], Step [217/328], Loss: 0.0066, Train Accuracy: 100.00%\n","Epoch [72/100], Step [218/328], Loss: 0.0072, Train Accuracy: 100.00%\n","Epoch [72/100], Step [219/328], Loss: 0.0078, Train Accuracy: 99.22%\n","Epoch [72/100], Step [220/328], Loss: 0.0088, Train Accuracy: 99.22%\n","Epoch [72/100], Step [221/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [72/100], Step [222/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [72/100], Step [223/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [72/100], Step [224/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [72/100], Step [225/328], Loss: 0.0116, Train Accuracy: 99.22%\n","Epoch [72/100], Step [226/328], Loss: 0.0107, Train Accuracy: 99.22%\n","Epoch [72/100], Step [227/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [72/100], Step [228/328], Loss: 0.0048, Train Accuracy: 100.00%\n","Epoch [72/100], Step [229/328], Loss: 0.0075, Train Accuracy: 99.22%\n","Epoch [72/100], Step [230/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [72/100], Step [231/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [72/100], Step [232/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [72/100], Step [233/328], Loss: 0.0172, Train Accuracy: 99.22%\n","Epoch [72/100], Step [234/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [72/100], Step [235/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [72/100], Step [236/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [72/100], Step [237/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [72/100], Step [238/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [72/100], Step [239/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [72/100], Step [240/328], Loss: 0.0188, Train Accuracy: 99.22%\n","Epoch [72/100], Step [241/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [72/100], Step [242/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [72/100], Step [243/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [72/100], Step [244/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [72/100], Step [245/328], Loss: 0.0152, Train Accuracy: 99.22%\n","Epoch [72/100], Step [246/328], Loss: 0.0068, Train Accuracy: 99.22%\n","Epoch [72/100], Step [247/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [72/100], Step [248/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [72/100], Step [249/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [72/100], Step [250/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [72/100], Step [251/328], Loss: 0.0067, Train Accuracy: 100.00%\n","Epoch [72/100], Step [252/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [72/100], Step [253/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [72/100], Step [254/328], Loss: 0.0067, Train Accuracy: 100.00%\n","Epoch [72/100], Step [255/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [72/100], Step [256/328], Loss: 0.0077, Train Accuracy: 99.22%\n","Epoch [72/100], Step [257/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [72/100], Step [258/328], Loss: 0.0072, Train Accuracy: 99.22%\n","Epoch [72/100], Step [259/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [72/100], Step [260/328], Loss: 0.0124, Train Accuracy: 99.22%\n","Epoch [72/100], Step [261/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [72/100], Step [262/328], Loss: 0.0092, Train Accuracy: 100.00%\n","Epoch [72/100], Step [263/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [72/100], Step [264/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [72/100], Step [265/328], Loss: 0.0101, Train Accuracy: 99.22%\n","Epoch [72/100], Step [266/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [72/100], Step [267/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [72/100], Step [268/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [72/100], Step [269/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [72/100], Step [270/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [72/100], Step [271/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [72/100], Step [272/328], Loss: 0.0310, Train Accuracy: 98.44%\n","Epoch [72/100], Step [273/328], Loss: 0.0101, Train Accuracy: 99.22%\n","Epoch [72/100], Step [274/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [72/100], Step [275/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [72/100], Step [276/328], Loss: 0.0096, Train Accuracy: 99.22%\n","Epoch [72/100], Step [277/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [72/100], Step [278/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [72/100], Step [279/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [72/100], Step [280/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [72/100], Step [281/328], Loss: 0.0065, Train Accuracy: 100.00%\n","Epoch [72/100], Step [282/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [72/100], Step [283/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [72/100], Step [284/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [72/100], Step [285/328], Loss: 0.0195, Train Accuracy: 99.22%\n","Epoch [72/100], Step [286/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [72/100], Step [287/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [72/100], Step [288/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [72/100], Step [289/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [72/100], Step [290/328], Loss: 0.0098, Train Accuracy: 99.22%\n","Epoch [72/100], Step [291/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [72/100], Step [292/328], Loss: 0.0166, Train Accuracy: 99.22%\n","Epoch [72/100], Step [293/328], Loss: 0.0370, Train Accuracy: 99.22%\n","Epoch [72/100], Step [294/328], Loss: 0.0124, Train Accuracy: 99.22%\n","Epoch [72/100], Step [295/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [72/100], Step [296/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [72/100], Step [297/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [72/100], Step [298/328], Loss: 0.0159, Train Accuracy: 99.22%\n","Epoch [72/100], Step [299/328], Loss: 0.0144, Train Accuracy: 99.22%\n","Epoch [72/100], Step [300/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [72/100], Step [301/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [72/100], Step [302/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [72/100], Step [303/328], Loss: 0.0110, Train Accuracy: 100.00%\n","Epoch [72/100], Step [304/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [72/100], Step [305/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [72/100], Step [306/328], Loss: 0.0413, Train Accuracy: 99.22%\n","Epoch [72/100], Step [307/328], Loss: 0.0285, Train Accuracy: 99.22%\n","Epoch [72/100], Step [308/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [72/100], Step [309/328], Loss: 0.0102, Train Accuracy: 100.00%\n","Epoch [72/100], Step [310/328], Loss: 0.0082, Train Accuracy: 100.00%\n","Epoch [72/100], Step [311/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [72/100], Step [312/328], Loss: 0.0332, Train Accuracy: 98.44%\n","Epoch [72/100], Step [313/328], Loss: 0.0206, Train Accuracy: 99.22%\n","Epoch [72/100], Step [314/328], Loss: 0.0507, Train Accuracy: 99.22%\n","Epoch [72/100], Step [315/328], Loss: 0.0065, Train Accuracy: 100.00%\n","Epoch [72/100], Step [316/328], Loss: 0.0121, Train Accuracy: 99.22%\n","Epoch [72/100], Step [317/328], Loss: 0.0079, Train Accuracy: 99.22%\n","Epoch [72/100], Step [318/328], Loss: 0.0117, Train Accuracy: 99.22%\n","Epoch [72/100], Step [319/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [72/100], Step [320/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [72/100], Step [321/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [72/100], Step [322/328], Loss: 0.0200, Train Accuracy: 99.22%\n","Epoch [72/100], Step [323/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [72/100], Step [324/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [72/100], Step [325/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [72/100], Step [326/328], Loss: 0.0357, Train Accuracy: 98.44%\n","Epoch [72/100], Step [327/328], Loss: 0.0100, Train Accuracy: 99.22%\n","Epoch [72/100], Step [328/328], Loss: 0.0382, Train Accuracy: 98.75%\n","Epoch [73/100], Step [1/328], Loss: 0.0109, Train Accuracy: 99.22%\n","Epoch [73/100], Step [2/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [73/100], Step [3/328], Loss: 0.0246, Train Accuracy: 98.44%\n","Epoch [73/100], Step [4/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [73/100], Step [5/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [73/100], Step [6/328], Loss: 0.0071, Train Accuracy: 99.22%\n","Epoch [73/100], Step [7/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [73/100], Step [8/328], Loss: 0.0183, Train Accuracy: 99.22%\n","Epoch [73/100], Step [9/328], Loss: 0.0222, Train Accuracy: 99.22%\n","Epoch [73/100], Step [10/328], Loss: 0.0073, Train Accuracy: 100.00%\n","Epoch [73/100], Step [11/328], Loss: 0.0452, Train Accuracy: 99.22%\n","Epoch [73/100], Step [12/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [73/100], Step [13/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [73/100], Step [14/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [73/100], Step [15/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [73/100], Step [16/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [73/100], Step [17/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [18/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [73/100], Step [19/328], Loss: 0.0156, Train Accuracy: 99.22%\n","Epoch [73/100], Step [20/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [21/328], Loss: 0.0071, Train Accuracy: 100.00%\n","Epoch [73/100], Step [22/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [73/100], Step [23/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [73/100], Step [24/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [73/100], Step [25/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [73/100], Step [26/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [73/100], Step [27/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [73/100], Step [28/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [73/100], Step [29/328], Loss: 0.0072, Train Accuracy: 99.22%\n","Epoch [73/100], Step [30/328], Loss: 0.0419, Train Accuracy: 98.44%\n","Epoch [73/100], Step [31/328], Loss: 0.0097, Train Accuracy: 99.22%\n","Epoch [73/100], Step [32/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [73/100], Step [33/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [73/100], Step [34/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [73/100], Step [35/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [73/100], Step [36/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [73/100], Step [37/328], Loss: 0.0817, Train Accuracy: 98.44%\n","Epoch [73/100], Step [38/328], Loss: 0.0317, Train Accuracy: 99.22%\n","Epoch [73/100], Step [39/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [73/100], Step [40/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [73/100], Step [41/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [73/100], Step [42/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [73/100], Step [43/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [73/100], Step [44/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [73/100], Step [45/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [73/100], Step [46/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [73/100], Step [47/328], Loss: 0.1614, Train Accuracy: 98.44%\n","Epoch [73/100], Step [48/328], Loss: 0.0355, Train Accuracy: 99.22%\n","Epoch [73/100], Step [49/328], Loss: 0.0064, Train Accuracy: 100.00%\n","Epoch [73/100], Step [50/328], Loss: 0.0581, Train Accuracy: 98.44%\n","Epoch [73/100], Step [51/328], Loss: 0.0076, Train Accuracy: 100.00%\n","Epoch [73/100], Step [52/328], Loss: 0.0440, Train Accuracy: 98.44%\n","Epoch [73/100], Step [53/328], Loss: 0.0322, Train Accuracy: 99.22%\n","Epoch [73/100], Step [54/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [73/100], Step [55/328], Loss: 0.0067, Train Accuracy: 99.22%\n","Epoch [73/100], Step [56/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [73/100], Step [57/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [73/100], Step [58/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [73/100], Step [59/328], Loss: 0.0113, Train Accuracy: 99.22%\n","Epoch [73/100], Step [60/328], Loss: 0.0127, Train Accuracy: 99.22%\n","Epoch [73/100], Step [61/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [73/100], Step [62/328], Loss: 0.0138, Train Accuracy: 98.44%\n","Epoch [73/100], Step [63/328], Loss: 0.0111, Train Accuracy: 99.22%\n","Epoch [73/100], Step [64/328], Loss: 0.0139, Train Accuracy: 98.44%\n","Epoch [73/100], Step [65/328], Loss: 0.0097, Train Accuracy: 100.00%\n","Epoch [73/100], Step [66/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [73/100], Step [67/328], Loss: 0.0621, Train Accuracy: 99.22%\n","Epoch [73/100], Step [68/328], Loss: 0.0133, Train Accuracy: 100.00%\n","Epoch [73/100], Step [69/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [73/100], Step [70/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [73/100], Step [71/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [73/100], Step [72/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [73/100], Step [73/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [73/100], Step [74/328], Loss: 0.0507, Train Accuracy: 96.88%\n","Epoch [73/100], Step [75/328], Loss: 0.0071, Train Accuracy: 100.00%\n","Epoch [73/100], Step [76/328], Loss: 0.0268, Train Accuracy: 98.44%\n","Epoch [73/100], Step [77/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [73/100], Step [78/328], Loss: 0.0085, Train Accuracy: 100.00%\n","Epoch [73/100], Step [79/328], Loss: 0.0066, Train Accuracy: 100.00%\n","Epoch [73/100], Step [80/328], Loss: 0.0695, Train Accuracy: 99.22%\n","Epoch [73/100], Step [81/328], Loss: 0.0376, Train Accuracy: 98.44%\n","Epoch [73/100], Step [82/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [73/100], Step [83/328], Loss: 0.0079, Train Accuracy: 100.00%\n","Epoch [73/100], Step [84/328], Loss: 0.0095, Train Accuracy: 99.22%\n","Epoch [73/100], Step [85/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [73/100], Step [86/328], Loss: 0.0068, Train Accuracy: 100.00%\n","Epoch [73/100], Step [87/328], Loss: 0.0162, Train Accuracy: 99.22%\n","Epoch [73/100], Step [88/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [73/100], Step [89/328], Loss: 0.0214, Train Accuracy: 99.22%\n","Epoch [73/100], Step [90/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [73/100], Step [91/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [73/100], Step [92/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [73/100], Step [93/328], Loss: 0.0377, Train Accuracy: 98.44%\n","Epoch [73/100], Step [94/328], Loss: 0.0080, Train Accuracy: 100.00%\n","Epoch [73/100], Step [95/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [73/100], Step [96/328], Loss: 0.0144, Train Accuracy: 99.22%\n","Epoch [73/100], Step [97/328], Loss: 0.0087, Train Accuracy: 100.00%\n","Epoch [73/100], Step [98/328], Loss: 0.0136, Train Accuracy: 99.22%\n","Epoch [73/100], Step [99/328], Loss: 0.0271, Train Accuracy: 99.22%\n","Epoch [73/100], Step [100/328], Loss: 0.0064, Train Accuracy: 100.00%\n","Epoch [73/100], Step [101/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [73/100], Step [102/328], Loss: 0.0308, Train Accuracy: 99.22%\n","Epoch [73/100], Step [103/328], Loss: 0.0099, Train Accuracy: 100.00%\n","Epoch [73/100], Step [104/328], Loss: 0.0104, Train Accuracy: 99.22%\n","Epoch [73/100], Step [105/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [73/100], Step [106/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [73/100], Step [107/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [73/100], Step [108/328], Loss: 0.0063, Train Accuracy: 100.00%\n","Epoch [73/100], Step [109/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [73/100], Step [110/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [73/100], Step [111/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [73/100], Step [112/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [73/100], Step [113/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [73/100], Step [114/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [73/100], Step [115/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [73/100], Step [116/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [73/100], Step [117/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [73/100], Step [118/328], Loss: 0.0241, Train Accuracy: 99.22%\n","Epoch [73/100], Step [119/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [73/100], Step [120/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [73/100], Step [121/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [73/100], Step [122/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [123/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [73/100], Step [124/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [73/100], Step [125/328], Loss: 0.0250, Train Accuracy: 99.22%\n","Epoch [73/100], Step [126/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [73/100], Step [127/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [73/100], Step [128/328], Loss: 0.0059, Train Accuracy: 100.00%\n","Epoch [73/100], Step [129/328], Loss: 0.0151, Train Accuracy: 99.22%\n","Epoch [73/100], Step [130/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [73/100], Step [131/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [132/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [133/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [73/100], Step [134/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [73/100], Step [135/328], Loss: 0.0075, Train Accuracy: 100.00%\n","Epoch [73/100], Step [136/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [137/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [138/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [73/100], Step [139/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [73/100], Step [140/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [73/100], Step [141/328], Loss: 0.0104, Train Accuracy: 100.00%\n","Epoch [73/100], Step [142/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [73/100], Step [143/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [144/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [73/100], Step [145/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [73/100], Step [146/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [73/100], Step [147/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [73/100], Step [148/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [73/100], Step [149/328], Loss: 0.0132, Train Accuracy: 99.22%\n","Epoch [73/100], Step [150/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [73/100], Step [151/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [152/328], Loss: 0.0073, Train Accuracy: 99.22%\n","Epoch [73/100], Step [153/328], Loss: 0.0074, Train Accuracy: 99.22%\n","Epoch [73/100], Step [154/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [73/100], Step [155/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [73/100], Step [156/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [73/100], Step [157/328], Loss: 0.0054, Train Accuracy: 100.00%\n","Epoch [73/100], Step [158/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [73/100], Step [159/328], Loss: 0.0444, Train Accuracy: 98.44%\n","Epoch [73/100], Step [160/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [73/100], Step [161/328], Loss: 0.0086, Train Accuracy: 99.22%\n","Epoch [73/100], Step [162/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [73/100], Step [163/328], Loss: 0.0177, Train Accuracy: 99.22%\n","Epoch [73/100], Step [164/328], Loss: 0.0196, Train Accuracy: 99.22%\n","Epoch [73/100], Step [165/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [73/100], Step [166/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [73/100], Step [167/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [73/100], Step [168/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [73/100], Step [169/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [73/100], Step [170/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [73/100], Step [171/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [73/100], Step [172/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [73/100], Step [173/328], Loss: 0.0102, Train Accuracy: 99.22%\n","Epoch [73/100], Step [174/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [73/100], Step [175/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [176/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [73/100], Step [177/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [73/100], Step [178/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [73/100], Step [179/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [73/100], Step [180/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [73/100], Step [181/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [73/100], Step [182/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [73/100], Step [183/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [73/100], Step [184/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [73/100], Step [185/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [73/100], Step [186/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [73/100], Step [187/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [73/100], Step [188/328], Loss: 0.0082, Train Accuracy: 99.22%\n","Epoch [73/100], Step [189/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [190/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [73/100], Step [191/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [73/100], Step [192/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [73/100], Step [193/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [73/100], Step [194/328], Loss: 0.0280, Train Accuracy: 99.22%\n","Epoch [73/100], Step [195/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [73/100], Step [196/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [197/328], Loss: 0.0109, Train Accuracy: 99.22%\n","Epoch [73/100], Step [198/328], Loss: 0.0054, Train Accuracy: 100.00%\n","Epoch [73/100], Step [199/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [73/100], Step [200/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [73/100], Step [201/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [73/100], Step [202/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [203/328], Loss: 0.0089, Train Accuracy: 99.22%\n","Epoch [73/100], Step [204/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [73/100], Step [205/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [73/100], Step [206/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [73/100], Step [207/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [73/100], Step [208/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [73/100], Step [209/328], Loss: 0.0170, Train Accuracy: 99.22%\n","Epoch [73/100], Step [210/328], Loss: 0.0074, Train Accuracy: 99.22%\n","Epoch [73/100], Step [211/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [73/100], Step [212/328], Loss: 0.0067, Train Accuracy: 99.22%\n","Epoch [73/100], Step [213/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [73/100], Step [214/328], Loss: 0.0084, Train Accuracy: 99.22%\n","Epoch [73/100], Step [215/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [73/100], Step [216/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [73/100], Step [217/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [73/100], Step [218/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [73/100], Step [219/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [73/100], Step [220/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [73/100], Step [221/328], Loss: 0.0064, Train Accuracy: 100.00%\n","Epoch [73/100], Step [222/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [73/100], Step [223/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [73/100], Step [224/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [73/100], Step [225/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [73/100], Step [226/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [73/100], Step [227/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [73/100], Step [228/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [73/100], Step [229/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [73/100], Step [230/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [73/100], Step [231/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [73/100], Step [232/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [73/100], Step [233/328], Loss: 0.0054, Train Accuracy: 100.00%\n","Epoch [73/100], Step [234/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [73/100], Step [235/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [236/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [73/100], Step [237/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [73/100], Step [238/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [73/100], Step [239/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [73/100], Step [240/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [73/100], Step [241/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [73/100], Step [242/328], Loss: 0.0182, Train Accuracy: 99.22%\n","Epoch [73/100], Step [243/328], Loss: 0.0099, Train Accuracy: 100.00%\n","Epoch [73/100], Step [244/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [73/100], Step [245/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [73/100], Step [246/328], Loss: 0.0097, Train Accuracy: 99.22%\n","Epoch [73/100], Step [247/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [73/100], Step [248/328], Loss: 0.0124, Train Accuracy: 99.22%\n","Epoch [73/100], Step [249/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [73/100], Step [250/328], Loss: 0.0113, Train Accuracy: 99.22%\n","Epoch [73/100], Step [251/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [73/100], Step [252/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [73/100], Step [253/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [73/100], Step [254/328], Loss: 0.0109, Train Accuracy: 99.22%\n","Epoch [73/100], Step [255/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [73/100], Step [256/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [73/100], Step [257/328], Loss: 0.0219, Train Accuracy: 99.22%\n","Epoch [73/100], Step [258/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [73/100], Step [259/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [73/100], Step [260/328], Loss: 0.0152, Train Accuracy: 99.22%\n","Epoch [73/100], Step [261/328], Loss: 0.0096, Train Accuracy: 99.22%\n","Epoch [73/100], Step [262/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [73/100], Step [263/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [73/100], Step [264/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [73/100], Step [265/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [73/100], Step [266/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [73/100], Step [267/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [73/100], Step [268/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [73/100], Step [269/328], Loss: 0.0132, Train Accuracy: 99.22%\n","Epoch [73/100], Step [270/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [73/100], Step [271/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [73/100], Step [272/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [73/100], Step [273/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [73/100], Step [274/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [73/100], Step [275/328], Loss: 0.0264, Train Accuracy: 99.22%\n","Epoch [73/100], Step [276/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [73/100], Step [277/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [73/100], Step [278/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [73/100], Step [279/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [73/100], Step [280/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [73/100], Step [281/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [282/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [73/100], Step [283/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [73/100], Step [284/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [73/100], Step [285/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [286/328], Loss: 0.0082, Train Accuracy: 99.22%\n","Epoch [73/100], Step [287/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [73/100], Step [288/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [73/100], Step [289/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [73/100], Step [290/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [73/100], Step [291/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [73/100], Step [292/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [73/100], Step [293/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [73/100], Step [294/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [73/100], Step [295/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [296/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [73/100], Step [297/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [73/100], Step [298/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [73/100], Step [299/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [73/100], Step [300/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [73/100], Step [301/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [73/100], Step [302/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [73/100], Step [303/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [73/100], Step [304/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [73/100], Step [305/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [73/100], Step [306/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [73/100], Step [307/328], Loss: 0.0060, Train Accuracy: 99.22%\n","Epoch [73/100], Step [308/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [73/100], Step [309/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [310/328], Loss: 0.0082, Train Accuracy: 99.22%\n","Epoch [73/100], Step [311/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [73/100], Step [312/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [73/100], Step [313/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [314/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [73/100], Step [315/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [73/100], Step [316/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [73/100], Step [317/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [73/100], Step [318/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [73/100], Step [319/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [73/100], Step [320/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [73/100], Step [321/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [73/100], Step [322/328], Loss: 0.0065, Train Accuracy: 100.00%\n","Epoch [73/100], Step [323/328], Loss: 0.0086, Train Accuracy: 99.22%\n","Epoch [73/100], Step [324/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [73/100], Step [325/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [73/100], Step [326/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [73/100], Step [327/328], Loss: 0.0048, Train Accuracy: 100.00%\n","Epoch [73/100], Step [328/328], Loss: 0.0244, Train Accuracy: 98.75%\n","Epoch [74/100], Step [1/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [74/100], Step [2/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [74/100], Step [3/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [74/100], Step [4/328], Loss: 0.0128, Train Accuracy: 99.22%\n","Epoch [74/100], Step [5/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [74/100], Step [6/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [74/100], Step [7/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [74/100], Step [8/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [74/100], Step [9/328], Loss: 0.0000, Train Accuracy: 100.00%\n","Epoch [74/100], Step [10/328], Loss: 0.0105, Train Accuracy: 99.22%\n","Epoch [74/100], Step [11/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [74/100], Step [12/328], Loss: 0.0361, Train Accuracy: 99.22%\n","Epoch [74/100], Step [13/328], Loss: 0.0107, Train Accuracy: 99.22%\n","Epoch [74/100], Step [14/328], Loss: 0.0092, Train Accuracy: 99.22%\n","Epoch [74/100], Step [15/328], Loss: 0.0108, Train Accuracy: 99.22%\n","Epoch [74/100], Step [16/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [74/100], Step [17/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [74/100], Step [18/328], Loss: 0.0223, Train Accuracy: 99.22%\n","Epoch [74/100], Step [19/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [74/100], Step [20/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [74/100], Step [21/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [74/100], Step [22/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [74/100], Step [23/328], Loss: 0.0276, Train Accuracy: 99.22%\n","Epoch [74/100], Step [24/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [74/100], Step [25/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [74/100], Step [26/328], Loss: 0.0123, Train Accuracy: 99.22%\n","Epoch [74/100], Step [27/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [74/100], Step [28/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [74/100], Step [29/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [74/100], Step [30/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [74/100], Step [31/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [74/100], Step [32/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [74/100], Step [33/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [74/100], Step [34/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [74/100], Step [35/328], Loss: 0.0266, Train Accuracy: 99.22%\n","Epoch [74/100], Step [36/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [74/100], Step [37/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [74/100], Step [38/328], Loss: 0.0063, Train Accuracy: 100.00%\n","Epoch [74/100], Step [39/328], Loss: 0.0061, Train Accuracy: 99.22%\n","Epoch [74/100], Step [40/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [74/100], Step [41/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [74/100], Step [42/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [74/100], Step [43/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [74/100], Step [44/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [74/100], Step [45/328], Loss: 0.0157, Train Accuracy: 99.22%\n","Epoch [74/100], Step [46/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [74/100], Step [47/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [74/100], Step [48/328], Loss: 0.0146, Train Accuracy: 99.22%\n","Epoch [74/100], Step [49/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [74/100], Step [50/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [74/100], Step [51/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [74/100], Step [52/328], Loss: 0.0113, Train Accuracy: 99.22%\n","Epoch [74/100], Step [53/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [74/100], Step [54/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [74/100], Step [55/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [74/100], Step [56/328], Loss: 0.0054, Train Accuracy: 100.00%\n","Epoch [74/100], Step [57/328], Loss: 0.0062, Train Accuracy: 100.00%\n","Epoch [74/100], Step [58/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [74/100], Step [59/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [74/100], Step [60/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [74/100], Step [61/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [74/100], Step [62/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [74/100], Step [63/328], Loss: 0.0109, Train Accuracy: 99.22%\n","Epoch [74/100], Step [64/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [74/100], Step [65/328], Loss: 0.0198, Train Accuracy: 99.22%\n","Epoch [74/100], Step [66/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [74/100], Step [67/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [74/100], Step [68/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [74/100], Step [69/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [74/100], Step [70/328], Loss: 0.0081, Train Accuracy: 99.22%\n","Epoch [74/100], Step [71/328], Loss: 0.0213, Train Accuracy: 99.22%\n","Epoch [74/100], Step [72/328], Loss: 0.0187, Train Accuracy: 99.22%\n","Epoch [74/100], Step [73/328], Loss: 0.0075, Train Accuracy: 100.00%\n","Epoch [74/100], Step [74/328], Loss: 0.0101, Train Accuracy: 99.22%\n","Epoch [74/100], Step [75/328], Loss: 0.0163, Train Accuracy: 99.22%\n","Epoch [74/100], Step [76/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [74/100], Step [77/328], Loss: 0.0123, Train Accuracy: 100.00%\n","Epoch [74/100], Step [78/328], Loss: 0.0110, Train Accuracy: 99.22%\n","Epoch [74/100], Step [79/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [74/100], Step [80/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [74/100], Step [81/328], Loss: 0.0149, Train Accuracy: 99.22%\n","Epoch [74/100], Step [82/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [74/100], Step [83/328], Loss: 0.0085, Train Accuracy: 100.00%\n","Epoch [74/100], Step [84/328], Loss: 0.0625, Train Accuracy: 97.66%\n","Epoch [74/100], Step [85/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [74/100], Step [86/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [74/100], Step [87/328], Loss: 0.0118, Train Accuracy: 99.22%\n","Epoch [74/100], Step [88/328], Loss: 0.0382, Train Accuracy: 99.22%\n","Epoch [74/100], Step [89/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [74/100], Step [90/328], Loss: 0.0367, Train Accuracy: 98.44%\n","Epoch [74/100], Step [91/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [74/100], Step [92/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [74/100], Step [93/328], Loss: 0.0138, Train Accuracy: 99.22%\n","Epoch [74/100], Step [94/328], Loss: 0.0079, Train Accuracy: 99.22%\n","Epoch [74/100], Step [95/328], Loss: 0.0081, Train Accuracy: 99.22%\n","Epoch [74/100], Step [96/328], Loss: 0.0797, Train Accuracy: 99.22%\n","Epoch [74/100], Step [97/328], Loss: 0.0321, Train Accuracy: 99.22%\n","Epoch [74/100], Step [98/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [74/100], Step [99/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [74/100], Step [100/328], Loss: 0.0136, Train Accuracy: 99.22%\n","Epoch [74/100], Step [101/328], Loss: 0.0280, Train Accuracy: 98.44%\n","Epoch [74/100], Step [102/328], Loss: 0.0394, Train Accuracy: 99.22%\n","Epoch [74/100], Step [103/328], Loss: 0.0108, Train Accuracy: 99.22%\n","Epoch [74/100], Step [104/328], Loss: 0.0172, Train Accuracy: 99.22%\n","Epoch [74/100], Step [105/328], Loss: 0.0286, Train Accuracy: 99.22%\n","Epoch [74/100], Step [106/328], Loss: 0.0263, Train Accuracy: 97.66%\n","Epoch [74/100], Step [107/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [74/100], Step [108/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [74/100], Step [109/328], Loss: 0.0122, Train Accuracy: 99.22%\n","Epoch [74/100], Step [110/328], Loss: 0.0134, Train Accuracy: 99.22%\n","Epoch [74/100], Step [111/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [74/100], Step [112/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [74/100], Step [113/328], Loss: 0.0211, Train Accuracy: 99.22%\n","Epoch [74/100], Step [114/328], Loss: 0.0224, Train Accuracy: 98.44%\n","Epoch [74/100], Step [115/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [74/100], Step [116/328], Loss: 0.0083, Train Accuracy: 99.22%\n","Epoch [74/100], Step [117/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [74/100], Step [118/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [74/100], Step [119/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [74/100], Step [120/328], Loss: 0.0079, Train Accuracy: 100.00%\n","Epoch [74/100], Step [121/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [74/100], Step [122/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [74/100], Step [123/328], Loss: 0.0186, Train Accuracy: 98.44%\n","Epoch [74/100], Step [124/328], Loss: 0.0086, Train Accuracy: 99.22%\n","Epoch [74/100], Step [125/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [74/100], Step [126/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [74/100], Step [127/328], Loss: 0.0370, Train Accuracy: 99.22%\n","Epoch [74/100], Step [128/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [74/100], Step [129/328], Loss: 0.0271, Train Accuracy: 99.22%\n","Epoch [74/100], Step [130/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [74/100], Step [131/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [74/100], Step [132/328], Loss: 0.0304, Train Accuracy: 99.22%\n","Epoch [74/100], Step [133/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [74/100], Step [134/328], Loss: 0.0526, Train Accuracy: 97.66%\n","Epoch [74/100], Step [135/328], Loss: 0.0325, Train Accuracy: 99.22%\n","Epoch [74/100], Step [136/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [74/100], Step [137/328], Loss: 0.0297, Train Accuracy: 99.22%\n","Epoch [74/100], Step [138/328], Loss: 0.0373, Train Accuracy: 99.22%\n","Epoch [74/100], Step [139/328], Loss: 0.0644, Train Accuracy: 98.44%\n","Epoch [74/100], Step [140/328], Loss: 0.0109, Train Accuracy: 99.22%\n","Epoch [74/100], Step [141/328], Loss: 0.0252, Train Accuracy: 99.22%\n","Epoch [74/100], Step [142/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [74/100], Step [143/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [74/100], Step [144/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [74/100], Step [145/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [74/100], Step [146/328], Loss: 0.0562, Train Accuracy: 97.66%\n","Epoch [74/100], Step [147/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [74/100], Step [148/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [74/100], Step [149/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [74/100], Step [150/328], Loss: 0.0131, Train Accuracy: 100.00%\n","Epoch [74/100], Step [151/328], Loss: 0.0348, Train Accuracy: 98.44%\n","Epoch [74/100], Step [152/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [74/100], Step [153/328], Loss: 0.0152, Train Accuracy: 100.00%\n","Epoch [74/100], Step [154/328], Loss: 0.1024, Train Accuracy: 98.44%\n","Epoch [74/100], Step [155/328], Loss: 0.0347, Train Accuracy: 99.22%\n","Epoch [74/100], Step [156/328], Loss: 0.0095, Train Accuracy: 99.22%\n","Epoch [74/100], Step [157/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [74/100], Step [158/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [74/100], Step [159/328], Loss: 0.0077, Train Accuracy: 100.00%\n","Epoch [74/100], Step [160/328], Loss: 0.0091, Train Accuracy: 100.00%\n","Epoch [74/100], Step [161/328], Loss: 0.0138, Train Accuracy: 99.22%\n","Epoch [74/100], Step [162/328], Loss: 0.0078, Train Accuracy: 100.00%\n","Epoch [74/100], Step [163/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [74/100], Step [164/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [74/100], Step [165/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [74/100], Step [166/328], Loss: 0.0107, Train Accuracy: 100.00%\n","Epoch [74/100], Step [167/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [74/100], Step [168/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [74/100], Step [169/328], Loss: 0.0115, Train Accuracy: 99.22%\n","Epoch [74/100], Step [170/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [74/100], Step [171/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [74/100], Step [172/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [74/100], Step [173/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [74/100], Step [174/328], Loss: 0.0076, Train Accuracy: 100.00%\n","Epoch [74/100], Step [175/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [74/100], Step [176/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [74/100], Step [177/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [74/100], Step [178/328], Loss: 0.0176, Train Accuracy: 99.22%\n","Epoch [74/100], Step [179/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [74/100], Step [180/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [74/100], Step [181/328], Loss: 0.0075, Train Accuracy: 99.22%\n","Epoch [74/100], Step [182/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [74/100], Step [183/328], Loss: 0.0378, Train Accuracy: 99.22%\n","Epoch [74/100], Step [184/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [74/100], Step [185/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [74/100], Step [186/328], Loss: 0.0170, Train Accuracy: 98.44%\n","Epoch [74/100], Step [187/328], Loss: 0.0422, Train Accuracy: 96.88%\n","Epoch [74/100], Step [188/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [74/100], Step [189/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [74/100], Step [190/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [74/100], Step [191/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [74/100], Step [192/328], Loss: 0.0645, Train Accuracy: 99.22%\n","Epoch [74/100], Step [193/328], Loss: 0.0071, Train Accuracy: 100.00%\n","Epoch [74/100], Step [194/328], Loss: 0.0136, Train Accuracy: 99.22%\n","Epoch [74/100], Step [195/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [74/100], Step [196/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [74/100], Step [197/328], Loss: 0.0227, Train Accuracy: 99.22%\n","Epoch [74/100], Step [198/328], Loss: 0.0066, Train Accuracy: 99.22%\n","Epoch [74/100], Step [199/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [74/100], Step [200/328], Loss: 0.0346, Train Accuracy: 99.22%\n","Epoch [74/100], Step [201/328], Loss: 0.0167, Train Accuracy: 99.22%\n","Epoch [74/100], Step [202/328], Loss: 0.0188, Train Accuracy: 99.22%\n","Epoch [74/100], Step [203/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [74/100], Step [204/328], Loss: 0.0145, Train Accuracy: 99.22%\n","Epoch [74/100], Step [205/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [74/100], Step [206/328], Loss: 0.0191, Train Accuracy: 99.22%\n","Epoch [74/100], Step [207/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [74/100], Step [208/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [74/100], Step [209/328], Loss: 0.0774, Train Accuracy: 96.88%\n","Epoch [74/100], Step [210/328], Loss: 0.0153, Train Accuracy: 99.22%\n","Epoch [74/100], Step [211/328], Loss: 0.0357, Train Accuracy: 98.44%\n","Epoch [74/100], Step [212/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [74/100], Step [213/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [74/100], Step [214/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [74/100], Step [215/328], Loss: 0.0823, Train Accuracy: 99.22%\n","Epoch [74/100], Step [216/328], Loss: 0.0507, Train Accuracy: 99.22%\n","Epoch [74/100], Step [217/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [74/100], Step [218/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [74/100], Step [219/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [74/100], Step [220/328], Loss: 0.0458, Train Accuracy: 98.44%\n","Epoch [74/100], Step [221/328], Loss: 0.0712, Train Accuracy: 96.88%\n","Epoch [74/100], Step [222/328], Loss: 0.0150, Train Accuracy: 99.22%\n","Epoch [74/100], Step [223/328], Loss: 0.0134, Train Accuracy: 99.22%\n","Epoch [74/100], Step [224/328], Loss: 0.0316, Train Accuracy: 99.22%\n","Epoch [74/100], Step [225/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [74/100], Step [226/328], Loss: 0.0218, Train Accuracy: 98.44%\n","Epoch [74/100], Step [227/328], Loss: 0.0114, Train Accuracy: 100.00%\n","Epoch [74/100], Step [228/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [74/100], Step [229/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [74/100], Step [230/328], Loss: 0.1690, Train Accuracy: 96.88%\n","Epoch [74/100], Step [231/328], Loss: 0.0394, Train Accuracy: 98.44%\n","Epoch [74/100], Step [232/328], Loss: 0.0415, Train Accuracy: 98.44%\n","Epoch [74/100], Step [233/328], Loss: 0.0290, Train Accuracy: 99.22%\n","Epoch [74/100], Step [234/328], Loss: 0.0138, Train Accuracy: 99.22%\n","Epoch [74/100], Step [235/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [74/100], Step [236/328], Loss: 0.0855, Train Accuracy: 97.66%\n","Epoch [74/100], Step [237/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [74/100], Step [238/328], Loss: 0.0209, Train Accuracy: 99.22%\n","Epoch [74/100], Step [239/328], Loss: 0.0115, Train Accuracy: 100.00%\n","Epoch [74/100], Step [240/328], Loss: 0.0070, Train Accuracy: 100.00%\n","Epoch [74/100], Step [241/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [74/100], Step [242/328], Loss: 0.0113, Train Accuracy: 99.22%\n","Epoch [74/100], Step [243/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [74/100], Step [244/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [74/100], Step [245/328], Loss: 0.0201, Train Accuracy: 99.22%\n","Epoch [74/100], Step [246/328], Loss: 0.0065, Train Accuracy: 100.00%\n","Epoch [74/100], Step [247/328], Loss: 0.0180, Train Accuracy: 98.44%\n","Epoch [74/100], Step [248/328], Loss: 0.0082, Train Accuracy: 100.00%\n","Epoch [74/100], Step [249/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [74/100], Step [250/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [74/100], Step [251/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [74/100], Step [252/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [74/100], Step [253/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [74/100], Step [254/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [74/100], Step [255/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [74/100], Step [256/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [74/100], Step [257/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [74/100], Step [258/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [74/100], Step [259/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [74/100], Step [260/328], Loss: 0.0100, Train Accuracy: 99.22%\n","Epoch [74/100], Step [261/328], Loss: 0.0121, Train Accuracy: 99.22%\n","Epoch [74/100], Step [262/328], Loss: 0.0140, Train Accuracy: 99.22%\n","Epoch [74/100], Step [263/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [74/100], Step [264/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [74/100], Step [265/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [74/100], Step [266/328], Loss: 0.0105, Train Accuracy: 99.22%\n","Epoch [74/100], Step [267/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [74/100], Step [268/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [74/100], Step [269/328], Loss: 0.0059, Train Accuracy: 100.00%\n","Epoch [74/100], Step [270/328], Loss: 0.0211, Train Accuracy: 99.22%\n","Epoch [74/100], Step [271/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [74/100], Step [272/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [74/100], Step [273/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [74/100], Step [274/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [74/100], Step [275/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [74/100], Step [276/328], Loss: 0.0108, Train Accuracy: 99.22%\n","Epoch [74/100], Step [277/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [74/100], Step [278/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [74/100], Step [279/328], Loss: 0.0127, Train Accuracy: 99.22%\n","Epoch [74/100], Step [280/328], Loss: 0.0071, Train Accuracy: 100.00%\n","Epoch [74/100], Step [281/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [74/100], Step [282/328], Loss: 0.0368, Train Accuracy: 99.22%\n","Epoch [74/100], Step [283/328], Loss: 0.0260, Train Accuracy: 99.22%\n","Epoch [74/100], Step [284/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [74/100], Step [285/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [74/100], Step [286/328], Loss: 0.0081, Train Accuracy: 100.00%\n","Epoch [74/100], Step [287/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [74/100], Step [288/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [74/100], Step [289/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [74/100], Step [290/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [74/100], Step [291/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [74/100], Step [292/328], Loss: 0.0297, Train Accuracy: 99.22%\n","Epoch [74/100], Step [293/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [74/100], Step [294/328], Loss: 0.0221, Train Accuracy: 99.22%\n","Epoch [74/100], Step [295/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [74/100], Step [296/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [74/100], Step [297/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [74/100], Step [298/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [74/100], Step [299/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [74/100], Step [300/328], Loss: 0.0171, Train Accuracy: 99.22%\n","Epoch [74/100], Step [301/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [74/100], Step [302/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [74/100], Step [303/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [74/100], Step [304/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [74/100], Step [305/328], Loss: 0.0100, Train Accuracy: 99.22%\n","Epoch [74/100], Step [306/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [74/100], Step [307/328], Loss: 0.0345, Train Accuracy: 98.44%\n","Epoch [74/100], Step [308/328], Loss: 0.0227, Train Accuracy: 98.44%\n","Epoch [74/100], Step [309/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [74/100], Step [310/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [74/100], Step [311/328], Loss: 0.0241, Train Accuracy: 99.22%\n","Epoch [74/100], Step [312/328], Loss: 0.0737, Train Accuracy: 97.66%\n","Epoch [74/100], Step [313/328], Loss: 0.0154, Train Accuracy: 99.22%\n","Epoch [74/100], Step [314/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [74/100], Step [315/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [74/100], Step [316/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [74/100], Step [317/328], Loss: 0.0307, Train Accuracy: 99.22%\n","Epoch [74/100], Step [318/328], Loss: 0.1177, Train Accuracy: 96.88%\n","Epoch [74/100], Step [319/328], Loss: 0.0155, Train Accuracy: 99.22%\n","Epoch [74/100], Step [320/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [74/100], Step [321/328], Loss: 0.0564, Train Accuracy: 98.44%\n","Epoch [74/100], Step [322/328], Loss: 0.0244, Train Accuracy: 98.44%\n","Epoch [74/100], Step [323/328], Loss: 0.0325, Train Accuracy: 98.44%\n","Epoch [74/100], Step [324/328], Loss: 0.0125, Train Accuracy: 100.00%\n","Epoch [74/100], Step [325/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [74/100], Step [326/328], Loss: 0.0106, Train Accuracy: 99.22%\n","Epoch [74/100], Step [327/328], Loss: 0.0884, Train Accuracy: 97.66%\n","Epoch [74/100], Step [328/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [75/100], Step [1/328], Loss: 0.0534, Train Accuracy: 98.44%\n","Epoch [75/100], Step [2/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [75/100], Step [3/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [75/100], Step [4/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [75/100], Step [5/328], Loss: 0.0464, Train Accuracy: 97.66%\n","Epoch [75/100], Step [6/328], Loss: 0.0262, Train Accuracy: 99.22%\n","Epoch [75/100], Step [7/328], Loss: 0.0073, Train Accuracy: 100.00%\n","Epoch [75/100], Step [8/328], Loss: 0.0248, Train Accuracy: 97.66%\n","Epoch [75/100], Step [9/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [75/100], Step [10/328], Loss: 0.0067, Train Accuracy: 100.00%\n","Epoch [75/100], Step [11/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [75/100], Step [12/328], Loss: 0.0059, Train Accuracy: 100.00%\n","Epoch [75/100], Step [13/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [75/100], Step [14/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [75/100], Step [15/328], Loss: 0.0048, Train Accuracy: 100.00%\n","Epoch [75/100], Step [16/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [75/100], Step [17/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [75/100], Step [18/328], Loss: 0.0226, Train Accuracy: 98.44%\n","Epoch [75/100], Step [19/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [75/100], Step [20/328], Loss: 0.0199, Train Accuracy: 99.22%\n","Epoch [75/100], Step [21/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [75/100], Step [22/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [75/100], Step [23/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [75/100], Step [24/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [75/100], Step [25/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [75/100], Step [26/328], Loss: 0.0129, Train Accuracy: 99.22%\n","Epoch [75/100], Step [27/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [75/100], Step [28/328], Loss: 0.0455, Train Accuracy: 99.22%\n","Epoch [75/100], Step [29/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [75/100], Step [30/328], Loss: 0.0125, Train Accuracy: 99.22%\n","Epoch [75/100], Step [31/328], Loss: 0.0118, Train Accuracy: 99.22%\n","Epoch [75/100], Step [32/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [75/100], Step [33/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [75/100], Step [34/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [75/100], Step [35/328], Loss: 0.0086, Train Accuracy: 100.00%\n","Epoch [75/100], Step [36/328], Loss: 0.0082, Train Accuracy: 100.00%\n","Epoch [75/100], Step [37/328], Loss: 0.0099, Train Accuracy: 99.22%\n","Epoch [75/100], Step [38/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [75/100], Step [39/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [75/100], Step [40/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [75/100], Step [41/328], Loss: 0.0109, Train Accuracy: 99.22%\n","Epoch [75/100], Step [42/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [75/100], Step [43/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [75/100], Step [44/328], Loss: 0.0072, Train Accuracy: 99.22%\n","Epoch [75/100], Step [45/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [75/100], Step [46/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [75/100], Step [47/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [75/100], Step [48/328], Loss: 0.0126, Train Accuracy: 99.22%\n","Epoch [75/100], Step [49/328], Loss: 0.0068, Train Accuracy: 99.22%\n","Epoch [75/100], Step [50/328], Loss: 0.0119, Train Accuracy: 99.22%\n","Epoch [75/100], Step [51/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [75/100], Step [52/328], Loss: 0.0100, Train Accuracy: 99.22%\n","Epoch [75/100], Step [53/328], Loss: 0.0069, Train Accuracy: 99.22%\n","Epoch [75/100], Step [54/328], Loss: 0.0146, Train Accuracy: 99.22%\n","Epoch [75/100], Step [55/328], Loss: 0.0204, Train Accuracy: 98.44%\n","Epoch [75/100], Step [56/328], Loss: 0.0555, Train Accuracy: 99.22%\n","Epoch [75/100], Step [57/328], Loss: 0.0117, Train Accuracy: 99.22%\n","Epoch [75/100], Step [58/328], Loss: 0.0115, Train Accuracy: 99.22%\n","Epoch [75/100], Step [59/328], Loss: 0.0190, Train Accuracy: 99.22%\n","Epoch [75/100], Step [60/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [75/100], Step [61/328], Loss: 0.0159, Train Accuracy: 99.22%\n","Epoch [75/100], Step [62/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [75/100], Step [63/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [75/100], Step [64/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [75/100], Step [65/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [75/100], Step [66/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [75/100], Step [67/328], Loss: 0.0062, Train Accuracy: 100.00%\n","Epoch [75/100], Step [68/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [75/100], Step [69/328], Loss: 0.0099, Train Accuracy: 99.22%\n","Epoch [75/100], Step [70/328], Loss: 0.0064, Train Accuracy: 100.00%\n","Epoch [75/100], Step [71/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [75/100], Step [72/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [75/100], Step [73/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [75/100], Step [74/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [75/100], Step [75/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [75/100], Step [76/328], Loss: 0.0183, Train Accuracy: 98.44%\n","Epoch [75/100], Step [77/328], Loss: 0.0106, Train Accuracy: 100.00%\n","Epoch [75/100], Step [78/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [75/100], Step [79/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [75/100], Step [80/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [75/100], Step [81/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [75/100], Step [82/328], Loss: 0.0287, Train Accuracy: 99.22%\n","Epoch [75/100], Step [83/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [75/100], Step [84/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [75/100], Step [85/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [75/100], Step [86/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [75/100], Step [87/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [75/100], Step [88/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [75/100], Step [89/328], Loss: 0.0077, Train Accuracy: 99.22%\n","Epoch [75/100], Step [90/328], Loss: 0.0127, Train Accuracy: 99.22%\n","Epoch [75/100], Step [91/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [75/100], Step [92/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [75/100], Step [93/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [75/100], Step [94/328], Loss: 0.0096, Train Accuracy: 100.00%\n","Epoch [75/100], Step [95/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [75/100], Step [96/328], Loss: 0.0099, Train Accuracy: 99.22%\n","Epoch [75/100], Step [97/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [75/100], Step [98/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [75/100], Step [99/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [75/100], Step [100/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [75/100], Step [101/328], Loss: 0.0435, Train Accuracy: 98.44%\n","Epoch [75/100], Step [102/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [75/100], Step [103/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [75/100], Step [104/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [75/100], Step [105/328], Loss: 0.0213, Train Accuracy: 99.22%\n","Epoch [75/100], Step [106/328], Loss: 0.0063, Train Accuracy: 100.00%\n","Epoch [75/100], Step [107/328], Loss: 0.0054, Train Accuracy: 100.00%\n","Epoch [75/100], Step [108/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [75/100], Step [109/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [75/100], Step [110/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [75/100], Step [111/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [75/100], Step [112/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [75/100], Step [113/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [75/100], Step [114/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [75/100], Step [115/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [75/100], Step [116/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [75/100], Step [117/328], Loss: 0.0165, Train Accuracy: 99.22%\n","Epoch [75/100], Step [118/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [75/100], Step [119/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [75/100], Step [120/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [75/100], Step [121/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [75/100], Step [122/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [75/100], Step [123/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [75/100], Step [124/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [75/100], Step [125/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [75/100], Step [126/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [75/100], Step [127/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [75/100], Step [128/328], Loss: 0.0070, Train Accuracy: 100.00%\n","Epoch [75/100], Step [129/328], Loss: 0.0069, Train Accuracy: 100.00%\n","Epoch [75/100], Step [130/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [75/100], Step [131/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [75/100], Step [132/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [75/100], Step [133/328], Loss: 0.0054, Train Accuracy: 100.00%\n","Epoch [75/100], Step [134/328], Loss: 0.0091, Train Accuracy: 99.22%\n","Epoch [75/100], Step [135/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [75/100], Step [136/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [75/100], Step [137/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [75/100], Step [138/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [75/100], Step [139/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [75/100], Step [140/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [75/100], Step [141/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [75/100], Step [142/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [75/100], Step [143/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [75/100], Step [144/328], Loss: 0.0128, Train Accuracy: 99.22%\n","Epoch [75/100], Step [145/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [75/100], Step [146/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [75/100], Step [147/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [75/100], Step [148/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [75/100], Step [149/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [75/100], Step [150/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [75/100], Step [151/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [75/100], Step [152/328], Loss: 0.0088, Train Accuracy: 99.22%\n","Epoch [75/100], Step [153/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [75/100], Step [154/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [75/100], Step [155/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [75/100], Step [156/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [75/100], Step [157/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [75/100], Step [158/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [75/100], Step [159/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [75/100], Step [160/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [75/100], Step [161/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [75/100], Step [162/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [75/100], Step [163/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [75/100], Step [164/328], Loss: 0.0098, Train Accuracy: 100.00%\n","Epoch [75/100], Step [165/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [75/100], Step [166/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [75/100], Step [167/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [75/100], Step [168/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [75/100], Step [169/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [75/100], Step [170/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [75/100], Step [171/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [75/100], Step [172/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [75/100], Step [173/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [75/100], Step [174/328], Loss: 0.0085, Train Accuracy: 99.22%\n","Epoch [75/100], Step [175/328], Loss: 0.0086, Train Accuracy: 99.22%\n","Epoch [75/100], Step [176/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [75/100], Step [177/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [75/100], Step [178/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [75/100], Step [179/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [75/100], Step [180/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [75/100], Step [181/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [75/100], Step [182/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [75/100], Step [183/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [75/100], Step [184/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [75/100], Step [185/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [75/100], Step [186/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [75/100], Step [187/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [75/100], Step [188/328], Loss: 0.0064, Train Accuracy: 100.00%\n","Epoch [75/100], Step [189/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [75/100], Step [190/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [75/100], Step [191/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [75/100], Step [192/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [75/100], Step [193/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [75/100], Step [194/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [75/100], Step [195/328], Loss: 0.0124, Train Accuracy: 99.22%\n","Epoch [75/100], Step [196/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [75/100], Step [197/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [75/100], Step [198/328], Loss: 0.0082, Train Accuracy: 99.22%\n","Epoch [75/100], Step [199/328], Loss: 0.0132, Train Accuracy: 99.22%\n","Epoch [75/100], Step [200/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [75/100], Step [201/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [75/100], Step [202/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [75/100], Step [203/328], Loss: 0.0070, Train Accuracy: 99.22%\n","Epoch [75/100], Step [204/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [75/100], Step [205/328], Loss: 0.0085, Train Accuracy: 100.00%\n","Epoch [75/100], Step [206/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [75/100], Step [207/328], Loss: 0.0233, Train Accuracy: 99.22%\n","Epoch [75/100], Step [208/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [75/100], Step [209/328], Loss: 0.0094, Train Accuracy: 99.22%\n","Epoch [75/100], Step [210/328], Loss: 0.0149, Train Accuracy: 99.22%\n","Epoch [75/100], Step [211/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [75/100], Step [212/328], Loss: 0.0157, Train Accuracy: 99.22%\n","Epoch [75/100], Step [213/328], Loss: 0.0104, Train Accuracy: 99.22%\n","Epoch [75/100], Step [214/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [75/100], Step [215/328], Loss: 0.0191, Train Accuracy: 99.22%\n","Epoch [75/100], Step [216/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [75/100], Step [217/328], Loss: 0.0136, Train Accuracy: 99.22%\n","Epoch [75/100], Step [218/328], Loss: 0.0124, Train Accuracy: 99.22%\n","Epoch [75/100], Step [219/328], Loss: 0.0071, Train Accuracy: 100.00%\n","Epoch [75/100], Step [220/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [75/100], Step [221/328], Loss: 0.0070, Train Accuracy: 100.00%\n","Epoch [75/100], Step [222/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [75/100], Step [223/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [75/100], Step [224/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [75/100], Step [225/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [75/100], Step [226/328], Loss: 0.0090, Train Accuracy: 99.22%\n","Epoch [75/100], Step [227/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [75/100], Step [228/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [75/100], Step [229/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [75/100], Step [230/328], Loss: 0.0067, Train Accuracy: 100.00%\n","Epoch [75/100], Step [231/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [75/100], Step [232/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [75/100], Step [233/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [75/100], Step [234/328], Loss: 0.0070, Train Accuracy: 100.00%\n","Epoch [75/100], Step [235/328], Loss: 0.0054, Train Accuracy: 100.00%\n","Epoch [75/100], Step [236/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [75/100], Step [237/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [75/100], Step [238/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [75/100], Step [239/328], Loss: 0.0165, Train Accuracy: 99.22%\n","Epoch [75/100], Step [240/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [75/100], Step [241/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [75/100], Step [242/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [75/100], Step [243/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [75/100], Step [244/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [75/100], Step [245/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [75/100], Step [246/328], Loss: 0.0221, Train Accuracy: 99.22%\n","Epoch [75/100], Step [247/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [75/100], Step [248/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [75/100], Step [249/328], Loss: 0.0079, Train Accuracy: 100.00%\n","Epoch [75/100], Step [250/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [75/100], Step [251/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [75/100], Step [252/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [75/100], Step [253/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [75/100], Step [254/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [75/100], Step [255/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [75/100], Step [256/328], Loss: 0.0277, Train Accuracy: 98.44%\n","Epoch [75/100], Step [257/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [75/100], Step [258/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [75/100], Step [259/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [75/100], Step [260/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [75/100], Step [261/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [75/100], Step [262/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [75/100], Step [263/328], Loss: 0.0224, Train Accuracy: 99.22%\n","Epoch [75/100], Step [264/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [75/100], Step [265/328], Loss: 0.0083, Train Accuracy: 99.22%\n","Epoch [75/100], Step [266/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [75/100], Step [267/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [75/100], Step [268/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [75/100], Step [269/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [75/100], Step [270/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [75/100], Step [271/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [75/100], Step [272/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [75/100], Step [273/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [75/100], Step [274/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [75/100], Step [275/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [75/100], Step [276/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [75/100], Step [277/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [75/100], Step [278/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [75/100], Step [279/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [75/100], Step [280/328], Loss: 0.0391, Train Accuracy: 99.22%\n","Epoch [75/100], Step [281/328], Loss: 0.0102, Train Accuracy: 99.22%\n","Epoch [75/100], Step [282/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [75/100], Step [283/328], Loss: 0.0093, Train Accuracy: 99.22%\n","Epoch [75/100], Step [284/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [75/100], Step [285/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [75/100], Step [286/328], Loss: 0.0065, Train Accuracy: 100.00%\n","Epoch [75/100], Step [287/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [75/100], Step [288/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [75/100], Step [289/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [75/100], Step [290/328], Loss: 0.0109, Train Accuracy: 99.22%\n","Epoch [75/100], Step [291/328], Loss: 0.0075, Train Accuracy: 99.22%\n","Epoch [75/100], Step [292/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [75/100], Step [293/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [75/100], Step [294/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [75/100], Step [295/328], Loss: 0.0065, Train Accuracy: 99.22%\n","Epoch [75/100], Step [296/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [75/100], Step [297/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [75/100], Step [298/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [75/100], Step [299/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [75/100], Step [300/328], Loss: 0.0110, Train Accuracy: 99.22%\n","Epoch [75/100], Step [301/328], Loss: 0.0093, Train Accuracy: 99.22%\n","Epoch [75/100], Step [302/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [75/100], Step [303/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [75/100], Step [304/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [75/100], Step [305/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [75/100], Step [306/328], Loss: 0.0354, Train Accuracy: 99.22%\n","Epoch [75/100], Step [307/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [75/100], Step [308/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [75/100], Step [309/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [75/100], Step [310/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [75/100], Step [311/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [75/100], Step [312/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [75/100], Step [313/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [75/100], Step [314/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [75/100], Step [315/328], Loss: 0.0525, Train Accuracy: 98.44%\n","Epoch [75/100], Step [316/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [75/100], Step [317/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [75/100], Step [318/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [75/100], Step [319/328], Loss: 0.0370, Train Accuracy: 99.22%\n","Epoch [75/100], Step [320/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [75/100], Step [321/328], Loss: 0.0078, Train Accuracy: 99.22%\n","Epoch [75/100], Step [322/328], Loss: 0.0173, Train Accuracy: 99.22%\n","Epoch [75/100], Step [323/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [75/100], Step [324/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [75/100], Step [325/328], Loss: 0.0109, Train Accuracy: 99.22%\n","Epoch [75/100], Step [326/328], Loss: 0.0162, Train Accuracy: 99.22%\n","Epoch [75/100], Step [327/328], Loss: 0.0089, Train Accuracy: 100.00%\n","Epoch [75/100], Step [328/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [76/100], Step [1/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [76/100], Step [2/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [76/100], Step [3/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [76/100], Step [4/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [76/100], Step [5/328], Loss: 0.0146, Train Accuracy: 99.22%\n","Epoch [76/100], Step [6/328], Loss: 0.0394, Train Accuracy: 97.66%\n","Epoch [76/100], Step [7/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [76/100], Step [8/328], Loss: 0.0054, Train Accuracy: 100.00%\n","Epoch [76/100], Step [9/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [76/100], Step [10/328], Loss: 0.0176, Train Accuracy: 99.22%\n","Epoch [76/100], Step [11/328], Loss: 0.0228, Train Accuracy: 99.22%\n","Epoch [76/100], Step [12/328], Loss: 0.0132, Train Accuracy: 99.22%\n","Epoch [76/100], Step [13/328], Loss: 0.0251, Train Accuracy: 99.22%\n","Epoch [76/100], Step [14/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [76/100], Step [15/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [76/100], Step [16/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [76/100], Step [17/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [76/100], Step [18/328], Loss: 0.0886, Train Accuracy: 97.66%\n","Epoch [76/100], Step [19/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [76/100], Step [20/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [76/100], Step [21/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [76/100], Step [22/328], Loss: 0.0000, Train Accuracy: 100.00%\n","Epoch [76/100], Step [23/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [76/100], Step [24/328], Loss: 0.0150, Train Accuracy: 99.22%\n","Epoch [76/100], Step [25/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [76/100], Step [26/328], Loss: 0.0149, Train Accuracy: 99.22%\n","Epoch [76/100], Step [27/328], Loss: 0.0157, Train Accuracy: 99.22%\n","Epoch [76/100], Step [28/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [76/100], Step [29/328], Loss: 0.0176, Train Accuracy: 99.22%\n","Epoch [76/100], Step [30/328], Loss: 0.0219, Train Accuracy: 99.22%\n","Epoch [76/100], Step [31/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [76/100], Step [32/328], Loss: 0.0071, Train Accuracy: 100.00%\n","Epoch [76/100], Step [33/328], Loss: 0.0109, Train Accuracy: 99.22%\n","Epoch [76/100], Step [34/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [76/100], Step [35/328], Loss: 0.0091, Train Accuracy: 100.00%\n","Epoch [76/100], Step [36/328], Loss: 0.0095, Train Accuracy: 99.22%\n","Epoch [76/100], Step [37/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [76/100], Step [38/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [76/100], Step [39/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [76/100], Step [40/328], Loss: 0.0250, Train Accuracy: 99.22%\n","Epoch [76/100], Step [41/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [76/100], Step [42/328], Loss: 0.0132, Train Accuracy: 100.00%\n","Epoch [76/100], Step [43/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [76/100], Step [44/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [76/100], Step [45/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [76/100], Step [46/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [76/100], Step [47/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [76/100], Step [48/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [76/100], Step [49/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [76/100], Step [50/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [76/100], Step [51/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [76/100], Step [52/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [76/100], Step [53/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [76/100], Step [54/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [76/100], Step [55/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [76/100], Step [56/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [76/100], Step [57/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [76/100], Step [58/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [76/100], Step [59/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [76/100], Step [60/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [76/100], Step [61/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [76/100], Step [62/328], Loss: 0.0091, Train Accuracy: 99.22%\n","Epoch [76/100], Step [63/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [76/100], Step [64/328], Loss: 0.0077, Train Accuracy: 100.00%\n","Epoch [76/100], Step [65/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [76/100], Step [66/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [76/100], Step [67/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [76/100], Step [68/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [76/100], Step [69/328], Loss: 0.0166, Train Accuracy: 99.22%\n","Epoch [76/100], Step [70/328], Loss: 0.0202, Train Accuracy: 99.22%\n","Epoch [76/100], Step [71/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [76/100], Step [72/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [76/100], Step [73/328], Loss: 0.0185, Train Accuracy: 99.22%\n","Epoch [76/100], Step [74/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [76/100], Step [75/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [76/100], Step [76/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [76/100], Step [77/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [76/100], Step [78/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [76/100], Step [79/328], Loss: 0.0164, Train Accuracy: 99.22%\n","Epoch [76/100], Step [80/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [76/100], Step [81/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [76/100], Step [82/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [76/100], Step [83/328], Loss: 0.0245, Train Accuracy: 99.22%\n","Epoch [76/100], Step [84/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [76/100], Step [85/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [76/100], Step [86/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [76/100], Step [87/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [76/100], Step [88/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [76/100], Step [89/328], Loss: 0.0140, Train Accuracy: 98.44%\n","Epoch [76/100], Step [90/328], Loss: 0.0067, Train Accuracy: 100.00%\n","Epoch [76/100], Step [91/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [76/100], Step [92/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [76/100], Step [93/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [76/100], Step [94/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [76/100], Step [95/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [76/100], Step [96/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [76/100], Step [97/328], Loss: 0.0344, Train Accuracy: 99.22%\n","Epoch [76/100], Step [98/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [76/100], Step [99/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [76/100], Step [100/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [76/100], Step [101/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [76/100], Step [102/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [76/100], Step [103/328], Loss: 0.0095, Train Accuracy: 100.00%\n","Epoch [76/100], Step [104/328], Loss: 0.0277, Train Accuracy: 99.22%\n","Epoch [76/100], Step [105/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [76/100], Step [106/328], Loss: 0.0092, Train Accuracy: 100.00%\n","Epoch [76/100], Step [107/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [76/100], Step [108/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [76/100], Step [109/328], Loss: 0.0255, Train Accuracy: 99.22%\n","Epoch [76/100], Step [110/328], Loss: 0.0379, Train Accuracy: 98.44%\n","Epoch [76/100], Step [111/328], Loss: 0.0543, Train Accuracy: 98.44%\n","Epoch [76/100], Step [112/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [76/100], Step [113/328], Loss: 0.0124, Train Accuracy: 99.22%\n","Epoch [76/100], Step [114/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [76/100], Step [115/328], Loss: 0.0268, Train Accuracy: 98.44%\n","Epoch [76/100], Step [116/328], Loss: 0.0772, Train Accuracy: 96.88%\n","Epoch [76/100], Step [117/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [76/100], Step [118/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [76/100], Step [119/328], Loss: 0.0425, Train Accuracy: 99.22%\n","Epoch [76/100], Step [120/328], Loss: 0.0744, Train Accuracy: 97.66%\n","Epoch [76/100], Step [121/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [76/100], Step [122/328], Loss: 0.0073, Train Accuracy: 100.00%\n","Epoch [76/100], Step [123/328], Loss: 0.0104, Train Accuracy: 100.00%\n","Epoch [76/100], Step [124/328], Loss: 0.0107, Train Accuracy: 100.00%\n","Epoch [76/100], Step [125/328], Loss: 0.0359, Train Accuracy: 99.22%\n","Epoch [76/100], Step [126/328], Loss: 0.0545, Train Accuracy: 98.44%\n","Epoch [76/100], Step [127/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [76/100], Step [128/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [76/100], Step [129/328], Loss: 0.0563, Train Accuracy: 97.66%\n","Epoch [76/100], Step [130/328], Loss: 0.0877, Train Accuracy: 96.88%\n","Epoch [76/100], Step [131/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [76/100], Step [132/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [76/100], Step [133/328], Loss: 0.0292, Train Accuracy: 99.22%\n","Epoch [76/100], Step [134/328], Loss: 0.0086, Train Accuracy: 99.22%\n","Epoch [76/100], Step [135/328], Loss: 0.0064, Train Accuracy: 100.00%\n","Epoch [76/100], Step [136/328], Loss: 0.0210, Train Accuracy: 99.22%\n","Epoch [76/100], Step [137/328], Loss: 0.0107, Train Accuracy: 99.22%\n","Epoch [76/100], Step [138/328], Loss: 0.0079, Train Accuracy: 100.00%\n","Epoch [76/100], Step [139/328], Loss: 0.0582, Train Accuracy: 99.22%\n","Epoch [76/100], Step [140/328], Loss: 0.0110, Train Accuracy: 100.00%\n","Epoch [76/100], Step [141/328], Loss: 0.0120, Train Accuracy: 99.22%\n","Epoch [76/100], Step [142/328], Loss: 0.0100, Train Accuracy: 99.22%\n","Epoch [76/100], Step [143/328], Loss: 0.0190, Train Accuracy: 99.22%\n","Epoch [76/100], Step [144/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [76/100], Step [145/328], Loss: 0.0378, Train Accuracy: 98.44%\n","Epoch [76/100], Step [146/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [76/100], Step [147/328], Loss: 0.0692, Train Accuracy: 99.22%\n","Epoch [76/100], Step [148/328], Loss: 0.0136, Train Accuracy: 100.00%\n","Epoch [76/100], Step [149/328], Loss: 0.0083, Train Accuracy: 100.00%\n","Epoch [76/100], Step [150/328], Loss: 0.0222, Train Accuracy: 98.44%\n","Epoch [76/100], Step [151/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [76/100], Step [152/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [76/100], Step [153/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [76/100], Step [154/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [76/100], Step [155/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [76/100], Step [156/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [76/100], Step [157/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [76/100], Step [158/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [76/100], Step [159/328], Loss: 0.0489, Train Accuracy: 97.66%\n","Epoch [76/100], Step [160/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [76/100], Step [161/328], Loss: 0.0342, Train Accuracy: 99.22%\n","Epoch [76/100], Step [162/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [76/100], Step [163/328], Loss: 0.0170, Train Accuracy: 99.22%\n","Epoch [76/100], Step [164/328], Loss: 0.0304, Train Accuracy: 98.44%\n","Epoch [76/100], Step [165/328], Loss: 0.0116, Train Accuracy: 100.00%\n","Epoch [76/100], Step [166/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [76/100], Step [167/328], Loss: 0.0179, Train Accuracy: 99.22%\n","Epoch [76/100], Step [168/328], Loss: 0.0363, Train Accuracy: 98.44%\n","Epoch [76/100], Step [169/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [76/100], Step [170/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [76/100], Step [171/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [76/100], Step [172/328], Loss: 0.0093, Train Accuracy: 100.00%\n","Epoch [76/100], Step [173/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [76/100], Step [174/328], Loss: 0.0175, Train Accuracy: 99.22%\n","Epoch [76/100], Step [175/328], Loss: 0.0110, Train Accuracy: 99.22%\n","Epoch [76/100], Step [176/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [76/100], Step [177/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [76/100], Step [178/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [76/100], Step [179/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [76/100], Step [180/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [76/100], Step [181/328], Loss: 0.0101, Train Accuracy: 99.22%\n","Epoch [76/100], Step [182/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [76/100], Step [183/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [76/100], Step [184/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [76/100], Step [185/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [76/100], Step [186/328], Loss: 0.0187, Train Accuracy: 99.22%\n","Epoch [76/100], Step [187/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [76/100], Step [188/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [76/100], Step [189/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [76/100], Step [190/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [76/100], Step [191/328], Loss: 0.0169, Train Accuracy: 99.22%\n","Epoch [76/100], Step [192/328], Loss: 0.0280, Train Accuracy: 99.22%\n","Epoch [76/100], Step [193/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [76/100], Step [194/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [76/100], Step [195/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [76/100], Step [196/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [76/100], Step [197/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [76/100], Step [198/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [76/100], Step [199/328], Loss: 0.0070, Train Accuracy: 100.00%\n","Epoch [76/100], Step [200/328], Loss: 0.0223, Train Accuracy: 98.44%\n","Epoch [76/100], Step [201/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [76/100], Step [202/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [76/100], Step [203/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [76/100], Step [204/328], Loss: 0.0097, Train Accuracy: 100.00%\n","Epoch [76/100], Step [205/328], Loss: 0.0088, Train Accuracy: 99.22%\n","Epoch [76/100], Step [206/328], Loss: 0.0554, Train Accuracy: 98.44%\n","Epoch [76/100], Step [207/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [76/100], Step [208/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [76/100], Step [209/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [76/100], Step [210/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [76/100], Step [211/328], Loss: 0.0100, Train Accuracy: 100.00%\n","Epoch [76/100], Step [212/328], Loss: 0.0098, Train Accuracy: 99.22%\n","Epoch [76/100], Step [213/328], Loss: 0.0135, Train Accuracy: 100.00%\n","Epoch [76/100], Step [214/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [76/100], Step [215/328], Loss: 0.0086, Train Accuracy: 100.00%\n","Epoch [76/100], Step [216/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [76/100], Step [217/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [76/100], Step [218/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [76/100], Step [219/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [76/100], Step [220/328], Loss: 0.0156, Train Accuracy: 99.22%\n","Epoch [76/100], Step [221/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [76/100], Step [222/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [76/100], Step [223/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [76/100], Step [224/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [76/100], Step [225/328], Loss: 0.0086, Train Accuracy: 99.22%\n","Epoch [76/100], Step [226/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [76/100], Step [227/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [76/100], Step [228/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [76/100], Step [229/328], Loss: 0.0296, Train Accuracy: 98.44%\n","Epoch [76/100], Step [230/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [76/100], Step [231/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [76/100], Step [232/328], Loss: 0.0115, Train Accuracy: 99.22%\n","Epoch [76/100], Step [233/328], Loss: 0.0071, Train Accuracy: 100.00%\n","Epoch [76/100], Step [234/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [76/100], Step [235/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [76/100], Step [236/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [76/100], Step [237/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [76/100], Step [238/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [76/100], Step [239/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [76/100], Step [240/328], Loss: 0.0249, Train Accuracy: 98.44%\n","Epoch [76/100], Step [241/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [76/100], Step [242/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [76/100], Step [243/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [76/100], Step [244/328], Loss: 0.0082, Train Accuracy: 100.00%\n","Epoch [76/100], Step [245/328], Loss: 0.0165, Train Accuracy: 99.22%\n","Epoch [76/100], Step [246/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [76/100], Step [247/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [76/100], Step [248/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [76/100], Step [249/328], Loss: 0.0290, Train Accuracy: 99.22%\n","Epoch [76/100], Step [250/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [76/100], Step [251/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [76/100], Step [252/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [76/100], Step [253/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [76/100], Step [254/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [76/100], Step [255/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [76/100], Step [256/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [76/100], Step [257/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [76/100], Step [258/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [76/100], Step [259/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [76/100], Step [260/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [76/100], Step [261/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [76/100], Step [262/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [76/100], Step [263/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [76/100], Step [264/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [76/100], Step [265/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [76/100], Step [266/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [76/100], Step [267/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [76/100], Step [268/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [76/100], Step [269/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [76/100], Step [270/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [76/100], Step [271/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [76/100], Step [272/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [76/100], Step [273/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [76/100], Step [274/328], Loss: 0.0199, Train Accuracy: 99.22%\n","Epoch [76/100], Step [275/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [76/100], Step [276/328], Loss: 0.0066, Train Accuracy: 100.00%\n","Epoch [76/100], Step [277/328], Loss: 0.0094, Train Accuracy: 99.22%\n","Epoch [76/100], Step [278/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [76/100], Step [279/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [76/100], Step [280/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [76/100], Step [281/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [76/100], Step [282/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [76/100], Step [283/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [76/100], Step [284/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [76/100], Step [285/328], Loss: 0.0062, Train Accuracy: 100.00%\n","Epoch [76/100], Step [286/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [76/100], Step [287/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [76/100], Step [288/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [76/100], Step [289/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [76/100], Step [290/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [76/100], Step [291/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [76/100], Step [292/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [76/100], Step [293/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [76/100], Step [294/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [76/100], Step [295/328], Loss: 0.0316, Train Accuracy: 99.22%\n","Epoch [76/100], Step [296/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [76/100], Step [297/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [76/100], Step [298/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [76/100], Step [299/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [76/100], Step [300/328], Loss: 0.0300, Train Accuracy: 99.22%\n","Epoch [76/100], Step [301/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [76/100], Step [302/328], Loss: 0.0264, Train Accuracy: 98.44%\n","Epoch [76/100], Step [303/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [76/100], Step [304/328], Loss: 0.0148, Train Accuracy: 99.22%\n","Epoch [76/100], Step [305/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [76/100], Step [306/328], Loss: 0.0410, Train Accuracy: 99.22%\n","Epoch [76/100], Step [307/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [76/100], Step [308/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [76/100], Step [309/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [76/100], Step [310/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [76/100], Step [311/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [76/100], Step [312/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [76/100], Step [313/328], Loss: 0.0267, Train Accuracy: 99.22%\n","Epoch [76/100], Step [314/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [76/100], Step [315/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [76/100], Step [316/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [76/100], Step [317/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [76/100], Step [318/328], Loss: 0.0094, Train Accuracy: 100.00%\n","Epoch [76/100], Step [319/328], Loss: 0.0453, Train Accuracy: 99.22%\n","Epoch [76/100], Step [320/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [76/100], Step [321/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [76/100], Step [322/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [76/100], Step [323/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [76/100], Step [324/328], Loss: 0.0104, Train Accuracy: 100.00%\n","Epoch [76/100], Step [325/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [76/100], Step [326/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [76/100], Step [327/328], Loss: 0.0182, Train Accuracy: 99.22%\n","Epoch [76/100], Step [328/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [77/100], Step [1/328], Loss: 0.0066, Train Accuracy: 99.22%\n","Epoch [77/100], Step [2/328], Loss: 0.0126, Train Accuracy: 99.22%\n","Epoch [77/100], Step [3/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [77/100], Step [4/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [77/100], Step [5/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [77/100], Step [6/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [77/100], Step [7/328], Loss: 0.0089, Train Accuracy: 100.00%\n","Epoch [77/100], Step [8/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [77/100], Step [9/328], Loss: 0.0105, Train Accuracy: 99.22%\n","Epoch [77/100], Step [10/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [77/100], Step [11/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [77/100], Step [12/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [77/100], Step [13/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [77/100], Step [14/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [77/100], Step [15/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [77/100], Step [16/328], Loss: 0.0166, Train Accuracy: 99.22%\n","Epoch [77/100], Step [17/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [77/100], Step [18/328], Loss: 0.0371, Train Accuracy: 98.44%\n","Epoch [77/100], Step [19/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [77/100], Step [20/328], Loss: 0.0063, Train Accuracy: 100.00%\n","Epoch [77/100], Step [21/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [77/100], Step [22/328], Loss: 0.0234, Train Accuracy: 99.22%\n","Epoch [77/100], Step [23/328], Loss: 0.0120, Train Accuracy: 100.00%\n","Epoch [77/100], Step [24/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [77/100], Step [25/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [77/100], Step [26/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [77/100], Step [27/328], Loss: 0.0151, Train Accuracy: 99.22%\n","Epoch [77/100], Step [28/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [77/100], Step [29/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [77/100], Step [30/328], Loss: 0.0167, Train Accuracy: 99.22%\n","Epoch [77/100], Step [31/328], Loss: 0.0078, Train Accuracy: 99.22%\n","Epoch [77/100], Step [32/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [77/100], Step [33/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [77/100], Step [34/328], Loss: 0.0119, Train Accuracy: 99.22%\n","Epoch [77/100], Step [35/328], Loss: 0.0070, Train Accuracy: 100.00%\n","Epoch [77/100], Step [36/328], Loss: 0.0473, Train Accuracy: 99.22%\n","Epoch [77/100], Step [37/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [77/100], Step [38/328], Loss: 0.0112, Train Accuracy: 99.22%\n","Epoch [77/100], Step [39/328], Loss: 0.0172, Train Accuracy: 99.22%\n","Epoch [77/100], Step [40/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [77/100], Step [41/328], Loss: 0.0160, Train Accuracy: 99.22%\n","Epoch [77/100], Step [42/328], Loss: 0.0089, Train Accuracy: 99.22%\n","Epoch [77/100], Step [43/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [77/100], Step [44/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [77/100], Step [45/328], Loss: 0.0145, Train Accuracy: 99.22%\n","Epoch [77/100], Step [46/328], Loss: 0.0065, Train Accuracy: 100.00%\n","Epoch [77/100], Step [47/328], Loss: 0.0060, Train Accuracy: 100.00%\n","Epoch [77/100], Step [48/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [77/100], Step [49/328], Loss: 0.0091, Train Accuracy: 99.22%\n","Epoch [77/100], Step [50/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [77/100], Step [51/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [77/100], Step [52/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [77/100], Step [53/328], Loss: 0.0125, Train Accuracy: 99.22%\n","Epoch [77/100], Step [54/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [77/100], Step [55/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [77/100], Step [56/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [77/100], Step [57/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [77/100], Step [58/328], Loss: 0.0205, Train Accuracy: 99.22%\n","Epoch [77/100], Step [59/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [77/100], Step [60/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [77/100], Step [61/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [77/100], Step [62/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [77/100], Step [63/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [77/100], Step [64/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [77/100], Step [65/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [77/100], Step [66/328], Loss: 0.0170, Train Accuracy: 99.22%\n","Epoch [77/100], Step [67/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [77/100], Step [68/328], Loss: 0.0126, Train Accuracy: 99.22%\n","Epoch [77/100], Step [69/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [77/100], Step [70/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [77/100], Step [71/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [77/100], Step [72/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [77/100], Step [73/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [77/100], Step [74/328], Loss: 0.0294, Train Accuracy: 99.22%\n","Epoch [77/100], Step [75/328], Loss: 0.0187, Train Accuracy: 99.22%\n","Epoch [77/100], Step [76/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [77/100], Step [77/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [77/100], Step [78/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [77/100], Step [79/328], Loss: 0.0179, Train Accuracy: 100.00%\n","Epoch [77/100], Step [80/328], Loss: 0.0118, Train Accuracy: 99.22%\n","Epoch [77/100], Step [81/328], Loss: 0.0059, Train Accuracy: 100.00%\n","Epoch [77/100], Step [82/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [77/100], Step [83/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [77/100], Step [84/328], Loss: 0.0181, Train Accuracy: 98.44%\n","Epoch [77/100], Step [85/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [77/100], Step [86/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [77/100], Step [87/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [77/100], Step [88/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [77/100], Step [89/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [77/100], Step [90/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [77/100], Step [91/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [77/100], Step [92/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [77/100], Step [93/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [77/100], Step [94/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [77/100], Step [95/328], Loss: 0.0076, Train Accuracy: 100.00%\n","Epoch [77/100], Step [96/328], Loss: 0.0109, Train Accuracy: 99.22%\n","Epoch [77/100], Step [97/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [77/100], Step [98/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [77/100], Step [99/328], Loss: 0.0097, Train Accuracy: 99.22%\n","Epoch [77/100], Step [100/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [77/100], Step [101/328], Loss: 0.0090, Train Accuracy: 99.22%\n","Epoch [77/100], Step [102/328], Loss: 0.0062, Train Accuracy: 100.00%\n","Epoch [77/100], Step [103/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [77/100], Step [104/328], Loss: 0.0062, Train Accuracy: 100.00%\n","Epoch [77/100], Step [105/328], Loss: 0.0361, Train Accuracy: 99.22%\n","Epoch [77/100], Step [106/328], Loss: 0.0159, Train Accuracy: 99.22%\n","Epoch [77/100], Step [107/328], Loss: 0.0140, Train Accuracy: 99.22%\n","Epoch [77/100], Step [108/328], Loss: 0.0125, Train Accuracy: 100.00%\n","Epoch [77/100], Step [109/328], Loss: 0.0060, Train Accuracy: 100.00%\n","Epoch [77/100], Step [110/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [77/100], Step [111/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [77/100], Step [112/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [77/100], Step [113/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [77/100], Step [114/328], Loss: 0.0096, Train Accuracy: 100.00%\n","Epoch [77/100], Step [115/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [77/100], Step [116/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [77/100], Step [117/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [77/100], Step [118/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [77/100], Step [119/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [77/100], Step [120/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [77/100], Step [121/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [77/100], Step [122/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [77/100], Step [123/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [77/100], Step [124/328], Loss: 0.0079, Train Accuracy: 99.22%\n","Epoch [77/100], Step [125/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [77/100], Step [126/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [77/100], Step [127/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [77/100], Step [128/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [77/100], Step [129/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [77/100], Step [130/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [77/100], Step [131/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [77/100], Step [132/328], Loss: 0.0064, Train Accuracy: 100.00%\n","Epoch [77/100], Step [133/328], Loss: 0.0173, Train Accuracy: 99.22%\n","Epoch [77/100], Step [134/328], Loss: 0.0168, Train Accuracy: 99.22%\n","Epoch [77/100], Step [135/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [77/100], Step [136/328], Loss: 0.0105, Train Accuracy: 99.22%\n","Epoch [77/100], Step [137/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [77/100], Step [138/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [77/100], Step [139/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [77/100], Step [140/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [77/100], Step [141/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [77/100], Step [142/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [77/100], Step [143/328], Loss: 0.0067, Train Accuracy: 100.00%\n","Epoch [77/100], Step [144/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [77/100], Step [145/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [77/100], Step [146/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [77/100], Step [147/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [77/100], Step [148/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [77/100], Step [149/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [77/100], Step [150/328], Loss: 0.0048, Train Accuracy: 100.00%\n","Epoch [77/100], Step [151/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [77/100], Step [152/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [77/100], Step [153/328], Loss: 0.0357, Train Accuracy: 99.22%\n","Epoch [77/100], Step [154/328], Loss: 0.0210, Train Accuracy: 99.22%\n","Epoch [77/100], Step [155/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [77/100], Step [156/328], Loss: 0.0097, Train Accuracy: 100.00%\n","Epoch [77/100], Step [157/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [77/100], Step [158/328], Loss: 0.0740, Train Accuracy: 98.44%\n","Epoch [77/100], Step [159/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [77/100], Step [160/328], Loss: 0.0062, Train Accuracy: 100.00%\n","Epoch [77/100], Step [161/328], Loss: 0.0590, Train Accuracy: 99.22%\n","Epoch [77/100], Step [162/328], Loss: 0.0180, Train Accuracy: 99.22%\n","Epoch [77/100], Step [163/328], Loss: 0.0267, Train Accuracy: 98.44%\n","Epoch [77/100], Step [164/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [77/100], Step [165/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [77/100], Step [166/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [77/100], Step [167/328], Loss: 0.0511, Train Accuracy: 97.66%\n","Epoch [77/100], Step [168/328], Loss: 0.0059, Train Accuracy: 100.00%\n","Epoch [77/100], Step [169/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [77/100], Step [170/328], Loss: 0.0184, Train Accuracy: 98.44%\n","Epoch [77/100], Step [171/328], Loss: 0.0669, Train Accuracy: 98.44%\n","Epoch [77/100], Step [172/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [77/100], Step [173/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [77/100], Step [174/328], Loss: 0.0208, Train Accuracy: 98.44%\n","Epoch [77/100], Step [175/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [77/100], Step [176/328], Loss: 0.0326, Train Accuracy: 99.22%\n","Epoch [77/100], Step [177/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [77/100], Step [178/328], Loss: 0.1321, Train Accuracy: 96.88%\n","Epoch [77/100], Step [179/328], Loss: 0.0184, Train Accuracy: 99.22%\n","Epoch [77/100], Step [180/328], Loss: 0.0321, Train Accuracy: 99.22%\n","Epoch [77/100], Step [181/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [77/100], Step [182/328], Loss: 0.0185, Train Accuracy: 99.22%\n","Epoch [77/100], Step [183/328], Loss: 0.0312, Train Accuracy: 98.44%\n","Epoch [77/100], Step [184/328], Loss: 0.0225, Train Accuracy: 98.44%\n","Epoch [77/100], Step [185/328], Loss: 0.0114, Train Accuracy: 99.22%\n","Epoch [77/100], Step [186/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [77/100], Step [187/328], Loss: 0.0085, Train Accuracy: 100.00%\n","Epoch [77/100], Step [188/328], Loss: 0.0830, Train Accuracy: 96.09%\n","Epoch [77/100], Step [189/328], Loss: 0.0371, Train Accuracy: 98.44%\n","Epoch [77/100], Step [190/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [77/100], Step [191/328], Loss: 0.0289, Train Accuracy: 99.22%\n","Epoch [77/100], Step [192/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [77/100], Step [193/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [77/100], Step [194/328], Loss: 0.0317, Train Accuracy: 98.44%\n","Epoch [77/100], Step [195/328], Loss: 0.0092, Train Accuracy: 100.00%\n","Epoch [77/100], Step [196/328], Loss: 0.0214, Train Accuracy: 98.44%\n","Epoch [77/100], Step [197/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [77/100], Step [198/328], Loss: 0.0065, Train Accuracy: 100.00%\n","Epoch [77/100], Step [199/328], Loss: 0.0103, Train Accuracy: 99.22%\n","Epoch [77/100], Step [200/328], Loss: 0.0176, Train Accuracy: 99.22%\n","Epoch [77/100], Step [201/328], Loss: 0.0519, Train Accuracy: 98.44%\n","Epoch [77/100], Step [202/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [77/100], Step [203/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [77/100], Step [204/328], Loss: 0.0227, Train Accuracy: 99.22%\n","Epoch [77/100], Step [205/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [77/100], Step [206/328], Loss: 0.0818, Train Accuracy: 98.44%\n","Epoch [77/100], Step [207/328], Loss: 0.0141, Train Accuracy: 99.22%\n","Epoch [77/100], Step [208/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [77/100], Step [209/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [77/100], Step [210/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [77/100], Step [211/328], Loss: 0.0105, Train Accuracy: 100.00%\n","Epoch [77/100], Step [212/328], Loss: 0.0458, Train Accuracy: 99.22%\n","Epoch [77/100], Step [213/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [77/100], Step [214/328], Loss: 0.0185, Train Accuracy: 99.22%\n","Epoch [77/100], Step [215/328], Loss: 0.0625, Train Accuracy: 98.44%\n","Epoch [77/100], Step [216/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [77/100], Step [217/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [77/100], Step [218/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [77/100], Step [219/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [77/100], Step [220/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [77/100], Step [221/328], Loss: 0.0130, Train Accuracy: 98.44%\n","Epoch [77/100], Step [222/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [77/100], Step [223/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [77/100], Step [224/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [77/100], Step [225/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [77/100], Step [226/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [77/100], Step [227/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [77/100], Step [228/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [77/100], Step [229/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [77/100], Step [230/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [77/100], Step [231/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [77/100], Step [232/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [77/100], Step [233/328], Loss: 0.0090, Train Accuracy: 100.00%\n","Epoch [77/100], Step [234/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [77/100], Step [235/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [77/100], Step [236/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [77/100], Step [237/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [77/100], Step [238/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [77/100], Step [239/328], Loss: 0.0204, Train Accuracy: 99.22%\n","Epoch [77/100], Step [240/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [77/100], Step [241/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [77/100], Step [242/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [77/100], Step [243/328], Loss: 0.0108, Train Accuracy: 99.22%\n","Epoch [77/100], Step [244/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [77/100], Step [245/328], Loss: 0.0070, Train Accuracy: 99.22%\n","Epoch [77/100], Step [246/328], Loss: 0.0094, Train Accuracy: 100.00%\n","Epoch [77/100], Step [247/328], Loss: 0.0054, Train Accuracy: 100.00%\n","Epoch [77/100], Step [248/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [77/100], Step [249/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [77/100], Step [250/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [77/100], Step [251/328], Loss: 0.0184, Train Accuracy: 99.22%\n","Epoch [77/100], Step [252/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [77/100], Step [253/328], Loss: 0.0074, Train Accuracy: 99.22%\n","Epoch [77/100], Step [254/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [77/100], Step [255/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [77/100], Step [256/328], Loss: 0.0110, Train Accuracy: 100.00%\n","Epoch [77/100], Step [257/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [77/100], Step [258/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [77/100], Step [259/328], Loss: 0.0105, Train Accuracy: 99.22%\n","Epoch [77/100], Step [260/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [77/100], Step [261/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [77/100], Step [262/328], Loss: 0.0066, Train Accuracy: 100.00%\n","Epoch [77/100], Step [263/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [77/100], Step [264/328], Loss: 0.0210, Train Accuracy: 99.22%\n","Epoch [77/100], Step [265/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [77/100], Step [266/328], Loss: 0.0110, Train Accuracy: 99.22%\n","Epoch [77/100], Step [267/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [77/100], Step [268/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [77/100], Step [269/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [77/100], Step [270/328], Loss: 0.0167, Train Accuracy: 98.44%\n","Epoch [77/100], Step [271/328], Loss: 0.0512, Train Accuracy: 99.22%\n","Epoch [77/100], Step [272/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [77/100], Step [273/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [77/100], Step [274/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [77/100], Step [275/328], Loss: 0.0110, Train Accuracy: 99.22%\n","Epoch [77/100], Step [276/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [77/100], Step [277/328], Loss: 0.0439, Train Accuracy: 97.66%\n","Epoch [77/100], Step [278/328], Loss: 0.0418, Train Accuracy: 99.22%\n","Epoch [77/100], Step [279/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [77/100], Step [280/328], Loss: 0.0262, Train Accuracy: 99.22%\n","Epoch [77/100], Step [281/328], Loss: 0.0074, Train Accuracy: 100.00%\n","Epoch [77/100], Step [282/328], Loss: 0.1305, Train Accuracy: 97.66%\n","Epoch [77/100], Step [283/328], Loss: 0.0458, Train Accuracy: 99.22%\n","Epoch [77/100], Step [284/328], Loss: 0.0139, Train Accuracy: 98.44%\n","Epoch [77/100], Step [285/328], Loss: 0.0382, Train Accuracy: 99.22%\n","Epoch [77/100], Step [286/328], Loss: 0.0587, Train Accuracy: 98.44%\n","Epoch [77/100], Step [287/328], Loss: 0.1077, Train Accuracy: 96.09%\n","Epoch [77/100], Step [288/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [77/100], Step [289/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [77/100], Step [290/328], Loss: 0.0090, Train Accuracy: 99.22%\n","Epoch [77/100], Step [291/328], Loss: 0.0207, Train Accuracy: 99.22%\n","Epoch [77/100], Step [292/328], Loss: 0.0553, Train Accuracy: 97.66%\n","Epoch [77/100], Step [293/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [77/100], Step [294/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [77/100], Step [295/328], Loss: 0.0448, Train Accuracy: 98.44%\n","Epoch [77/100], Step [296/328], Loss: 0.0217, Train Accuracy: 99.22%\n","Epoch [77/100], Step [297/328], Loss: 0.0519, Train Accuracy: 98.44%\n","Epoch [77/100], Step [298/328], Loss: 0.0178, Train Accuracy: 98.44%\n","Epoch [77/100], Step [299/328], Loss: 0.0192, Train Accuracy: 99.22%\n","Epoch [77/100], Step [300/328], Loss: 0.0477, Train Accuracy: 97.66%\n","Epoch [77/100], Step [301/328], Loss: 0.0258, Train Accuracy: 99.22%\n","Epoch [77/100], Step [302/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [77/100], Step [303/328], Loss: 0.0147, Train Accuracy: 99.22%\n","Epoch [77/100], Step [304/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [77/100], Step [305/328], Loss: 0.0122, Train Accuracy: 99.22%\n","Epoch [77/100], Step [306/328], Loss: 0.0809, Train Accuracy: 99.22%\n","Epoch [77/100], Step [307/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [77/100], Step [308/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [77/100], Step [309/328], Loss: 0.0152, Train Accuracy: 100.00%\n","Epoch [77/100], Step [310/328], Loss: 0.0295, Train Accuracy: 99.22%\n","Epoch [77/100], Step [311/328], Loss: 0.0129, Train Accuracy: 99.22%\n","Epoch [77/100], Step [312/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [77/100], Step [313/328], Loss: 0.0159, Train Accuracy: 98.44%\n","Epoch [77/100], Step [314/328], Loss: 0.0172, Train Accuracy: 99.22%\n","Epoch [77/100], Step [315/328], Loss: 0.0484, Train Accuracy: 98.44%\n","Epoch [77/100], Step [316/328], Loss: 0.0345, Train Accuracy: 99.22%\n","Epoch [77/100], Step [317/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [77/100], Step [318/328], Loss: 0.0122, Train Accuracy: 99.22%\n","Epoch [77/100], Step [319/328], Loss: 0.0607, Train Accuracy: 96.88%\n","Epoch [77/100], Step [320/328], Loss: 0.0867, Train Accuracy: 95.31%\n","Epoch [77/100], Step [321/328], Loss: 0.0338, Train Accuracy: 99.22%\n","Epoch [77/100], Step [322/328], Loss: 0.0207, Train Accuracy: 98.44%\n","Epoch [77/100], Step [323/328], Loss: 0.1651, Train Accuracy: 96.88%\n","Epoch [77/100], Step [324/328], Loss: 0.2926, Train Accuracy: 95.31%\n","Epoch [77/100], Step [325/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [77/100], Step [326/328], Loss: 0.0402, Train Accuracy: 99.22%\n","Epoch [77/100], Step [327/328], Loss: 0.0770, Train Accuracy: 97.66%\n","Epoch [77/100], Step [328/328], Loss: 0.0260, Train Accuracy: 98.75%\n","Epoch [78/100], Step [1/328], Loss: 0.0102, Train Accuracy: 100.00%\n","Epoch [78/100], Step [2/328], Loss: 0.0126, Train Accuracy: 100.00%\n","Epoch [78/100], Step [3/328], Loss: 0.0321, Train Accuracy: 98.44%\n","Epoch [78/100], Step [4/328], Loss: 0.0109, Train Accuracy: 100.00%\n","Epoch [78/100], Step [5/328], Loss: 0.1327, Train Accuracy: 96.88%\n","Epoch [78/100], Step [6/328], Loss: 0.0748, Train Accuracy: 96.88%\n","Epoch [78/100], Step [7/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [78/100], Step [8/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [78/100], Step [9/328], Loss: 0.0291, Train Accuracy: 98.44%\n","Epoch [78/100], Step [10/328], Loss: 0.0702, Train Accuracy: 97.66%\n","Epoch [78/100], Step [11/328], Loss: 0.0068, Train Accuracy: 100.00%\n","Epoch [78/100], Step [12/328], Loss: 0.0083, Train Accuracy: 99.22%\n","Epoch [78/100], Step [13/328], Loss: 0.1191, Train Accuracy: 97.66%\n","Epoch [78/100], Step [14/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [78/100], Step [15/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [78/100], Step [16/328], Loss: 0.0077, Train Accuracy: 100.00%\n","Epoch [78/100], Step [17/328], Loss: 0.0115, Train Accuracy: 99.22%\n","Epoch [78/100], Step [18/328], Loss: 0.0082, Train Accuracy: 100.00%\n","Epoch [78/100], Step [19/328], Loss: 0.0259, Train Accuracy: 98.44%\n","Epoch [78/100], Step [20/328], Loss: 0.0093, Train Accuracy: 100.00%\n","Epoch [78/100], Step [21/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [78/100], Step [22/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [78/100], Step [23/328], Loss: 0.0097, Train Accuracy: 100.00%\n","Epoch [78/100], Step [24/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [78/100], Step [25/328], Loss: 0.0059, Train Accuracy: 100.00%\n","Epoch [78/100], Step [26/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [78/100], Step [27/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [78/100], Step [28/328], Loss: 0.0141, Train Accuracy: 99.22%\n","Epoch [78/100], Step [29/328], Loss: 0.0075, Train Accuracy: 99.22%\n","Epoch [78/100], Step [30/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [78/100], Step [31/328], Loss: 0.0066, Train Accuracy: 100.00%\n","Epoch [78/100], Step [32/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [78/100], Step [33/328], Loss: 0.0119, Train Accuracy: 99.22%\n","Epoch [78/100], Step [34/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [78/100], Step [35/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [78/100], Step [36/328], Loss: 0.0172, Train Accuracy: 98.44%\n","Epoch [78/100], Step [37/328], Loss: 0.0109, Train Accuracy: 99.22%\n","Epoch [78/100], Step [38/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [78/100], Step [39/328], Loss: 0.0446, Train Accuracy: 97.66%\n","Epoch [78/100], Step [40/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [78/100], Step [41/328], Loss: 0.0073, Train Accuracy: 99.22%\n","Epoch [78/100], Step [42/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [78/100], Step [43/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [78/100], Step [44/328], Loss: 0.0368, Train Accuracy: 99.22%\n","Epoch [78/100], Step [45/328], Loss: 0.0183, Train Accuracy: 99.22%\n","Epoch [78/100], Step [46/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [78/100], Step [47/328], Loss: 0.0314, Train Accuracy: 98.44%\n","Epoch [78/100], Step [48/328], Loss: 0.0140, Train Accuracy: 100.00%\n","Epoch [78/100], Step [49/328], Loss: 0.0127, Train Accuracy: 99.22%\n","Epoch [78/100], Step [50/328], Loss: 0.0094, Train Accuracy: 100.00%\n","Epoch [78/100], Step [51/328], Loss: 0.0279, Train Accuracy: 99.22%\n","Epoch [78/100], Step [52/328], Loss: 0.0073, Train Accuracy: 100.00%\n","Epoch [78/100], Step [53/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [78/100], Step [54/328], Loss: 0.0111, Train Accuracy: 99.22%\n","Epoch [78/100], Step [55/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [78/100], Step [56/328], Loss: 0.0096, Train Accuracy: 99.22%\n","Epoch [78/100], Step [57/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [78/100], Step [58/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [78/100], Step [59/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [78/100], Step [60/328], Loss: 0.0142, Train Accuracy: 99.22%\n","Epoch [78/100], Step [61/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [78/100], Step [62/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [78/100], Step [63/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [78/100], Step [64/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [78/100], Step [65/328], Loss: 0.0107, Train Accuracy: 99.22%\n","Epoch [78/100], Step [66/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [78/100], Step [67/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [78/100], Step [68/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [78/100], Step [69/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [78/100], Step [70/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [78/100], Step [71/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [78/100], Step [72/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [78/100], Step [73/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [78/100], Step [74/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [78/100], Step [75/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [78/100], Step [76/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [78/100], Step [77/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [78/100], Step [78/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [78/100], Step [79/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [78/100], Step [80/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [78/100], Step [81/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [78/100], Step [82/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [78/100], Step [83/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [78/100], Step [84/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [78/100], Step [85/328], Loss: 0.0063, Train Accuracy: 100.00%\n","Epoch [78/100], Step [86/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [78/100], Step [87/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [78/100], Step [88/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [78/100], Step [89/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [78/100], Step [90/328], Loss: 0.0063, Train Accuracy: 100.00%\n","Epoch [78/100], Step [91/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [78/100], Step [92/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [78/100], Step [93/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [78/100], Step [94/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [78/100], Step [95/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [78/100], Step [96/328], Loss: 0.0199, Train Accuracy: 99.22%\n","Epoch [78/100], Step [97/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [78/100], Step [98/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [78/100], Step [99/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [78/100], Step [100/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [78/100], Step [101/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [78/100], Step [102/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [78/100], Step [103/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [78/100], Step [104/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [78/100], Step [105/328], Loss: 0.0126, Train Accuracy: 99.22%\n","Epoch [78/100], Step [106/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [78/100], Step [107/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [78/100], Step [108/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [78/100], Step [109/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [78/100], Step [110/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [78/100], Step [111/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [78/100], Step [112/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [78/100], Step [113/328], Loss: 0.0097, Train Accuracy: 100.00%\n","Epoch [78/100], Step [114/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [78/100], Step [115/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [78/100], Step [116/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [78/100], Step [117/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [78/100], Step [118/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [78/100], Step [119/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [78/100], Step [120/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [78/100], Step [121/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [78/100], Step [122/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [78/100], Step [123/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [78/100], Step [124/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [78/100], Step [125/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [78/100], Step [126/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [78/100], Step [127/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [78/100], Step [128/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [78/100], Step [129/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [78/100], Step [130/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [78/100], Step [131/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [78/100], Step [132/328], Loss: 0.0182, Train Accuracy: 99.22%\n","Epoch [78/100], Step [133/328], Loss: 0.0070, Train Accuracy: 100.00%\n","Epoch [78/100], Step [134/328], Loss: 0.0104, Train Accuracy: 99.22%\n","Epoch [78/100], Step [135/328], Loss: 0.0135, Train Accuracy: 99.22%\n","Epoch [78/100], Step [136/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [78/100], Step [137/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [78/100], Step [138/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [78/100], Step [139/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [78/100], Step [140/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [78/100], Step [141/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [78/100], Step [142/328], Loss: 0.0168, Train Accuracy: 99.22%\n","Epoch [78/100], Step [143/328], Loss: 0.0083, Train Accuracy: 100.00%\n","Epoch [78/100], Step [144/328], Loss: 0.0178, Train Accuracy: 98.44%\n","Epoch [78/100], Step [145/328], Loss: 0.0071, Train Accuracy: 99.22%\n","Epoch [78/100], Step [146/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [78/100], Step [147/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [78/100], Step [148/328], Loss: 0.0063, Train Accuracy: 100.00%\n","Epoch [78/100], Step [149/328], Loss: 0.0113, Train Accuracy: 100.00%\n","Epoch [78/100], Step [150/328], Loss: 0.0064, Train Accuracy: 100.00%\n","Epoch [78/100], Step [151/328], Loss: 0.0085, Train Accuracy: 100.00%\n","Epoch [78/100], Step [152/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [78/100], Step [153/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [78/100], Step [154/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [78/100], Step [155/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [78/100], Step [156/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [78/100], Step [157/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [78/100], Step [158/328], Loss: 0.0063, Train Accuracy: 99.22%\n","Epoch [78/100], Step [159/328], Loss: 0.0169, Train Accuracy: 99.22%\n","Epoch [78/100], Step [160/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [78/100], Step [161/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [78/100], Step [162/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [78/100], Step [163/328], Loss: 0.0112, Train Accuracy: 99.22%\n","Epoch [78/100], Step [164/328], Loss: 0.0069, Train Accuracy: 100.00%\n","Epoch [78/100], Step [165/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [78/100], Step [166/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [78/100], Step [167/328], Loss: 0.0344, Train Accuracy: 97.66%\n","Epoch [78/100], Step [168/328], Loss: 0.0075, Train Accuracy: 100.00%\n","Epoch [78/100], Step [169/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [78/100], Step [170/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [78/100], Step [171/328], Loss: 0.0064, Train Accuracy: 99.22%\n","Epoch [78/100], Step [172/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [78/100], Step [173/328], Loss: 0.0067, Train Accuracy: 100.00%\n","Epoch [78/100], Step [174/328], Loss: 0.0062, Train Accuracy: 100.00%\n","Epoch [78/100], Step [175/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [78/100], Step [176/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [78/100], Step [177/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [78/100], Step [178/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [78/100], Step [179/328], Loss: 0.0081, Train Accuracy: 100.00%\n","Epoch [78/100], Step [180/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [78/100], Step [181/328], Loss: 0.0125, Train Accuracy: 99.22%\n","Epoch [78/100], Step [182/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [78/100], Step [183/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [78/100], Step [184/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [78/100], Step [185/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [78/100], Step [186/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [78/100], Step [187/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [78/100], Step [188/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [78/100], Step [189/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [78/100], Step [190/328], Loss: 0.0134, Train Accuracy: 99.22%\n","Epoch [78/100], Step [191/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [78/100], Step [192/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [78/100], Step [193/328], Loss: 0.0092, Train Accuracy: 99.22%\n","Epoch [78/100], Step [194/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [78/100], Step [195/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [78/100], Step [196/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [78/100], Step [197/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [78/100], Step [198/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [78/100], Step [199/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [78/100], Step [200/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [78/100], Step [201/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [78/100], Step [202/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [78/100], Step [203/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [78/100], Step [204/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [78/100], Step [205/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [78/100], Step [206/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [78/100], Step [207/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [78/100], Step [208/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [78/100], Step [209/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [78/100], Step [210/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [78/100], Step [211/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [78/100], Step [212/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [78/100], Step [213/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [78/100], Step [214/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [78/100], Step [215/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [78/100], Step [216/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [78/100], Step [217/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [78/100], Step [218/328], Loss: 0.0067, Train Accuracy: 99.22%\n","Epoch [78/100], Step [219/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [78/100], Step [220/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [78/100], Step [221/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [78/100], Step [222/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [78/100], Step [223/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [78/100], Step [224/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [78/100], Step [225/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [78/100], Step [226/328], Loss: 0.0092, Train Accuracy: 99.22%\n","Epoch [78/100], Step [227/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [78/100], Step [228/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [78/100], Step [229/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [78/100], Step [230/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [78/100], Step [231/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [78/100], Step [232/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [78/100], Step [233/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [78/100], Step [234/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [78/100], Step [235/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [78/100], Step [236/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [78/100], Step [237/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [78/100], Step [238/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [78/100], Step [239/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [78/100], Step [240/328], Loss: 0.0070, Train Accuracy: 99.22%\n","Epoch [78/100], Step [241/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [78/100], Step [242/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [78/100], Step [243/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [78/100], Step [244/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [78/100], Step [245/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [78/100], Step [246/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [78/100], Step [247/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [78/100], Step [248/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [78/100], Step [249/328], Loss: 0.0069, Train Accuracy: 100.00%\n","Epoch [78/100], Step [250/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [78/100], Step [251/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [78/100], Step [252/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [78/100], Step [253/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [78/100], Step [254/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [78/100], Step [255/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [78/100], Step [256/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [78/100], Step [257/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [78/100], Step [258/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [78/100], Step [259/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [78/100], Step [260/328], Loss: 0.0086, Train Accuracy: 99.22%\n","Epoch [78/100], Step [261/328], Loss: 0.0156, Train Accuracy: 99.22%\n","Epoch [78/100], Step [262/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [78/100], Step [263/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [78/100], Step [264/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [78/100], Step [265/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [78/100], Step [266/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [78/100], Step [267/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [78/100], Step [268/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [78/100], Step [269/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [78/100], Step [270/328], Loss: 0.0166, Train Accuracy: 99.22%\n","Epoch [78/100], Step [271/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [78/100], Step [272/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [78/100], Step [273/328], Loss: 0.0832, Train Accuracy: 98.44%\n","Epoch [78/100], Step [274/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [78/100], Step [275/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [78/100], Step [276/328], Loss: 0.0091, Train Accuracy: 100.00%\n","Epoch [78/100], Step [277/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [78/100], Step [278/328], Loss: 0.0076, Train Accuracy: 100.00%\n","Epoch [78/100], Step [279/328], Loss: 0.0067, Train Accuracy: 100.00%\n","Epoch [78/100], Step [280/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [78/100], Step [281/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [78/100], Step [282/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [78/100], Step [283/328], Loss: 0.1476, Train Accuracy: 98.44%\n","Epoch [78/100], Step [284/328], Loss: 0.0223, Train Accuracy: 99.22%\n","Epoch [78/100], Step [285/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [78/100], Step [286/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [78/100], Step [287/328], Loss: 0.0116, Train Accuracy: 99.22%\n","Epoch [78/100], Step [288/328], Loss: 0.0070, Train Accuracy: 100.00%\n","Epoch [78/100], Step [289/328], Loss: 0.0132, Train Accuracy: 99.22%\n","Epoch [78/100], Step [290/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [78/100], Step [291/328], Loss: 0.0131, Train Accuracy: 99.22%\n","Epoch [78/100], Step [292/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [78/100], Step [293/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [78/100], Step [294/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [78/100], Step [295/328], Loss: 0.0112, Train Accuracy: 99.22%\n","Epoch [78/100], Step [296/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [78/100], Step [297/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [78/100], Step [298/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [78/100], Step [299/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [78/100], Step [300/328], Loss: 0.0105, Train Accuracy: 99.22%\n","Epoch [78/100], Step [301/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [78/100], Step [302/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [78/100], Step [303/328], Loss: 0.0075, Train Accuracy: 100.00%\n","Epoch [78/100], Step [304/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [78/100], Step [305/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [78/100], Step [306/328], Loss: 0.0104, Train Accuracy: 100.00%\n","Epoch [78/100], Step [307/328], Loss: 0.0158, Train Accuracy: 99.22%\n","Epoch [78/100], Step [308/328], Loss: 0.0072, Train Accuracy: 100.00%\n","Epoch [78/100], Step [309/328], Loss: 0.0064, Train Accuracy: 100.00%\n","Epoch [78/100], Step [310/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [78/100], Step [311/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [78/100], Step [312/328], Loss: 0.0183, Train Accuracy: 99.22%\n","Epoch [78/100], Step [313/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [78/100], Step [314/328], Loss: 0.0084, Train Accuracy: 100.00%\n","Epoch [78/100], Step [315/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [78/100], Step [316/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [78/100], Step [317/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [78/100], Step [318/328], Loss: 0.0070, Train Accuracy: 100.00%\n","Epoch [78/100], Step [319/328], Loss: 0.0185, Train Accuracy: 99.22%\n","Epoch [78/100], Step [320/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [78/100], Step [321/328], Loss: 0.0149, Train Accuracy: 99.22%\n","Epoch [78/100], Step [322/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [78/100], Step [323/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [78/100], Step [324/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [78/100], Step [325/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [78/100], Step [326/328], Loss: 0.0471, Train Accuracy: 98.44%\n","Epoch [78/100], Step [327/328], Loss: 0.0085, Train Accuracy: 99.22%\n","Epoch [78/100], Step [328/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [79/100], Step [1/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [79/100], Step [2/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [79/100], Step [3/328], Loss: 0.0067, Train Accuracy: 100.00%\n","Epoch [79/100], Step [4/328], Loss: 0.0101, Train Accuracy: 99.22%\n","Epoch [79/100], Step [5/328], Loss: 0.0183, Train Accuracy: 99.22%\n","Epoch [79/100], Step [6/328], Loss: 0.0119, Train Accuracy: 100.00%\n","Epoch [79/100], Step [7/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [79/100], Step [8/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [79/100], Step [9/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [79/100], Step [10/328], Loss: 0.0191, Train Accuracy: 98.44%\n","Epoch [79/100], Step [11/328], Loss: 0.0071, Train Accuracy: 99.22%\n","Epoch [79/100], Step [12/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [79/100], Step [13/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [79/100], Step [14/328], Loss: 0.0120, Train Accuracy: 99.22%\n","Epoch [79/100], Step [15/328], Loss: 0.0337, Train Accuracy: 99.22%\n","Epoch [79/100], Step [16/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [79/100], Step [17/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [79/100], Step [18/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [79/100], Step [19/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [79/100], Step [20/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [79/100], Step [21/328], Loss: 0.0544, Train Accuracy: 97.66%\n","Epoch [79/100], Step [22/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [79/100], Step [23/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [79/100], Step [24/328], Loss: 0.0182, Train Accuracy: 99.22%\n","Epoch [79/100], Step [25/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [79/100], Step [26/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [79/100], Step [27/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [79/100], Step [28/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [79/100], Step [29/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [79/100], Step [30/328], Loss: 0.0060, Train Accuracy: 100.00%\n","Epoch [79/100], Step [31/328], Loss: 0.0143, Train Accuracy: 99.22%\n","Epoch [79/100], Step [32/328], Loss: 0.0195, Train Accuracy: 99.22%\n","Epoch [79/100], Step [33/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [79/100], Step [34/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [79/100], Step [35/328], Loss: 0.0125, Train Accuracy: 99.22%\n","Epoch [79/100], Step [36/328], Loss: 0.0484, Train Accuracy: 98.44%\n","Epoch [79/100], Step [37/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [79/100], Step [38/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [79/100], Step [39/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [79/100], Step [40/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [79/100], Step [41/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [79/100], Step [42/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [79/100], Step [43/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [79/100], Step [44/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [79/100], Step [45/328], Loss: 0.0345, Train Accuracy: 98.44%\n","Epoch [79/100], Step [46/328], Loss: 0.0134, Train Accuracy: 99.22%\n","Epoch [79/100], Step [47/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [79/100], Step [48/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [79/100], Step [49/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [79/100], Step [50/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [79/100], Step [51/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [79/100], Step [52/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [79/100], Step [53/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [79/100], Step [54/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [79/100], Step [55/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [79/100], Step [56/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [79/100], Step [57/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [79/100], Step [58/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [79/100], Step [59/328], Loss: 0.0085, Train Accuracy: 99.22%\n","Epoch [79/100], Step [60/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [79/100], Step [61/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [79/100], Step [62/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [79/100], Step [63/328], Loss: 0.0243, Train Accuracy: 98.44%\n","Epoch [79/100], Step [64/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [79/100], Step [65/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [79/100], Step [66/328], Loss: 0.0086, Train Accuracy: 100.00%\n","Epoch [79/100], Step [67/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [79/100], Step [68/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [79/100], Step [69/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [79/100], Step [70/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [79/100], Step [71/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [79/100], Step [72/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [79/100], Step [73/328], Loss: 0.0209, Train Accuracy: 99.22%\n","Epoch [79/100], Step [74/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [79/100], Step [75/328], Loss: 0.0141, Train Accuracy: 99.22%\n","Epoch [79/100], Step [76/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [79/100], Step [77/328], Loss: 0.0068, Train Accuracy: 100.00%\n","Epoch [79/100], Step [78/328], Loss: 0.0234, Train Accuracy: 99.22%\n","Epoch [79/100], Step [79/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [79/100], Step [80/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [79/100], Step [81/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [79/100], Step [82/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [79/100], Step [83/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [79/100], Step [84/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [79/100], Step [85/328], Loss: 0.0161, Train Accuracy: 99.22%\n","Epoch [79/100], Step [86/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [79/100], Step [87/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [79/100], Step [88/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [79/100], Step [89/328], Loss: 0.0197, Train Accuracy: 99.22%\n","Epoch [79/100], Step [90/328], Loss: 0.0243, Train Accuracy: 99.22%\n","Epoch [79/100], Step [91/328], Loss: 0.0287, Train Accuracy: 99.22%\n","Epoch [79/100], Step [92/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [79/100], Step [93/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [79/100], Step [94/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [79/100], Step [95/328], Loss: 0.0236, Train Accuracy: 99.22%\n","Epoch [79/100], Step [96/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [79/100], Step [97/328], Loss: 0.0064, Train Accuracy: 99.22%\n","Epoch [79/100], Step [98/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [79/100], Step [99/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [79/100], Step [100/328], Loss: 0.0432, Train Accuracy: 97.66%\n","Epoch [79/100], Step [101/328], Loss: 0.0101, Train Accuracy: 100.00%\n","Epoch [79/100], Step [102/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [79/100], Step [103/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [79/100], Step [104/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [79/100], Step [105/328], Loss: 0.0146, Train Accuracy: 99.22%\n","Epoch [79/100], Step [106/328], Loss: 0.0264, Train Accuracy: 98.44%\n","Epoch [79/100], Step [107/328], Loss: 0.0189, Train Accuracy: 99.22%\n","Epoch [79/100], Step [108/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [79/100], Step [109/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [79/100], Step [110/328], Loss: 0.0141, Train Accuracy: 99.22%\n","Epoch [79/100], Step [111/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [79/100], Step [112/328], Loss: 0.0221, Train Accuracy: 99.22%\n","Epoch [79/100], Step [113/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [79/100], Step [114/328], Loss: 0.0359, Train Accuracy: 98.44%\n","Epoch [79/100], Step [115/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [79/100], Step [116/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [79/100], Step [117/328], Loss: 0.0825, Train Accuracy: 96.88%\n","Epoch [79/100], Step [118/328], Loss: 0.0073, Train Accuracy: 99.22%\n","Epoch [79/100], Step [119/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [79/100], Step [120/328], Loss: 0.0048, Train Accuracy: 100.00%\n","Epoch [79/100], Step [121/328], Loss: 0.0522, Train Accuracy: 97.66%\n","Epoch [79/100], Step [122/328], Loss: 0.0088, Train Accuracy: 99.22%\n","Epoch [79/100], Step [123/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [79/100], Step [124/328], Loss: 0.0979, Train Accuracy: 97.66%\n","Epoch [79/100], Step [125/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [79/100], Step [126/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [79/100], Step [127/328], Loss: 0.0204, Train Accuracy: 99.22%\n","Epoch [79/100], Step [128/328], Loss: 0.0645, Train Accuracy: 97.66%\n","Epoch [79/100], Step [129/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [79/100], Step [130/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [79/100], Step [131/328], Loss: 0.0199, Train Accuracy: 99.22%\n","Epoch [79/100], Step [132/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [79/100], Step [133/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [79/100], Step [134/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [79/100], Step [135/328], Loss: 0.0276, Train Accuracy: 98.44%\n","Epoch [79/100], Step [136/328], Loss: 0.0133, Train Accuracy: 99.22%\n","Epoch [79/100], Step [137/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [79/100], Step [138/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [79/100], Step [139/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [79/100], Step [140/328], Loss: 0.0481, Train Accuracy: 99.22%\n","Epoch [79/100], Step [141/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [79/100], Step [142/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [79/100], Step [143/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [79/100], Step [144/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [79/100], Step [145/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [79/100], Step [146/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [79/100], Step [147/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [79/100], Step [148/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [79/100], Step [149/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [79/100], Step [150/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [79/100], Step [151/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [79/100], Step [152/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [79/100], Step [153/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [79/100], Step [154/328], Loss: 0.0048, Train Accuracy: 100.00%\n","Epoch [79/100], Step [155/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [79/100], Step [156/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [79/100], Step [157/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [79/100], Step [158/328], Loss: 0.0305, Train Accuracy: 98.44%\n","Epoch [79/100], Step [159/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [79/100], Step [160/328], Loss: 0.0133, Train Accuracy: 100.00%\n","Epoch [79/100], Step [161/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [79/100], Step [162/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [79/100], Step [163/328], Loss: 0.0090, Train Accuracy: 99.22%\n","Epoch [79/100], Step [164/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [79/100], Step [165/328], Loss: 0.0211, Train Accuracy: 99.22%\n","Epoch [79/100], Step [166/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [79/100], Step [167/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [79/100], Step [168/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [79/100], Step [169/328], Loss: 0.0087, Train Accuracy: 99.22%\n","Epoch [79/100], Step [170/328], Loss: 0.0160, Train Accuracy: 99.22%\n","Epoch [79/100], Step [171/328], Loss: 0.0081, Train Accuracy: 100.00%\n","Epoch [79/100], Step [172/328], Loss: 0.0082, Train Accuracy: 99.22%\n","Epoch [79/100], Step [173/328], Loss: 0.0068, Train Accuracy: 100.00%\n","Epoch [79/100], Step [174/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [79/100], Step [175/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [79/100], Step [176/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [79/100], Step [177/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [79/100], Step [178/328], Loss: 0.0344, Train Accuracy: 98.44%\n","Epoch [79/100], Step [179/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [79/100], Step [180/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [79/100], Step [181/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [79/100], Step [182/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [79/100], Step [183/328], Loss: 0.0119, Train Accuracy: 99.22%\n","Epoch [79/100], Step [184/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [79/100], Step [185/328], Loss: 0.0462, Train Accuracy: 98.44%\n","Epoch [79/100], Step [186/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [79/100], Step [187/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [79/100], Step [188/328], Loss: 0.0298, Train Accuracy: 98.44%\n","Epoch [79/100], Step [189/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [79/100], Step [190/328], Loss: 0.0123, Train Accuracy: 99.22%\n","Epoch [79/100], Step [191/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [79/100], Step [192/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [79/100], Step [193/328], Loss: 0.0168, Train Accuracy: 99.22%\n","Epoch [79/100], Step [194/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [79/100], Step [195/328], Loss: 0.0169, Train Accuracy: 99.22%\n","Epoch [79/100], Step [196/328], Loss: 0.0075, Train Accuracy: 100.00%\n","Epoch [79/100], Step [197/328], Loss: 0.0107, Train Accuracy: 99.22%\n","Epoch [79/100], Step [198/328], Loss: 0.0063, Train Accuracy: 100.00%\n","Epoch [79/100], Step [199/328], Loss: 0.0138, Train Accuracy: 99.22%\n","Epoch [79/100], Step [200/328], Loss: 0.0139, Train Accuracy: 98.44%\n","Epoch [79/100], Step [201/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [79/100], Step [202/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [79/100], Step [203/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [79/100], Step [204/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [79/100], Step [205/328], Loss: 0.0089, Train Accuracy: 100.00%\n","Epoch [79/100], Step [206/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [79/100], Step [207/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [79/100], Step [208/328], Loss: 0.0146, Train Accuracy: 99.22%\n","Epoch [79/100], Step [209/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [79/100], Step [210/328], Loss: 0.0226, Train Accuracy: 99.22%\n","Epoch [79/100], Step [211/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [79/100], Step [212/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [79/100], Step [213/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [79/100], Step [214/328], Loss: 0.0159, Train Accuracy: 99.22%\n","Epoch [79/100], Step [215/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [79/100], Step [216/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [79/100], Step [217/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [79/100], Step [218/328], Loss: 0.0121, Train Accuracy: 99.22%\n","Epoch [79/100], Step [219/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [79/100], Step [220/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [79/100], Step [221/328], Loss: 0.0090, Train Accuracy: 99.22%\n","Epoch [79/100], Step [222/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [79/100], Step [223/328], Loss: 0.0127, Train Accuracy: 99.22%\n","Epoch [79/100], Step [224/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [79/100], Step [225/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [79/100], Step [226/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [79/100], Step [227/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [79/100], Step [228/328], Loss: 0.0075, Train Accuracy: 99.22%\n","Epoch [79/100], Step [229/328], Loss: 0.0106, Train Accuracy: 100.00%\n","Epoch [79/100], Step [230/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [79/100], Step [231/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [79/100], Step [232/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [79/100], Step [233/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [79/100], Step [234/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [79/100], Step [235/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [79/100], Step [236/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [79/100], Step [237/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [79/100], Step [238/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [79/100], Step [239/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [79/100], Step [240/328], Loss: 0.0200, Train Accuracy: 99.22%\n","Epoch [79/100], Step [241/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [79/100], Step [242/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [79/100], Step [243/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [79/100], Step [244/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [79/100], Step [245/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [79/100], Step [246/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [79/100], Step [247/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [79/100], Step [248/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [79/100], Step [249/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [79/100], Step [250/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [79/100], Step [251/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [79/100], Step [252/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [79/100], Step [253/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [79/100], Step [254/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [79/100], Step [255/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [79/100], Step [256/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [79/100], Step [257/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [79/100], Step [258/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [79/100], Step [259/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [79/100], Step [260/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [79/100], Step [261/328], Loss: 0.0076, Train Accuracy: 99.22%\n","Epoch [79/100], Step [262/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [79/100], Step [263/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [79/100], Step [264/328], Loss: 0.0526, Train Accuracy: 99.22%\n","Epoch [79/100], Step [265/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [79/100], Step [266/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [79/100], Step [267/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [79/100], Step [268/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [79/100], Step [269/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [79/100], Step [270/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [79/100], Step [271/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [79/100], Step [272/328], Loss: 0.0068, Train Accuracy: 99.22%\n","Epoch [79/100], Step [273/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [79/100], Step [274/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [79/100], Step [275/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [79/100], Step [276/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [79/100], Step [277/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [79/100], Step [278/328], Loss: 0.0107, Train Accuracy: 99.22%\n","Epoch [79/100], Step [279/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [79/100], Step [280/328], Loss: 0.0164, Train Accuracy: 99.22%\n","Epoch [79/100], Step [281/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [79/100], Step [282/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [79/100], Step [283/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [79/100], Step [284/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [79/100], Step [285/328], Loss: 0.0319, Train Accuracy: 99.22%\n","Epoch [79/100], Step [286/328], Loss: 0.0160, Train Accuracy: 99.22%\n","Epoch [79/100], Step [287/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [79/100], Step [288/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [79/100], Step [289/328], Loss: 0.0118, Train Accuracy: 99.22%\n","Epoch [79/100], Step [290/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [79/100], Step [291/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [79/100], Step [292/328], Loss: 0.0077, Train Accuracy: 99.22%\n","Epoch [79/100], Step [293/328], Loss: 0.0082, Train Accuracy: 99.22%\n","Epoch [79/100], Step [294/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [79/100], Step [295/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [79/100], Step [296/328], Loss: 0.0068, Train Accuracy: 100.00%\n","Epoch [79/100], Step [297/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [79/100], Step [298/328], Loss: 0.0251, Train Accuracy: 98.44%\n","Epoch [79/100], Step [299/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [79/100], Step [300/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [79/100], Step [301/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [79/100], Step [302/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [79/100], Step [303/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [79/100], Step [304/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [79/100], Step [305/328], Loss: 0.0281, Train Accuracy: 99.22%\n","Epoch [79/100], Step [306/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [79/100], Step [307/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [79/100], Step [308/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [79/100], Step [309/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [79/100], Step [310/328], Loss: 0.0054, Train Accuracy: 100.00%\n","Epoch [79/100], Step [311/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [79/100], Step [312/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [79/100], Step [313/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [79/100], Step [314/328], Loss: 0.0076, Train Accuracy: 100.00%\n","Epoch [79/100], Step [315/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [79/100], Step [316/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [79/100], Step [317/328], Loss: 0.0084, Train Accuracy: 100.00%\n","Epoch [79/100], Step [318/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [79/100], Step [319/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [79/100], Step [320/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [79/100], Step [321/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [79/100], Step [322/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [79/100], Step [323/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [79/100], Step [324/328], Loss: 0.0064, Train Accuracy: 100.00%\n","Epoch [79/100], Step [325/328], Loss: 0.0177, Train Accuracy: 99.22%\n","Epoch [79/100], Step [326/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [79/100], Step [327/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [79/100], Step [328/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [80/100], Step [1/328], Loss: 0.0122, Train Accuracy: 99.22%\n","Epoch [80/100], Step [2/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [80/100], Step [3/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [80/100], Step [4/328], Loss: 0.0070, Train Accuracy: 100.00%\n","Epoch [80/100], Step [5/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [80/100], Step [6/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [80/100], Step [7/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [80/100], Step [8/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [80/100], Step [9/328], Loss: 0.0250, Train Accuracy: 99.22%\n","Epoch [80/100], Step [10/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [80/100], Step [11/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [80/100], Step [12/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [80/100], Step [13/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [80/100], Step [14/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [80/100], Step [15/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [80/100], Step [16/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [80/100], Step [17/328], Loss: 0.0283, Train Accuracy: 99.22%\n","Epoch [80/100], Step [18/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [80/100], Step [19/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [80/100], Step [20/328], Loss: 0.0081, Train Accuracy: 99.22%\n","Epoch [80/100], Step [21/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [80/100], Step [22/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [80/100], Step [23/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [80/100], Step [24/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [80/100], Step [25/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [80/100], Step [26/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [80/100], Step [27/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [80/100], Step [28/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [80/100], Step [29/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [80/100], Step [30/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [80/100], Step [31/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [80/100], Step [32/328], Loss: 0.0332, Train Accuracy: 99.22%\n","Epoch [80/100], Step [33/328], Loss: 0.0067, Train Accuracy: 100.00%\n","Epoch [80/100], Step [34/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [80/100], Step [35/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [80/100], Step [36/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [80/100], Step [37/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [80/100], Step [38/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [80/100], Step [39/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [80/100], Step [40/328], Loss: 0.0172, Train Accuracy: 98.44%\n","Epoch [80/100], Step [41/328], Loss: 0.0154, Train Accuracy: 99.22%\n","Epoch [80/100], Step [42/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [80/100], Step [43/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [80/100], Step [44/328], Loss: 0.0086, Train Accuracy: 99.22%\n","Epoch [80/100], Step [45/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [80/100], Step [46/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [80/100], Step [47/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [80/100], Step [48/328], Loss: 0.0096, Train Accuracy: 100.00%\n","Epoch [80/100], Step [49/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [80/100], Step [50/328], Loss: 0.0113, Train Accuracy: 99.22%\n","Epoch [80/100], Step [51/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [80/100], Step [52/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [80/100], Step [53/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [80/100], Step [54/328], Loss: 0.0161, Train Accuracy: 99.22%\n","Epoch [80/100], Step [55/328], Loss: 0.0185, Train Accuracy: 99.22%\n","Epoch [80/100], Step [56/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [80/100], Step [57/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [80/100], Step [58/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [80/100], Step [59/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [80/100], Step [60/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [80/100], Step [61/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [80/100], Step [62/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [80/100], Step [63/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [80/100], Step [64/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [80/100], Step [65/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [80/100], Step [66/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [80/100], Step [67/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [80/100], Step [68/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [80/100], Step [69/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [80/100], Step [70/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [80/100], Step [71/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [80/100], Step [72/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [80/100], Step [73/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [80/100], Step [74/328], Loss: 0.0378, Train Accuracy: 99.22%\n","Epoch [80/100], Step [75/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [80/100], Step [76/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [80/100], Step [77/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [80/100], Step [78/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [80/100], Step [79/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [80/100], Step [80/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [80/100], Step [81/328], Loss: 0.0165, Train Accuracy: 99.22%\n","Epoch [80/100], Step [82/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [80/100], Step [83/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [80/100], Step [84/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [80/100], Step [85/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [80/100], Step [86/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [80/100], Step [87/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [80/100], Step [88/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [80/100], Step [89/328], Loss: 0.0064, Train Accuracy: 100.00%\n","Epoch [80/100], Step [90/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [80/100], Step [91/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [80/100], Step [92/328], Loss: 0.0048, Train Accuracy: 100.00%\n","Epoch [80/100], Step [93/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [80/100], Step [94/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [80/100], Step [95/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [80/100], Step [96/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [80/100], Step [97/328], Loss: 0.0072, Train Accuracy: 99.22%\n","Epoch [80/100], Step [98/328], Loss: 0.0062, Train Accuracy: 99.22%\n","Epoch [80/100], Step [99/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [80/100], Step [100/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [80/100], Step [101/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [80/100], Step [102/328], Loss: 0.0139, Train Accuracy: 99.22%\n","Epoch [80/100], Step [103/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [80/100], Step [104/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [80/100], Step [105/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [80/100], Step [106/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [80/100], Step [107/328], Loss: 0.0269, Train Accuracy: 99.22%\n","Epoch [80/100], Step [108/328], Loss: 0.0066, Train Accuracy: 100.00%\n","Epoch [80/100], Step [109/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [80/100], Step [110/328], Loss: 0.0101, Train Accuracy: 99.22%\n","Epoch [80/100], Step [111/328], Loss: 0.0839, Train Accuracy: 98.44%\n","Epoch [80/100], Step [112/328], Loss: 0.0089, Train Accuracy: 100.00%\n","Epoch [80/100], Step [113/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [80/100], Step [114/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [80/100], Step [115/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [80/100], Step [116/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [80/100], Step [117/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [80/100], Step [118/328], Loss: 0.0066, Train Accuracy: 100.00%\n","Epoch [80/100], Step [119/328], Loss: 0.0462, Train Accuracy: 97.66%\n","Epoch [80/100], Step [120/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [80/100], Step [121/328], Loss: 0.0084, Train Accuracy: 100.00%\n","Epoch [80/100], Step [122/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [80/100], Step [123/328], Loss: 0.0099, Train Accuracy: 100.00%\n","Epoch [80/100], Step [124/328], Loss: 0.0075, Train Accuracy: 100.00%\n","Epoch [80/100], Step [125/328], Loss: 0.0326, Train Accuracy: 99.22%\n","Epoch [80/100], Step [126/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [80/100], Step [127/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [80/100], Step [128/328], Loss: 0.0059, Train Accuracy: 100.00%\n","Epoch [80/100], Step [129/328], Loss: 0.0065, Train Accuracy: 100.00%\n","Epoch [80/100], Step [130/328], Loss: 0.0059, Train Accuracy: 100.00%\n","Epoch [80/100], Step [131/328], Loss: 0.0060, Train Accuracy: 100.00%\n","Epoch [80/100], Step [132/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [80/100], Step [133/328], Loss: 0.0094, Train Accuracy: 99.22%\n","Epoch [80/100], Step [134/328], Loss: 0.0080, Train Accuracy: 99.22%\n","Epoch [80/100], Step [135/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [80/100], Step [136/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [80/100], Step [137/328], Loss: 0.0109, Train Accuracy: 99.22%\n","Epoch [80/100], Step [138/328], Loss: 0.0223, Train Accuracy: 98.44%\n","Epoch [80/100], Step [139/328], Loss: 0.0158, Train Accuracy: 99.22%\n","Epoch [80/100], Step [140/328], Loss: 0.0121, Train Accuracy: 100.00%\n","Epoch [80/100], Step [141/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [80/100], Step [142/328], Loss: 0.0048, Train Accuracy: 100.00%\n","Epoch [80/100], Step [143/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [80/100], Step [144/328], Loss: 0.0159, Train Accuracy: 99.22%\n","Epoch [80/100], Step [145/328], Loss: 0.0087, Train Accuracy: 100.00%\n","Epoch [80/100], Step [146/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [80/100], Step [147/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [80/100], Step [148/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [80/100], Step [149/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [80/100], Step [150/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [80/100], Step [151/328], Loss: 0.0433, Train Accuracy: 99.22%\n","Epoch [80/100], Step [152/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [80/100], Step [153/328], Loss: 0.0382, Train Accuracy: 98.44%\n","Epoch [80/100], Step [154/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [80/100], Step [155/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [80/100], Step [156/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [80/100], Step [157/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [80/100], Step [158/328], Loss: 0.0256, Train Accuracy: 99.22%\n","Epoch [80/100], Step [159/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [80/100], Step [160/328], Loss: 0.0114, Train Accuracy: 99.22%\n","Epoch [80/100], Step [161/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [80/100], Step [162/328], Loss: 0.0122, Train Accuracy: 99.22%\n","Epoch [80/100], Step [163/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [80/100], Step [164/328], Loss: 0.0113, Train Accuracy: 99.22%\n","Epoch [80/100], Step [165/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [80/100], Step [166/328], Loss: 0.0085, Train Accuracy: 99.22%\n","Epoch [80/100], Step [167/328], Loss: 0.0095, Train Accuracy: 99.22%\n","Epoch [80/100], Step [168/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [80/100], Step [169/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [80/100], Step [170/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [80/100], Step [171/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [80/100], Step [172/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [80/100], Step [173/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [80/100], Step [174/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [80/100], Step [175/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [80/100], Step [176/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [80/100], Step [177/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [80/100], Step [178/328], Loss: 0.0150, Train Accuracy: 99.22%\n","Epoch [80/100], Step [179/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [80/100], Step [180/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [80/100], Step [181/328], Loss: 0.0510, Train Accuracy: 98.44%\n","Epoch [80/100], Step [182/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [80/100], Step [183/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [80/100], Step [184/328], Loss: 0.0157, Train Accuracy: 99.22%\n","Epoch [80/100], Step [185/328], Loss: 0.0269, Train Accuracy: 98.44%\n","Epoch [80/100], Step [186/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [80/100], Step [187/328], Loss: 0.0111, Train Accuracy: 99.22%\n","Epoch [80/100], Step [188/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [80/100], Step [189/328], Loss: 0.0077, Train Accuracy: 100.00%\n","Epoch [80/100], Step [190/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [80/100], Step [191/328], Loss: 0.0401, Train Accuracy: 98.44%\n","Epoch [80/100], Step [192/328], Loss: 0.0215, Train Accuracy: 98.44%\n","Epoch [80/100], Step [193/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [80/100], Step [194/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [80/100], Step [195/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [80/100], Step [196/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [80/100], Step [197/328], Loss: 0.0133, Train Accuracy: 99.22%\n","Epoch [80/100], Step [198/328], Loss: 0.0363, Train Accuracy: 98.44%\n","Epoch [80/100], Step [199/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [80/100], Step [200/328], Loss: 0.0080, Train Accuracy: 100.00%\n","Epoch [80/100], Step [201/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [80/100], Step [202/328], Loss: 0.0199, Train Accuracy: 99.22%\n","Epoch [80/100], Step [203/328], Loss: 0.0407, Train Accuracy: 98.44%\n","Epoch [80/100], Step [204/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [80/100], Step [205/328], Loss: 0.0235, Train Accuracy: 99.22%\n","Epoch [80/100], Step [206/328], Loss: 0.0464, Train Accuracy: 98.44%\n","Epoch [80/100], Step [207/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [80/100], Step [208/328], Loss: 0.0125, Train Accuracy: 99.22%\n","Epoch [80/100], Step [209/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [80/100], Step [210/328], Loss: 0.0149, Train Accuracy: 98.44%\n","Epoch [80/100], Step [211/328], Loss: 0.0443, Train Accuracy: 97.66%\n","Epoch [80/100], Step [212/328], Loss: 0.0139, Train Accuracy: 99.22%\n","Epoch [80/100], Step [213/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [80/100], Step [214/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [80/100], Step [215/328], Loss: 0.0279, Train Accuracy: 99.22%\n","Epoch [80/100], Step [216/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [80/100], Step [217/328], Loss: 0.0337, Train Accuracy: 99.22%\n","Epoch [80/100], Step [218/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [80/100], Step [219/328], Loss: 0.0060, Train Accuracy: 100.00%\n","Epoch [80/100], Step [220/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [80/100], Step [221/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [80/100], Step [222/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [80/100], Step [223/328], Loss: 0.0087, Train Accuracy: 99.22%\n","Epoch [80/100], Step [224/328], Loss: 0.0209, Train Accuracy: 99.22%\n","Epoch [80/100], Step [225/328], Loss: 0.0096, Train Accuracy: 99.22%\n","Epoch [80/100], Step [226/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [80/100], Step [227/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [80/100], Step [228/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [80/100], Step [229/328], Loss: 0.0084, Train Accuracy: 99.22%\n","Epoch [80/100], Step [230/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [80/100], Step [231/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [80/100], Step [232/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [80/100], Step [233/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [80/100], Step [234/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [80/100], Step [235/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [80/100], Step [236/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [80/100], Step [237/328], Loss: 0.0135, Train Accuracy: 99.22%\n","Epoch [80/100], Step [238/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [80/100], Step [239/328], Loss: 0.0068, Train Accuracy: 100.00%\n","Epoch [80/100], Step [240/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [80/100], Step [241/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [80/100], Step [242/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [80/100], Step [243/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [80/100], Step [244/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [80/100], Step [245/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [80/100], Step [246/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [80/100], Step [247/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [80/100], Step [248/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [80/100], Step [249/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [80/100], Step [250/328], Loss: 0.0178, Train Accuracy: 99.22%\n","Epoch [80/100], Step [251/328], Loss: 0.0127, Train Accuracy: 99.22%\n","Epoch [80/100], Step [252/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [80/100], Step [253/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [80/100], Step [254/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [80/100], Step [255/328], Loss: 0.0329, Train Accuracy: 99.22%\n","Epoch [80/100], Step [256/328], Loss: 0.0131, Train Accuracy: 99.22%\n","Epoch [80/100], Step [257/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [80/100], Step [258/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [80/100], Step [259/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [80/100], Step [260/328], Loss: 0.0316, Train Accuracy: 98.44%\n","Epoch [80/100], Step [261/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [80/100], Step [262/328], Loss: 0.0313, Train Accuracy: 99.22%\n","Epoch [80/100], Step [263/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [80/100], Step [264/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [80/100], Step [265/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [80/100], Step [266/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [80/100], Step [267/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [80/100], Step [268/328], Loss: 0.0143, Train Accuracy: 100.00%\n","Epoch [80/100], Step [269/328], Loss: 0.0187, Train Accuracy: 99.22%\n","Epoch [80/100], Step [270/328], Loss: 0.0134, Train Accuracy: 99.22%\n","Epoch [80/100], Step [271/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [80/100], Step [272/328], Loss: 0.0080, Train Accuracy: 100.00%\n","Epoch [80/100], Step [273/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [80/100], Step [274/328], Loss: 0.0089, Train Accuracy: 100.00%\n","Epoch [80/100], Step [275/328], Loss: 0.0326, Train Accuracy: 98.44%\n","Epoch [80/100], Step [276/328], Loss: 0.0439, Train Accuracy: 98.44%\n","Epoch [80/100], Step [277/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [80/100], Step [278/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [80/100], Step [279/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [80/100], Step [280/328], Loss: 0.0135, Train Accuracy: 99.22%\n","Epoch [80/100], Step [281/328], Loss: 0.0066, Train Accuracy: 100.00%\n","Epoch [80/100], Step [282/328], Loss: 0.0555, Train Accuracy: 98.44%\n","Epoch [80/100], Step [283/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [80/100], Step [284/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [80/100], Step [285/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [80/100], Step [286/328], Loss: 0.0171, Train Accuracy: 99.22%\n","Epoch [80/100], Step [287/328], Loss: 0.0309, Train Accuracy: 99.22%\n","Epoch [80/100], Step [288/328], Loss: 0.0417, Train Accuracy: 98.44%\n","Epoch [80/100], Step [289/328], Loss: 0.0316, Train Accuracy: 99.22%\n","Epoch [80/100], Step [290/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [80/100], Step [291/328], Loss: 0.0177, Train Accuracy: 98.44%\n","Epoch [80/100], Step [292/328], Loss: 0.0079, Train Accuracy: 100.00%\n","Epoch [80/100], Step [293/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [80/100], Step [294/328], Loss: 0.0146, Train Accuracy: 99.22%\n","Epoch [80/100], Step [295/328], Loss: 0.0243, Train Accuracy: 99.22%\n","Epoch [80/100], Step [296/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [80/100], Step [297/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [80/100], Step [298/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [80/100], Step [299/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [80/100], Step [300/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [80/100], Step [301/328], Loss: 0.0140, Train Accuracy: 99.22%\n","Epoch [80/100], Step [302/328], Loss: 0.0776, Train Accuracy: 98.44%\n","Epoch [80/100], Step [303/328], Loss: 0.0824, Train Accuracy: 97.66%\n","Epoch [80/100], Step [304/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [80/100], Step [305/328], Loss: 0.0178, Train Accuracy: 99.22%\n","Epoch [80/100], Step [306/328], Loss: 0.0821, Train Accuracy: 97.66%\n","Epoch [80/100], Step [307/328], Loss: 0.0517, Train Accuracy: 99.22%\n","Epoch [80/100], Step [308/328], Loss: 0.0136, Train Accuracy: 100.00%\n","Epoch [80/100], Step [309/328], Loss: 0.0076, Train Accuracy: 100.00%\n","Epoch [80/100], Step [310/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [80/100], Step [311/328], Loss: 0.0149, Train Accuracy: 99.22%\n","Epoch [80/100], Step [312/328], Loss: 0.0064, Train Accuracy: 100.00%\n","Epoch [80/100], Step [313/328], Loss: 0.0291, Train Accuracy: 99.22%\n","Epoch [80/100], Step [314/328], Loss: 0.0236, Train Accuracy: 98.44%\n","Epoch [80/100], Step [315/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [80/100], Step [316/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [80/100], Step [317/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [80/100], Step [318/328], Loss: 0.0222, Train Accuracy: 99.22%\n","Epoch [80/100], Step [319/328], Loss: 0.0236, Train Accuracy: 98.44%\n","Epoch [80/100], Step [320/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [80/100], Step [321/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [80/100], Step [322/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [80/100], Step [323/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [80/100], Step [324/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [80/100], Step [325/328], Loss: 0.0121, Train Accuracy: 99.22%\n","Epoch [80/100], Step [326/328], Loss: 0.0091, Train Accuracy: 99.22%\n","Epoch [80/100], Step [327/328], Loss: 0.0068, Train Accuracy: 100.00%\n","Epoch [80/100], Step [328/328], Loss: 0.0101, Train Accuracy: 98.75%\n","Epoch [81/100], Step [1/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [81/100], Step [2/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [81/100], Step [3/328], Loss: 0.0086, Train Accuracy: 100.00%\n","Epoch [81/100], Step [4/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [81/100], Step [5/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [81/100], Step [6/328], Loss: 0.0181, Train Accuracy: 98.44%\n","Epoch [81/100], Step [7/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [81/100], Step [8/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [81/100], Step [9/328], Loss: 0.0195, Train Accuracy: 99.22%\n","Epoch [81/100], Step [10/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [81/100], Step [11/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [81/100], Step [12/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [81/100], Step [13/328], Loss: 0.0071, Train Accuracy: 100.00%\n","Epoch [81/100], Step [14/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [81/100], Step [15/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [81/100], Step [16/328], Loss: 0.0081, Train Accuracy: 99.22%\n","Epoch [81/100], Step [17/328], Loss: 0.0062, Train Accuracy: 100.00%\n","Epoch [81/100], Step [18/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [81/100], Step [19/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [81/100], Step [20/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [81/100], Step [21/328], Loss: 0.0071, Train Accuracy: 100.00%\n","Epoch [81/100], Step [22/328], Loss: 0.0326, Train Accuracy: 98.44%\n","Epoch [81/100], Step [23/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [81/100], Step [24/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [81/100], Step [25/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [81/100], Step [26/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [81/100], Step [27/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [81/100], Step [28/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [81/100], Step [29/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [81/100], Step [30/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [81/100], Step [31/328], Loss: 0.0285, Train Accuracy: 99.22%\n","Epoch [81/100], Step [32/328], Loss: 0.0101, Train Accuracy: 100.00%\n","Epoch [81/100], Step [33/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [81/100], Step [34/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [81/100], Step [35/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [81/100], Step [36/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [81/100], Step [37/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [81/100], Step [38/328], Loss: 0.0575, Train Accuracy: 98.44%\n","Epoch [81/100], Step [39/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [81/100], Step [40/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [81/100], Step [41/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [81/100], Step [42/328], Loss: 0.0069, Train Accuracy: 100.00%\n","Epoch [81/100], Step [43/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [81/100], Step [44/328], Loss: 0.0183, Train Accuracy: 99.22%\n","Epoch [81/100], Step [45/328], Loss: 0.0083, Train Accuracy: 100.00%\n","Epoch [81/100], Step [46/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [81/100], Step [47/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [81/100], Step [48/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [81/100], Step [49/328], Loss: 0.0060, Train Accuracy: 100.00%\n","Epoch [81/100], Step [50/328], Loss: 0.0205, Train Accuracy: 98.44%\n","Epoch [81/100], Step [51/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [81/100], Step [52/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [81/100], Step [53/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [81/100], Step [54/328], Loss: 0.0238, Train Accuracy: 99.22%\n","Epoch [81/100], Step [55/328], Loss: 0.0059, Train Accuracy: 100.00%\n","Epoch [81/100], Step [56/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [81/100], Step [57/328], Loss: 0.0318, Train Accuracy: 99.22%\n","Epoch [81/100], Step [58/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [81/100], Step [59/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [81/100], Step [60/328], Loss: 0.0108, Train Accuracy: 99.22%\n","Epoch [81/100], Step [61/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [81/100], Step [62/328], Loss: 0.0108, Train Accuracy: 99.22%\n","Epoch [81/100], Step [63/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [81/100], Step [64/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [81/100], Step [65/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [81/100], Step [66/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [81/100], Step [67/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [81/100], Step [68/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [81/100], Step [69/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [81/100], Step [70/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [81/100], Step [71/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [81/100], Step [72/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [81/100], Step [73/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [81/100], Step [74/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [81/100], Step [75/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [81/100], Step [76/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [81/100], Step [77/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [81/100], Step [78/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [81/100], Step [79/328], Loss: 0.0114, Train Accuracy: 99.22%\n","Epoch [81/100], Step [80/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [81/100], Step [81/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [81/100], Step [82/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [81/100], Step [83/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [81/100], Step [84/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [81/100], Step [85/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [81/100], Step [86/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [81/100], Step [87/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [81/100], Step [88/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [81/100], Step [89/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [81/100], Step [90/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [81/100], Step [91/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [81/100], Step [92/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [81/100], Step [93/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [81/100], Step [94/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [81/100], Step [95/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [81/100], Step [96/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [81/100], Step [97/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [81/100], Step [98/328], Loss: 0.0198, Train Accuracy: 99.22%\n","Epoch [81/100], Step [99/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [81/100], Step [100/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [81/100], Step [101/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [81/100], Step [102/328], Loss: 0.0120, Train Accuracy: 99.22%\n","Epoch [81/100], Step [103/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [81/100], Step [104/328], Loss: 0.0096, Train Accuracy: 99.22%\n","Epoch [81/100], Step [105/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [81/100], Step [106/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [81/100], Step [107/328], Loss: 0.0050, Train Accuracy: 100.00%\n","Epoch [81/100], Step [108/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [81/100], Step [109/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [81/100], Step [110/328], Loss: 0.0103, Train Accuracy: 99.22%\n","Epoch [81/100], Step [111/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [81/100], Step [112/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [81/100], Step [113/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [81/100], Step [114/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [81/100], Step [115/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [81/100], Step [116/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [81/100], Step [117/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [81/100], Step [118/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [81/100], Step [119/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [81/100], Step [120/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [81/100], Step [121/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [81/100], Step [122/328], Loss: 0.0174, Train Accuracy: 99.22%\n","Epoch [81/100], Step [123/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [81/100], Step [124/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [81/100], Step [125/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [81/100], Step [126/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [81/100], Step [127/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [81/100], Step [128/328], Loss: 0.0107, Train Accuracy: 99.22%\n","Epoch [81/100], Step [129/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [81/100], Step [130/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [81/100], Step [131/328], Loss: 0.0082, Train Accuracy: 99.22%\n","Epoch [81/100], Step [132/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [81/100], Step [133/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [81/100], Step [134/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [81/100], Step [135/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [81/100], Step [136/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [81/100], Step [137/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [81/100], Step [138/328], Loss: 0.0083, Train Accuracy: 100.00%\n","Epoch [81/100], Step [139/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [81/100], Step [140/328], Loss: 0.0178, Train Accuracy: 99.22%\n","Epoch [81/100], Step [141/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [81/100], Step [142/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [81/100], Step [143/328], Loss: 0.0111, Train Accuracy: 99.22%\n","Epoch [81/100], Step [144/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [81/100], Step [145/328], Loss: 0.0200, Train Accuracy: 99.22%\n","Epoch [81/100], Step [146/328], Loss: 0.0152, Train Accuracy: 99.22%\n","Epoch [81/100], Step [147/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [81/100], Step [148/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [81/100], Step [149/328], Loss: 0.0198, Train Accuracy: 99.22%\n","Epoch [81/100], Step [150/328], Loss: 0.0178, Train Accuracy: 99.22%\n","Epoch [81/100], Step [151/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [81/100], Step [152/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [81/100], Step [153/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [81/100], Step [154/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [81/100], Step [155/328], Loss: 0.0066, Train Accuracy: 100.00%\n","Epoch [81/100], Step [156/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [81/100], Step [157/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [81/100], Step [158/328], Loss: 0.0297, Train Accuracy: 99.22%\n","Epoch [81/100], Step [159/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [81/100], Step [160/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [81/100], Step [161/328], Loss: 0.0142, Train Accuracy: 99.22%\n","Epoch [81/100], Step [162/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [81/100], Step [163/328], Loss: 0.0085, Train Accuracy: 100.00%\n","Epoch [81/100], Step [164/328], Loss: 0.0107, Train Accuracy: 99.22%\n","Epoch [81/100], Step [165/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [81/100], Step [166/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [81/100], Step [167/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [81/100], Step [168/328], Loss: 0.0123, Train Accuracy: 99.22%\n","Epoch [81/100], Step [169/328], Loss: 0.0065, Train Accuracy: 100.00%\n","Epoch [81/100], Step [170/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [81/100], Step [171/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [81/100], Step [172/328], Loss: 0.0828, Train Accuracy: 99.22%\n","Epoch [81/100], Step [173/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [81/100], Step [174/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [81/100], Step [175/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [81/100], Step [176/328], Loss: 0.0794, Train Accuracy: 97.66%\n","Epoch [81/100], Step [177/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [81/100], Step [178/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [81/100], Step [179/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [81/100], Step [180/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [81/100], Step [181/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [81/100], Step [182/328], Loss: 0.0317, Train Accuracy: 99.22%\n","Epoch [81/100], Step [183/328], Loss: 0.1037, Train Accuracy: 99.22%\n","Epoch [81/100], Step [184/328], Loss: 0.1002, Train Accuracy: 99.22%\n","Epoch [81/100], Step [185/328], Loss: 0.0079, Train Accuracy: 99.22%\n","Epoch [81/100], Step [186/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [81/100], Step [187/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [81/100], Step [188/328], Loss: 0.0109, Train Accuracy: 99.22%\n","Epoch [81/100], Step [189/328], Loss: 0.0204, Train Accuracy: 99.22%\n","Epoch [81/100], Step [190/328], Loss: 0.0553, Train Accuracy: 96.88%\n","Epoch [81/100], Step [191/328], Loss: 0.0219, Train Accuracy: 99.22%\n","Epoch [81/100], Step [192/328], Loss: 0.0351, Train Accuracy: 99.22%\n","Epoch [81/100], Step [193/328], Loss: 0.0247, Train Accuracy: 99.22%\n","Epoch [81/100], Step [194/328], Loss: 0.0259, Train Accuracy: 98.44%\n","Epoch [81/100], Step [195/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [81/100], Step [196/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [81/100], Step [197/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [81/100], Step [198/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [81/100], Step [199/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [81/100], Step [200/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [81/100], Step [201/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [81/100], Step [202/328], Loss: 0.0075, Train Accuracy: 100.00%\n","Epoch [81/100], Step [203/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [81/100], Step [204/328], Loss: 0.0048, Train Accuracy: 100.00%\n","Epoch [81/100], Step [205/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [81/100], Step [206/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [81/100], Step [207/328], Loss: 0.0133, Train Accuracy: 99.22%\n","Epoch [81/100], Step [208/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [81/100], Step [209/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [81/100], Step [210/328], Loss: 0.0232, Train Accuracy: 98.44%\n","Epoch [81/100], Step [211/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [81/100], Step [212/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [81/100], Step [213/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [81/100], Step [214/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [81/100], Step [215/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [81/100], Step [216/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [81/100], Step [217/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [81/100], Step [218/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [81/100], Step [219/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [81/100], Step [220/328], Loss: 0.0235, Train Accuracy: 99.22%\n","Epoch [81/100], Step [221/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [81/100], Step [222/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [81/100], Step [223/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [81/100], Step [224/328], Loss: 0.0078, Train Accuracy: 100.00%\n","Epoch [81/100], Step [225/328], Loss: 0.0150, Train Accuracy: 99.22%\n","Epoch [81/100], Step [226/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [81/100], Step [227/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [81/100], Step [228/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [81/100], Step [229/328], Loss: 0.0114, Train Accuracy: 99.22%\n","Epoch [81/100], Step [230/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [81/100], Step [231/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [81/100], Step [232/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [81/100], Step [233/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [81/100], Step [234/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [81/100], Step [235/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [81/100], Step [236/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [81/100], Step [237/328], Loss: 0.0087, Train Accuracy: 99.22%\n","Epoch [81/100], Step [238/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [81/100], Step [239/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [81/100], Step [240/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [81/100], Step [241/328], Loss: 0.0048, Train Accuracy: 100.00%\n","Epoch [81/100], Step [242/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [81/100], Step [243/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [81/100], Step [244/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [81/100], Step [245/328], Loss: 0.0116, Train Accuracy: 99.22%\n","Epoch [81/100], Step [246/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [81/100], Step [247/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [81/100], Step [248/328], Loss: 0.0136, Train Accuracy: 98.44%\n","Epoch [81/100], Step [249/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [81/100], Step [250/328], Loss: 0.0060, Train Accuracy: 100.00%\n","Epoch [81/100], Step [251/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [81/100], Step [252/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [81/100], Step [253/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [81/100], Step [254/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [81/100], Step [255/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [81/100], Step [256/328], Loss: 0.0661, Train Accuracy: 97.66%\n","Epoch [81/100], Step [257/328], Loss: 0.0000, Train Accuracy: 100.00%\n","Epoch [81/100], Step [258/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [81/100], Step [259/328], Loss: 0.0147, Train Accuracy: 99.22%\n","Epoch [81/100], Step [260/328], Loss: 0.0635, Train Accuracy: 97.66%\n","Epoch [81/100], Step [261/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [81/100], Step [262/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [81/100], Step [263/328], Loss: 0.0235, Train Accuracy: 99.22%\n","Epoch [81/100], Step [264/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [81/100], Step [265/328], Loss: 0.0174, Train Accuracy: 99.22%\n","Epoch [81/100], Step [266/328], Loss: 0.0175, Train Accuracy: 99.22%\n","Epoch [81/100], Step [267/328], Loss: 0.0158, Train Accuracy: 99.22%\n","Epoch [81/100], Step [268/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [81/100], Step [269/328], Loss: 0.0346, Train Accuracy: 99.22%\n","Epoch [81/100], Step [270/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [81/100], Step [271/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [81/100], Step [272/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [81/100], Step [273/328], Loss: 0.0096, Train Accuracy: 99.22%\n","Epoch [81/100], Step [274/328], Loss: 0.0915, Train Accuracy: 96.09%\n","Epoch [81/100], Step [275/328], Loss: 0.0203, Train Accuracy: 99.22%\n","Epoch [81/100], Step [276/328], Loss: 0.0203, Train Accuracy: 99.22%\n","Epoch [81/100], Step [277/328], Loss: 0.0654, Train Accuracy: 99.22%\n","Epoch [81/100], Step [278/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [81/100], Step [279/328], Loss: 0.0375, Train Accuracy: 98.44%\n","Epoch [81/100], Step [280/328], Loss: 0.0252, Train Accuracy: 98.44%\n","Epoch [81/100], Step [281/328], Loss: 0.0084, Train Accuracy: 100.00%\n","Epoch [81/100], Step [282/328], Loss: 0.0265, Train Accuracy: 99.22%\n","Epoch [81/100], Step [283/328], Loss: 0.0355, Train Accuracy: 96.88%\n","Epoch [81/100], Step [284/328], Loss: 0.0439, Train Accuracy: 97.66%\n","Epoch [81/100], Step [285/328], Loss: 0.0197, Train Accuracy: 98.44%\n","Epoch [81/100], Step [286/328], Loss: 0.0504, Train Accuracy: 97.66%\n","Epoch [81/100], Step [287/328], Loss: 0.0123, Train Accuracy: 99.22%\n","Epoch [81/100], Step [288/328], Loss: 0.0083, Train Accuracy: 100.00%\n","Epoch [81/100], Step [289/328], Loss: 0.0293, Train Accuracy: 98.44%\n","Epoch [81/100], Step [290/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [81/100], Step [291/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [81/100], Step [292/328], Loss: 0.0106, Train Accuracy: 99.22%\n","Epoch [81/100], Step [293/328], Loss: 0.0346, Train Accuracy: 99.22%\n","Epoch [81/100], Step [294/328], Loss: 0.0206, Train Accuracy: 98.44%\n","Epoch [81/100], Step [295/328], Loss: 0.0606, Train Accuracy: 98.44%\n","Epoch [81/100], Step [296/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [81/100], Step [297/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [81/100], Step [298/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [81/100], Step [299/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [81/100], Step [300/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [81/100], Step [301/328], Loss: 0.0958, Train Accuracy: 96.88%\n","Epoch [81/100], Step [302/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [81/100], Step [303/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [81/100], Step [304/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [81/100], Step [305/328], Loss: 0.0069, Train Accuracy: 100.00%\n","Epoch [81/100], Step [306/328], Loss: 0.0094, Train Accuracy: 100.00%\n","Epoch [81/100], Step [307/328], Loss: 0.0261, Train Accuracy: 99.22%\n","Epoch [81/100], Step [308/328], Loss: 0.0394, Train Accuracy: 99.22%\n","Epoch [81/100], Step [309/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [81/100], Step [310/328], Loss: 0.0139, Train Accuracy: 99.22%\n","Epoch [81/100], Step [311/328], Loss: 0.0121, Train Accuracy: 99.22%\n","Epoch [81/100], Step [312/328], Loss: 0.0354, Train Accuracy: 98.44%\n","Epoch [81/100], Step [313/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [81/100], Step [314/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [81/100], Step [315/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [81/100], Step [316/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [81/100], Step [317/328], Loss: 0.0172, Train Accuracy: 99.22%\n","Epoch [81/100], Step [318/328], Loss: 0.0122, Train Accuracy: 100.00%\n","Epoch [81/100], Step [319/328], Loss: 0.0079, Train Accuracy: 100.00%\n","Epoch [81/100], Step [320/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [81/100], Step [321/328], Loss: 0.0286, Train Accuracy: 99.22%\n","Epoch [81/100], Step [322/328], Loss: 0.0188, Train Accuracy: 99.22%\n","Epoch [81/100], Step [323/328], Loss: 0.0143, Train Accuracy: 99.22%\n","Epoch [81/100], Step [324/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [81/100], Step [325/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [81/100], Step [326/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [81/100], Step [327/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [81/100], Step [328/328], Loss: 0.0151, Train Accuracy: 98.75%\n","Epoch [82/100], Step [1/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [82/100], Step [2/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [82/100], Step [3/328], Loss: 0.0067, Train Accuracy: 100.00%\n","Epoch [82/100], Step [4/328], Loss: 0.0296, Train Accuracy: 99.22%\n","Epoch [82/100], Step [5/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [82/100], Step [6/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [82/100], Step [7/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [82/100], Step [8/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [82/100], Step [9/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [82/100], Step [10/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [82/100], Step [11/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [82/100], Step [12/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [82/100], Step [13/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [82/100], Step [14/328], Loss: 0.0191, Train Accuracy: 99.22%\n","Epoch [82/100], Step [15/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [82/100], Step [16/328], Loss: 0.0084, Train Accuracy: 99.22%\n","Epoch [82/100], Step [17/328], Loss: 0.0376, Train Accuracy: 99.22%\n","Epoch [82/100], Step [18/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [82/100], Step [19/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [82/100], Step [20/328], Loss: 0.0478, Train Accuracy: 99.22%\n","Epoch [82/100], Step [21/328], Loss: 0.0150, Train Accuracy: 99.22%\n","Epoch [82/100], Step [22/328], Loss: 0.0180, Train Accuracy: 99.22%\n","Epoch [82/100], Step [23/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [82/100], Step [24/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [82/100], Step [25/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [82/100], Step [26/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [82/100], Step [27/328], Loss: 0.0350, Train Accuracy: 99.22%\n","Epoch [82/100], Step [28/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [82/100], Step [29/328], Loss: 0.0358, Train Accuracy: 99.22%\n","Epoch [82/100], Step [30/328], Loss: 0.0097, Train Accuracy: 99.22%\n","Epoch [82/100], Step [31/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [82/100], Step [32/328], Loss: 0.0285, Train Accuracy: 98.44%\n","Epoch [82/100], Step [33/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [82/100], Step [34/328], Loss: 0.0246, Train Accuracy: 98.44%\n","Epoch [82/100], Step [35/328], Loss: 0.0318, Train Accuracy: 98.44%\n","Epoch [82/100], Step [36/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [82/100], Step [37/328], Loss: 0.0412, Train Accuracy: 98.44%\n","Epoch [82/100], Step [38/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [82/100], Step [39/328], Loss: 0.0210, Train Accuracy: 99.22%\n","Epoch [82/100], Step [40/328], Loss: 0.0379, Train Accuracy: 98.44%\n","Epoch [82/100], Step [41/328], Loss: 0.0100, Train Accuracy: 99.22%\n","Epoch [82/100], Step [42/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [82/100], Step [43/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [82/100], Step [44/328], Loss: 0.0176, Train Accuracy: 99.22%\n","Epoch [82/100], Step [45/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [82/100], Step [46/328], Loss: 0.0173, Train Accuracy: 99.22%\n","Epoch [82/100], Step [47/328], Loss: 0.0200, Train Accuracy: 99.22%\n","Epoch [82/100], Step [48/328], Loss: 0.0097, Train Accuracy: 99.22%\n","Epoch [82/100], Step [49/328], Loss: 0.0115, Train Accuracy: 99.22%\n","Epoch [82/100], Step [50/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [82/100], Step [51/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [82/100], Step [52/328], Loss: 0.0072, Train Accuracy: 100.00%\n","Epoch [82/100], Step [53/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [82/100], Step [54/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [82/100], Step [55/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [82/100], Step [56/328], Loss: 0.0097, Train Accuracy: 100.00%\n","Epoch [82/100], Step [57/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [82/100], Step [58/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [82/100], Step [59/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [82/100], Step [60/328], Loss: 0.0188, Train Accuracy: 99.22%\n","Epoch [82/100], Step [61/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [82/100], Step [62/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [82/100], Step [63/328], Loss: 0.0080, Train Accuracy: 100.00%\n","Epoch [82/100], Step [64/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [82/100], Step [65/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [82/100], Step [66/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [82/100], Step [67/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [82/100], Step [68/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [82/100], Step [69/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [82/100], Step [70/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [82/100], Step [71/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [82/100], Step [72/328], Loss: 0.0082, Train Accuracy: 99.22%\n","Epoch [82/100], Step [73/328], Loss: 0.0069, Train Accuracy: 99.22%\n","Epoch [82/100], Step [74/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [82/100], Step [75/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [82/100], Step [76/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [82/100], Step [77/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [82/100], Step [78/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [82/100], Step [79/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [82/100], Step [80/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [82/100], Step [81/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [82/100], Step [82/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [82/100], Step [83/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [82/100], Step [84/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [82/100], Step [85/328], Loss: 0.0238, Train Accuracy: 99.22%\n","Epoch [82/100], Step [86/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [82/100], Step [87/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [82/100], Step [88/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [82/100], Step [89/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [82/100], Step [90/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [82/100], Step [91/328], Loss: 0.0086, Train Accuracy: 100.00%\n","Epoch [82/100], Step [92/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [82/100], Step [93/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [82/100], Step [94/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [82/100], Step [95/328], Loss: 0.0110, Train Accuracy: 99.22%\n","Epoch [82/100], Step [96/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [82/100], Step [97/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [82/100], Step [98/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [82/100], Step [99/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [82/100], Step [100/328], Loss: 0.0068, Train Accuracy: 100.00%\n","Epoch [82/100], Step [101/328], Loss: 0.0233, Train Accuracy: 99.22%\n","Epoch [82/100], Step [102/328], Loss: 0.0301, Train Accuracy: 99.22%\n","Epoch [82/100], Step [103/328], Loss: 0.0079, Train Accuracy: 100.00%\n","Epoch [82/100], Step [104/328], Loss: 0.0203, Train Accuracy: 99.22%\n","Epoch [82/100], Step [105/328], Loss: 0.0104, Train Accuracy: 99.22%\n","Epoch [82/100], Step [106/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [82/100], Step [107/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [82/100], Step [108/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [82/100], Step [109/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [82/100], Step [110/328], Loss: 0.0444, Train Accuracy: 98.44%\n","Epoch [82/100], Step [111/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [82/100], Step [112/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [82/100], Step [113/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [82/100], Step [114/328], Loss: 0.0168, Train Accuracy: 99.22%\n","Epoch [82/100], Step [115/328], Loss: 0.0126, Train Accuracy: 100.00%\n","Epoch [82/100], Step [116/328], Loss: 0.0458, Train Accuracy: 98.44%\n","Epoch [82/100], Step [117/328], Loss: 0.0409, Train Accuracy: 98.44%\n","Epoch [82/100], Step [118/328], Loss: 0.0170, Train Accuracy: 99.22%\n","Epoch [82/100], Step [119/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [82/100], Step [120/328], Loss: 0.0100, Train Accuracy: 99.22%\n","Epoch [82/100], Step [121/328], Loss: 0.0089, Train Accuracy: 100.00%\n","Epoch [82/100], Step [122/328], Loss: 0.1627, Train Accuracy: 96.88%\n","Epoch [82/100], Step [123/328], Loss: 0.0048, Train Accuracy: 100.00%\n","Epoch [82/100], Step [124/328], Loss: 0.0104, Train Accuracy: 100.00%\n","Epoch [82/100], Step [125/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [82/100], Step [126/328], Loss: 0.1580, Train Accuracy: 96.09%\n","Epoch [82/100], Step [127/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [82/100], Step [128/328], Loss: 0.0072, Train Accuracy: 100.00%\n","Epoch [82/100], Step [129/328], Loss: 0.0357, Train Accuracy: 98.44%\n","Epoch [82/100], Step [130/328], Loss: 0.0189, Train Accuracy: 99.22%\n","Epoch [82/100], Step [131/328], Loss: 0.0336, Train Accuracy: 99.22%\n","Epoch [82/100], Step [132/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [82/100], Step [133/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [82/100], Step [134/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [82/100], Step [135/328], Loss: 0.1054, Train Accuracy: 97.66%\n","Epoch [82/100], Step [136/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [82/100], Step [137/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [82/100], Step [138/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [82/100], Step [139/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [82/100], Step [140/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [82/100], Step [141/328], Loss: 0.0111, Train Accuracy: 99.22%\n","Epoch [82/100], Step [142/328], Loss: 0.0126, Train Accuracy: 99.22%\n","Epoch [82/100], Step [143/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [82/100], Step [144/328], Loss: 0.0323, Train Accuracy: 98.44%\n","Epoch [82/100], Step [145/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [82/100], Step [146/328], Loss: 0.0466, Train Accuracy: 97.66%\n","Epoch [82/100], Step [147/328], Loss: 0.0196, Train Accuracy: 100.00%\n","Epoch [82/100], Step [148/328], Loss: 0.0095, Train Accuracy: 100.00%\n","Epoch [82/100], Step [149/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [82/100], Step [150/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [82/100], Step [151/328], Loss: 0.0308, Train Accuracy: 99.22%\n","Epoch [82/100], Step [152/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [82/100], Step [153/328], Loss: 0.0345, Train Accuracy: 98.44%\n","Epoch [82/100], Step [154/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [82/100], Step [155/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [82/100], Step [156/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [82/100], Step [157/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [82/100], Step [158/328], Loss: 0.0147, Train Accuracy: 99.22%\n","Epoch [82/100], Step [159/328], Loss: 0.0062, Train Accuracy: 100.00%\n","Epoch [82/100], Step [160/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [82/100], Step [161/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [82/100], Step [162/328], Loss: 0.0231, Train Accuracy: 99.22%\n","Epoch [82/100], Step [163/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [82/100], Step [164/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [82/100], Step [165/328], Loss: 0.0090, Train Accuracy: 100.00%\n","Epoch [82/100], Step [166/328], Loss: 0.0077, Train Accuracy: 100.00%\n","Epoch [82/100], Step [167/328], Loss: 0.0226, Train Accuracy: 99.22%\n","Epoch [82/100], Step [168/328], Loss: 0.0039, Train Accuracy: 100.00%\n","Epoch [82/100], Step [169/328], Loss: 0.1661, Train Accuracy: 98.44%\n","Epoch [82/100], Step [170/328], Loss: 0.0125, Train Accuracy: 99.22%\n","Epoch [82/100], Step [171/328], Loss: 0.0174, Train Accuracy: 100.00%\n","Epoch [82/100], Step [172/328], Loss: 0.0354, Train Accuracy: 97.66%\n","Epoch [82/100], Step [173/328], Loss: 0.0109, Train Accuracy: 99.22%\n","Epoch [82/100], Step [174/328], Loss: 0.0315, Train Accuracy: 99.22%\n","Epoch [82/100], Step [175/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [82/100], Step [176/328], Loss: 0.0354, Train Accuracy: 99.22%\n","Epoch [82/100], Step [177/328], Loss: 0.0513, Train Accuracy: 97.66%\n","Epoch [82/100], Step [178/328], Loss: 0.0851, Train Accuracy: 96.88%\n","Epoch [82/100], Step [179/328], Loss: 0.0096, Train Accuracy: 99.22%\n","Epoch [82/100], Step [180/328], Loss: 0.0327, Train Accuracy: 99.22%\n","Epoch [82/100], Step [181/328], Loss: 0.0317, Train Accuracy: 98.44%\n","Epoch [82/100], Step [182/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [82/100], Step [183/328], Loss: 0.0262, Train Accuracy: 99.22%\n","Epoch [82/100], Step [184/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [82/100], Step [185/328], Loss: 0.0556, Train Accuracy: 98.44%\n","Epoch [82/100], Step [186/328], Loss: 0.0083, Train Accuracy: 100.00%\n","Epoch [82/100], Step [187/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [82/100], Step [188/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [82/100], Step [189/328], Loss: 0.0217, Train Accuracy: 98.44%\n","Epoch [82/100], Step [190/328], Loss: 0.0130, Train Accuracy: 99.22%\n","Epoch [82/100], Step [191/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [82/100], Step [192/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [82/100], Step [193/328], Loss: 0.0330, Train Accuracy: 98.44%\n","Epoch [82/100], Step [194/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [82/100], Step [195/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [82/100], Step [196/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [82/100], Step [197/328], Loss: 0.0096, Train Accuracy: 99.22%\n","Epoch [82/100], Step [198/328], Loss: 0.0116, Train Accuracy: 99.22%\n","Epoch [82/100], Step [199/328], Loss: 0.0117, Train Accuracy: 99.22%\n","Epoch [82/100], Step [200/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [82/100], Step [201/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [82/100], Step [202/328], Loss: 0.0093, Train Accuracy: 99.22%\n","Epoch [82/100], Step [203/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [82/100], Step [204/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [82/100], Step [205/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [82/100], Step [206/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [82/100], Step [207/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [82/100], Step [208/328], Loss: 0.0415, Train Accuracy: 97.66%\n","Epoch [82/100], Step [209/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [82/100], Step [210/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [82/100], Step [211/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [82/100], Step [212/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [82/100], Step [213/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [82/100], Step [214/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [82/100], Step [215/328], Loss: 0.0155, Train Accuracy: 99.22%\n","Epoch [82/100], Step [216/328], Loss: 0.0110, Train Accuracy: 99.22%\n","Epoch [82/100], Step [217/328], Loss: 0.0113, Train Accuracy: 99.22%\n","Epoch [82/100], Step [218/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [82/100], Step [219/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [82/100], Step [220/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [82/100], Step [221/328], Loss: 0.0076, Train Accuracy: 100.00%\n","Epoch [82/100], Step [222/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [82/100], Step [223/328], Loss: 0.0088, Train Accuracy: 99.22%\n","Epoch [82/100], Step [224/328], Loss: 0.0055, Train Accuracy: 100.00%\n","Epoch [82/100], Step [225/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [82/100], Step [226/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [82/100], Step [227/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [82/100], Step [228/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [82/100], Step [229/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [82/100], Step [230/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [82/100], Step [231/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [82/100], Step [232/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [82/100], Step [233/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [82/100], Step [234/328], Loss: 0.0076, Train Accuracy: 99.22%\n","Epoch [82/100], Step [235/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [82/100], Step [236/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [82/100], Step [237/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [82/100], Step [238/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [82/100], Step [239/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [82/100], Step [240/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [82/100], Step [241/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [82/100], Step [242/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [82/100], Step [243/328], Loss: 0.0067, Train Accuracy: 100.00%\n","Epoch [82/100], Step [244/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [82/100], Step [245/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [82/100], Step [246/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [82/100], Step [247/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [82/100], Step [248/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [82/100], Step [249/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [82/100], Step [250/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [82/100], Step [251/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [82/100], Step [252/328], Loss: 0.0080, Train Accuracy: 99.22%\n","Epoch [82/100], Step [253/328], Loss: 0.0093, Train Accuracy: 99.22%\n","Epoch [82/100], Step [254/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [82/100], Step [255/328], Loss: 0.0060, Train Accuracy: 100.00%\n","Epoch [82/100], Step [256/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [82/100], Step [257/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [82/100], Step [258/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [82/100], Step [259/328], Loss: 0.0185, Train Accuracy: 99.22%\n","Epoch [82/100], Step [260/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [82/100], Step [261/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [82/100], Step [262/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [82/100], Step [263/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [82/100], Step [264/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [82/100], Step [265/328], Loss: 0.0229, Train Accuracy: 98.44%\n","Epoch [82/100], Step [266/328], Loss: 0.0187, Train Accuracy: 99.22%\n","Epoch [82/100], Step [267/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [82/100], Step [268/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [82/100], Step [269/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [82/100], Step [270/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [82/100], Step [271/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [82/100], Step [272/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [82/100], Step [273/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [82/100], Step [274/328], Loss: 0.0253, Train Accuracy: 99.22%\n","Epoch [82/100], Step [275/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [82/100], Step [276/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [82/100], Step [277/328], Loss: 0.0157, Train Accuracy: 98.44%\n","Epoch [82/100], Step [278/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [82/100], Step [279/328], Loss: 0.0075, Train Accuracy: 100.00%\n","Epoch [82/100], Step [280/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [82/100], Step [281/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [82/100], Step [282/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [82/100], Step [283/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [82/100], Step [284/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [82/100], Step [285/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [82/100], Step [286/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [82/100], Step [287/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [82/100], Step [288/328], Loss: 0.0149, Train Accuracy: 99.22%\n","Epoch [82/100], Step [289/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [82/100], Step [290/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [82/100], Step [291/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [82/100], Step [292/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [82/100], Step [293/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [82/100], Step [294/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [82/100], Step [295/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [82/100], Step [296/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [82/100], Step [297/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [82/100], Step [298/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [82/100], Step [299/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [82/100], Step [300/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [82/100], Step [301/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [82/100], Step [302/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [82/100], Step [303/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [82/100], Step [304/328], Loss: 0.0082, Train Accuracy: 99.22%\n","Epoch [82/100], Step [305/328], Loss: 0.0160, Train Accuracy: 99.22%\n","Epoch [82/100], Step [306/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [82/100], Step [307/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [82/100], Step [308/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [82/100], Step [309/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [82/100], Step [310/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [82/100], Step [311/328], Loss: 0.0075, Train Accuracy: 99.22%\n","Epoch [82/100], Step [312/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [82/100], Step [313/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [82/100], Step [314/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [82/100], Step [315/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [82/100], Step [316/328], Loss: 0.0049, Train Accuracy: 100.00%\n","Epoch [82/100], Step [317/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [82/100], Step [318/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [82/100], Step [319/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [82/100], Step [320/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [82/100], Step [321/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [82/100], Step [322/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [82/100], Step [323/328], Loss: 0.0066, Train Accuracy: 99.22%\n","Epoch [82/100], Step [324/328], Loss: 0.0070, Train Accuracy: 100.00%\n","Epoch [82/100], Step [325/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [82/100], Step [326/328], Loss: 0.0123, Train Accuracy: 99.22%\n","Epoch [82/100], Step [327/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [82/100], Step [328/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [83/100], Step [1/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [83/100], Step [2/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [83/100], Step [3/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [83/100], Step [4/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [83/100], Step [5/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [83/100], Step [6/328], Loss: 0.0085, Train Accuracy: 99.22%\n","Epoch [83/100], Step [7/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [83/100], Step [8/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [83/100], Step [9/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [83/100], Step [10/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [83/100], Step [11/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [83/100], Step [12/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [83/100], Step [13/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [83/100], Step [14/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [83/100], Step [15/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [83/100], Step [16/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [83/100], Step [17/328], Loss: 0.0259, Train Accuracy: 99.22%\n","Epoch [83/100], Step [18/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [83/100], Step [19/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [83/100], Step [20/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [83/100], Step [21/328], Loss: 0.0093, Train Accuracy: 100.00%\n","Epoch [83/100], Step [22/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [83/100], Step [23/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [83/100], Step [24/328], Loss: 0.0084, Train Accuracy: 99.22%\n","Epoch [83/100], Step [25/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [83/100], Step [26/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [83/100], Step [27/328], Loss: 0.0079, Train Accuracy: 99.22%\n","Epoch [83/100], Step [28/328], Loss: 0.0338, Train Accuracy: 99.22%\n","Epoch [83/100], Step [29/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [83/100], Step [30/328], Loss: 0.0170, Train Accuracy: 99.22%\n","Epoch [83/100], Step [31/328], Loss: 0.0033, Train Accuracy: 100.00%\n","Epoch [83/100], Step [32/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [83/100], Step [33/328], Loss: 0.0078, Train Accuracy: 100.00%\n","Epoch [83/100], Step [34/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [83/100], Step [35/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [83/100], Step [36/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [83/100], Step [37/328], Loss: 0.0132, Train Accuracy: 100.00%\n","Epoch [83/100], Step [38/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [83/100], Step [39/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [83/100], Step [40/328], Loss: 0.0186, Train Accuracy: 98.44%\n","Epoch [83/100], Step [41/328], Loss: 0.0013, Train Accuracy: 100.00%\n","Epoch [83/100], Step [42/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [83/100], Step [43/328], Loss: 0.0024, Train Accuracy: 100.00%\n","Epoch [83/100], Step [44/328], Loss: 0.0320, Train Accuracy: 99.22%\n","Epoch [83/100], Step [45/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [83/100], Step [46/328], Loss: 0.0069, Train Accuracy: 100.00%\n","Epoch [83/100], Step [47/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [83/100], Step [48/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [83/100], Step [49/328], Loss: 0.0072, Train Accuracy: 100.00%\n","Epoch [83/100], Step [50/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [83/100], Step [51/328], Loss: 0.0732, Train Accuracy: 98.44%\n","Epoch [83/100], Step [52/328], Loss: 0.0165, Train Accuracy: 99.22%\n","Epoch [83/100], Step [53/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [83/100], Step [54/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [83/100], Step [55/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [83/100], Step [56/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [83/100], Step [57/328], Loss: 0.0220, Train Accuracy: 98.44%\n","Epoch [83/100], Step [58/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [83/100], Step [59/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [83/100], Step [60/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [83/100], Step [61/328], Loss: 0.0064, Train Accuracy: 100.00%\n","Epoch [83/100], Step [62/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [83/100], Step [63/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [83/100], Step [64/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [83/100], Step [65/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [83/100], Step [66/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [83/100], Step [67/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [83/100], Step [68/328], Loss: 0.0098, Train Accuracy: 100.00%\n","Epoch [83/100], Step [69/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [83/100], Step [70/328], Loss: 0.0081, Train Accuracy: 100.00%\n","Epoch [83/100], Step [71/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [83/100], Step [72/328], Loss: 0.0201, Train Accuracy: 99.22%\n","Epoch [83/100], Step [73/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [83/100], Step [74/328], Loss: 0.0052, Train Accuracy: 100.00%\n","Epoch [83/100], Step [75/328], Loss: 0.0061, Train Accuracy: 100.00%\n","Epoch [83/100], Step [76/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [83/100], Step [77/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [83/100], Step [78/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [83/100], Step [79/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [83/100], Step [80/328], Loss: 0.0709, Train Accuracy: 98.44%\n","Epoch [83/100], Step [81/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [83/100], Step [82/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [83/100], Step [83/328], Loss: 0.0108, Train Accuracy: 100.00%\n","Epoch [83/100], Step [84/328], Loss: 0.0028, Train Accuracy: 100.00%\n","Epoch [83/100], Step [85/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [83/100], Step [86/328], Loss: 0.0037, Train Accuracy: 100.00%\n","Epoch [83/100], Step [87/328], Loss: 0.0040, Train Accuracy: 100.00%\n","Epoch [83/100], Step [88/328], Loss: 0.0434, Train Accuracy: 98.44%\n","Epoch [83/100], Step [89/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [83/100], Step [90/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [83/100], Step [91/328], Loss: 0.0118, Train Accuracy: 99.22%\n","Epoch [83/100], Step [92/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [83/100], Step [93/328], Loss: 0.0569, Train Accuracy: 97.66%\n","Epoch [83/100], Step [94/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [83/100], Step [95/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [83/100], Step [96/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [83/100], Step [97/328], Loss: 0.0208, Train Accuracy: 99.22%\n","Epoch [83/100], Step [98/328], Loss: 0.0495, Train Accuracy: 98.44%\n","Epoch [83/100], Step [99/328], Loss: 0.0245, Train Accuracy: 99.22%\n","Epoch [83/100], Step [100/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [83/100], Step [101/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [83/100], Step [102/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [83/100], Step [103/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [83/100], Step [104/328], Loss: 0.0531, Train Accuracy: 98.44%\n","Epoch [83/100], Step [105/328], Loss: 0.0101, Train Accuracy: 99.22%\n","Epoch [83/100], Step [106/328], Loss: 0.0080, Train Accuracy: 99.22%\n","Epoch [83/100], Step [107/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [83/100], Step [108/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [83/100], Step [109/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [83/100], Step [110/328], Loss: 0.0066, Train Accuracy: 99.22%\n","Epoch [83/100], Step [111/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [83/100], Step [112/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [83/100], Step [113/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [83/100], Step [114/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [83/100], Step [115/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [83/100], Step [116/328], Loss: 0.0068, Train Accuracy: 100.00%\n","Epoch [83/100], Step [117/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [83/100], Step [118/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [83/100], Step [119/328], Loss: 0.0099, Train Accuracy: 99.22%\n","Epoch [83/100], Step [120/328], Loss: 0.0045, Train Accuracy: 100.00%\n","Epoch [83/100], Step [121/328], Loss: 0.0205, Train Accuracy: 98.44%\n","Epoch [83/100], Step [122/328], Loss: 0.0069, Train Accuracy: 100.00%\n","Epoch [83/100], Step [123/328], Loss: 0.0067, Train Accuracy: 99.22%\n","Epoch [83/100], Step [124/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [83/100], Step [125/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [83/100], Step [126/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [83/100], Step [127/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [83/100], Step [128/328], Loss: 0.0031, Train Accuracy: 100.00%\n","Epoch [83/100], Step [129/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [83/100], Step [130/328], Loss: 0.0029, Train Accuracy: 100.00%\n","Epoch [83/100], Step [131/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [83/100], Step [132/328], Loss: 0.0119, Train Accuracy: 99.22%\n","Epoch [83/100], Step [133/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [83/100], Step [134/328], Loss: 0.0106, Train Accuracy: 99.22%\n","Epoch [83/100], Step [135/328], Loss: 0.0208, Train Accuracy: 99.22%\n","Epoch [83/100], Step [136/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [83/100], Step [137/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [83/100], Step [138/328], Loss: 0.0137, Train Accuracy: 99.22%\n","Epoch [83/100], Step [139/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [83/100], Step [140/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [83/100], Step [141/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [83/100], Step [142/328], Loss: 0.0101, Train Accuracy: 99.22%\n","Epoch [83/100], Step [143/328], Loss: 0.0066, Train Accuracy: 100.00%\n","Epoch [83/100], Step [144/328], Loss: 0.0165, Train Accuracy: 99.22%\n","Epoch [83/100], Step [145/328], Loss: 0.0853, Train Accuracy: 98.44%\n","Epoch [83/100], Step [146/328], Loss: 0.0601, Train Accuracy: 97.66%\n","Epoch [83/100], Step [147/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [83/100], Step [148/328], Loss: 0.0204, Train Accuracy: 99.22%\n","Epoch [83/100], Step [149/328], Loss: 0.0667, Train Accuracy: 96.88%\n","Epoch [83/100], Step [150/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [83/100], Step [151/328], Loss: 0.0138, Train Accuracy: 99.22%\n","Epoch [83/100], Step [152/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [83/100], Step [153/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [83/100], Step [154/328], Loss: 0.0498, Train Accuracy: 97.66%\n","Epoch [83/100], Step [155/328], Loss: 0.0686, Train Accuracy: 99.22%\n","Epoch [83/100], Step [156/328], Loss: 0.0156, Train Accuracy: 99.22%\n","Epoch [83/100], Step [157/328], Loss: 0.0417, Train Accuracy: 99.22%\n","Epoch [83/100], Step [158/328], Loss: 0.0548, Train Accuracy: 98.44%\n","Epoch [83/100], Step [159/328], Loss: 0.0474, Train Accuracy: 97.66%\n","Epoch [83/100], Step [160/328], Loss: 0.0078, Train Accuracy: 100.00%\n","Epoch [83/100], Step [161/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [83/100], Step [162/328], Loss: 0.0250, Train Accuracy: 98.44%\n","Epoch [83/100], Step [163/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [83/100], Step [164/328], Loss: 0.0347, Train Accuracy: 98.44%\n","Epoch [83/100], Step [165/328], Loss: 0.0144, Train Accuracy: 99.22%\n","Epoch [83/100], Step [166/328], Loss: 0.0071, Train Accuracy: 100.00%\n","Epoch [83/100], Step [167/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [83/100], Step [168/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [83/100], Step [169/328], Loss: 0.0065, Train Accuracy: 100.00%\n","Epoch [83/100], Step [170/328], Loss: 0.0202, Train Accuracy: 99.22%\n","Epoch [83/100], Step [171/328], Loss: 0.0202, Train Accuracy: 99.22%\n","Epoch [83/100], Step [172/328], Loss: 0.0128, Train Accuracy: 99.22%\n","Epoch [83/100], Step [173/328], Loss: 0.0053, Train Accuracy: 100.00%\n","Epoch [83/100], Step [174/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [83/100], Step [175/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [83/100], Step [176/328], Loss: 0.0420, Train Accuracy: 99.22%\n","Epoch [83/100], Step [177/328], Loss: 0.0288, Train Accuracy: 98.44%\n","Epoch [83/100], Step [178/328], Loss: 0.0104, Train Accuracy: 100.00%\n","Epoch [83/100], Step [179/328], Loss: 0.0140, Train Accuracy: 100.00%\n","Epoch [83/100], Step [180/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [83/100], Step [181/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [83/100], Step [182/328], Loss: 0.0265, Train Accuracy: 98.44%\n","Epoch [83/100], Step [183/328], Loss: 0.0582, Train Accuracy: 97.66%\n","Epoch [83/100], Step [184/328], Loss: 0.0598, Train Accuracy: 98.44%\n","Epoch [83/100], Step [185/328], Loss: 0.0186, Train Accuracy: 99.22%\n","Epoch [83/100], Step [186/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [83/100], Step [187/328], Loss: 0.0613, Train Accuracy: 98.44%\n","Epoch [83/100], Step [188/328], Loss: 0.0720, Train Accuracy: 96.88%\n","Epoch [83/100], Step [189/328], Loss: 0.0291, Train Accuracy: 99.22%\n","Epoch [83/100], Step [190/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [83/100], Step [191/328], Loss: 0.0158, Train Accuracy: 99.22%\n","Epoch [83/100], Step [192/328], Loss: 0.0099, Train Accuracy: 99.22%\n","Epoch [83/100], Step [193/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [83/100], Step [194/328], Loss: 0.0651, Train Accuracy: 97.66%\n","Epoch [83/100], Step [195/328], Loss: 0.0122, Train Accuracy: 100.00%\n","Epoch [83/100], Step [196/328], Loss: 0.0006, Train Accuracy: 100.00%\n","Epoch [83/100], Step [197/328], Loss: 0.0122, Train Accuracy: 99.22%\n","Epoch [83/100], Step [198/328], Loss: 0.0047, Train Accuracy: 100.00%\n","Epoch [83/100], Step [199/328], Loss: 0.0703, Train Accuracy: 97.66%\n","Epoch [83/100], Step [200/328], Loss: 0.0383, Train Accuracy: 99.22%\n","Epoch [83/100], Step [201/328], Loss: 0.0022, Train Accuracy: 100.00%\n","Epoch [83/100], Step [202/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [83/100], Step [203/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [83/100], Step [204/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [83/100], Step [205/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [83/100], Step [206/328], Loss: 0.0279, Train Accuracy: 98.44%\n","Epoch [83/100], Step [207/328], Loss: 0.0262, Train Accuracy: 98.44%\n","Epoch [83/100], Step [208/328], Loss: 0.0147, Train Accuracy: 99.22%\n","Epoch [83/100], Step [209/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [83/100], Step [210/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [83/100], Step [211/328], Loss: 0.0001, Train Accuracy: 100.00%\n","Epoch [83/100], Step [212/328], Loss: 0.0009, Train Accuracy: 100.00%\n","Epoch [83/100], Step [213/328], Loss: 0.0096, Train Accuracy: 100.00%\n","Epoch [83/100], Step [214/328], Loss: 0.0202, Train Accuracy: 98.44%\n","Epoch [83/100], Step [215/328], Loss: 0.0709, Train Accuracy: 97.66%\n","Epoch [83/100], Step [216/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [83/100], Step [217/328], Loss: 0.0011, Train Accuracy: 100.00%\n","Epoch [83/100], Step [218/328], Loss: 0.0002, Train Accuracy: 100.00%\n","Epoch [83/100], Step [219/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [83/100], Step [220/328], Loss: 0.0877, Train Accuracy: 98.44%\n","Epoch [83/100], Step [221/328], Loss: 0.0074, Train Accuracy: 99.22%\n","Epoch [83/100], Step [222/328], Loss: 0.0232, Train Accuracy: 99.22%\n","Epoch [83/100], Step [223/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [83/100], Step [224/328], Loss: 0.0168, Train Accuracy: 98.44%\n","Epoch [83/100], Step [225/328], Loss: 0.0030, Train Accuracy: 100.00%\n","Epoch [83/100], Step [226/328], Loss: 0.0362, Train Accuracy: 99.22%\n","Epoch [83/100], Step [227/328], Loss: 0.0208, Train Accuracy: 99.22%\n","Epoch [83/100], Step [228/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [83/100], Step [229/328], Loss: 0.0017, Train Accuracy: 100.00%\n","Epoch [83/100], Step [230/328], Loss: 0.0077, Train Accuracy: 100.00%\n","Epoch [83/100], Step [231/328], Loss: 0.0048, Train Accuracy: 100.00%\n","Epoch [83/100], Step [232/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [83/100], Step [233/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [83/100], Step [234/328], Loss: 0.0064, Train Accuracy: 100.00%\n","Epoch [83/100], Step [235/328], Loss: 0.0223, Train Accuracy: 99.22%\n","Epoch [83/100], Step [236/328], Loss: 0.0128, Train Accuracy: 100.00%\n","Epoch [83/100], Step [237/328], Loss: 0.0416, Train Accuracy: 98.44%\n","Epoch [83/100], Step [238/328], Loss: 0.0051, Train Accuracy: 100.00%\n","Epoch [83/100], Step [239/328], Loss: 0.0018, Train Accuracy: 100.00%\n","Epoch [83/100], Step [240/328], Loss: 0.0016, Train Accuracy: 100.00%\n","Epoch [83/100], Step [241/328], Loss: 0.0019, Train Accuracy: 100.00%\n","Epoch [83/100], Step [242/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [83/100], Step [243/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [83/100], Step [244/328], Loss: 0.0256, Train Accuracy: 99.22%\n","Epoch [83/100], Step [245/328], Loss: 0.0038, Train Accuracy: 100.00%\n","Epoch [83/100], Step [246/328], Loss: 0.0057, Train Accuracy: 100.00%\n","Epoch [83/100], Step [247/328], Loss: 0.0058, Train Accuracy: 100.00%\n","Epoch [83/100], Step [248/328], Loss: 0.0148, Train Accuracy: 99.22%\n","Epoch [83/100], Step [249/328], Loss: 0.0003, Train Accuracy: 100.00%\n","Epoch [83/100], Step [250/328], Loss: 0.0115, Train Accuracy: 99.22%\n","Epoch [83/100], Step [251/328], Loss: 0.0046, Train Accuracy: 100.00%\n","Epoch [83/100], Step [252/328], Loss: 0.0042, Train Accuracy: 100.00%\n","Epoch [83/100], Step [253/328], Loss: 0.0043, Train Accuracy: 100.00%\n","Epoch [83/100], Step [254/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [83/100], Step [255/328], Loss: 0.0005, Train Accuracy: 100.00%\n","Epoch [83/100], Step [256/328], Loss: 0.0010, Train Accuracy: 100.00%\n","Epoch [83/100], Step [257/328], Loss: 0.0166, Train Accuracy: 99.22%\n","Epoch [83/100], Step [258/328], Loss: 0.0020, Train Accuracy: 100.00%\n","Epoch [83/100], Step [259/328], Loss: 0.0273, Train Accuracy: 99.22%\n","Epoch [83/100], Step [260/328], Loss: 0.0084, Train Accuracy: 99.22%\n","Epoch [83/100], Step [261/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [83/100], Step [262/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [83/100], Step [263/328], Loss: 0.0275, Train Accuracy: 99.22%\n","Epoch [83/100], Step [264/328], Loss: 0.0095, Train Accuracy: 99.22%\n","Epoch [83/100], Step [265/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [83/100], Step [266/328], Loss: 0.0004, Train Accuracy: 100.00%\n","Epoch [83/100], Step [267/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [83/100], Step [268/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [83/100], Step [269/328], Loss: 0.0184, Train Accuracy: 99.22%\n","Epoch [83/100], Step [270/328], Loss: 0.0056, Train Accuracy: 100.00%\n","Epoch [83/100], Step [271/328], Loss: 0.0105, Train Accuracy: 99.22%\n","Epoch [83/100], Step [272/328], Loss: 0.0402, Train Accuracy: 98.44%\n","Epoch [83/100], Step [273/328], Loss: 0.0145, Train Accuracy: 99.22%\n","Epoch [83/100], Step [274/328], Loss: 0.0036, Train Accuracy: 100.00%\n","Epoch [83/100], Step [275/328], Loss: 0.0044, Train Accuracy: 100.00%\n","Epoch [83/100], Step [276/328], Loss: 0.0026, Train Accuracy: 100.00%\n","Epoch [83/100], Step [277/328], Loss: 0.0027, Train Accuracy: 100.00%\n","Epoch [83/100], Step [278/328], Loss: 0.0124, Train Accuracy: 99.22%\n","Epoch [83/100], Step [279/328], Loss: 0.0167, Train Accuracy: 99.22%\n","Epoch [83/100], Step [280/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [83/100], Step [281/328], Loss: 0.0034, Train Accuracy: 100.00%\n","Epoch [83/100], Step [282/328], Loss: 0.0015, Train Accuracy: 100.00%\n","Epoch [83/100], Step [283/328], Loss: 0.0021, Train Accuracy: 100.00%\n","Epoch [83/100], Step [284/328], Loss: 0.0189, Train Accuracy: 99.22%\n","Epoch [83/100], Step [285/328], Loss: 0.0128, Train Accuracy: 99.22%\n","Epoch [83/100], Step [286/328], Loss: 0.0012, Train Accuracy: 100.00%\n","Epoch [83/100], Step [287/328], Loss: 0.0060, Train Accuracy: 100.00%\n","Epoch [83/100], Step [288/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [83/100], Step [289/328], Loss: 0.0025, Train Accuracy: 100.00%\n","Epoch [83/100], Step [290/328], Loss: 0.0314, Train Accuracy: 99.22%\n","Epoch [83/100], Step [291/328], Loss: 0.0041, Train Accuracy: 100.00%\n","Epoch [83/100], Step [292/328], Loss: 0.0007, Train Accuracy: 100.00%\n","Epoch [83/100], Step [293/328], Loss: 0.0035, Train Accuracy: 100.00%\n","Epoch [83/100], Step [294/328], Loss: 0.0032, Train Accuracy: 100.00%\n","Epoch [83/100], Step [295/328], Loss: 0.0161, Train Accuracy: 99.22%\n","Epoch [83/100], Step [296/328], Loss: 0.0014, Train Accuracy: 100.00%\n","Epoch [83/100], Step [297/328], Loss: 0.0331, Train Accuracy: 98.44%\n","Epoch [83/100], Step [298/328], Loss: 0.0008, Train Accuracy: 100.00%\n","Epoch [83/100], Step [299/328], Loss: 0.0893, Train Accuracy: 96.88%\n","Epoch [83/100], Step [300/328], Loss: 0.0054, Train Accuracy: 100.00%\n","Epoch [83/100], Step [301/328], Loss: 0.0309, Train Accuracy: 98.44%\n","Epoch [83/100], Step [302/328], Loss: 0.0102, Train Accuracy: 99.22%\n","Epoch [83/100], Step [303/328], Loss: 0.1804, Train Accuracy: 94.53%\n","Epoch [83/100], Step [304/328], Loss: 0.0251, Train Accuracy: 99.22%\n","Epoch [83/100], Step [305/328], Loss: 0.1231, Train Accuracy: 96.88%\n","Epoch [83/100], Step [306/328], Loss: 0.0302, Train Accuracy: 98.44%\n","Epoch [83/100], Step [307/328], Loss: 0.0023, Train Accuracy: 100.00%\n","Epoch [83/100], Step [308/328], Loss: 0.0131, Train Accuracy: 99.22%\n"]}]},{"cell_type":"code","source":["torch.save(cnn,'cnnC3_gearbox_100epochs.pth')"],"metadata":{"id":"r4bsgYzrsSrd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_step = len(test_loader)\n","print(total_step)\n","loss_list_test = []\n","acc_list_test = []\n","pred_list = []\n","labels_list = []\n","with torch.no_grad():\n","    for i, (signals, labels) in enumerate(test_loader):\n","        # Run the forward pass\n","        signals, labels = signals.to(device), labels.to(device)\n","        signals=signals\n","        labels=labels\n","        outputs = cnn(signals.double())\n","        # pred_list.append(outputs)\n","        # labels_list.append(labels)\n","        loss = criterion(outputs, labels.long())\n","        loss_list_test.append(loss.item())\n","        total = labels.size(0)\n","        _, predicted = torch.max(outputs.data, 1)\n","        correct = (predicted == labels.long()).sum().item()\n","        acc_list_test.append(correct / total)\n","        # if (epoch) % 1 == 0:\n","        print('Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n","              .format(i + 1, total_step, loss.item(),\n","                      (correct / total) * 100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EaKyEVnWijmT","executionInfo":{"status":"ok","timestamp":1640101967597,"user_tz":-180,"elapsed":1209,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"9bb3b3e2-9274-4d09-a05b-4eac48d31a99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["11\n","Step [1/11], Loss: 0.0264, Accuracy: 99.12%\n","Step [2/11], Loss: 0.0326, Accuracy: 99.02%\n","Step [3/11], Loss: 0.0136, Accuracy: 99.51%\n","Step [4/11], Loss: 0.0221, Accuracy: 99.61%\n","Step [5/11], Loss: 0.0189, Accuracy: 99.41%\n","Step [6/11], Loss: 0.0077, Accuracy: 99.80%\n","Step [7/11], Loss: 0.0243, Accuracy: 99.32%\n","Step [8/11], Loss: 0.0423, Accuracy: 99.51%\n","Step [9/11], Loss: 0.0099, Accuracy: 99.71%\n","Step [10/11], Loss: 0.0159, Accuracy: 99.32%\n","Step [11/11], Loss: 0.0240, Accuracy: 98.78%\n"]}]},{"cell_type":"code","source":["# 1\n","np.mean(np.array(loss_list_test)), np.mean(np.array(acc_list_test)), np.std(np.array(acc_list_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yhb5Idwdlfiv","executionInfo":{"status":"ok","timestamp":1640101972149,"user_tz":-180,"elapsed":331,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"0d8545be-ace7-4052-f106-d69e8fd22f0a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.02161836251636839, 0.9937422048226164, 0.002918727536666369)"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["def get_all_preds(model, loader):\n","    with torch.no_grad():\n","        all_preds = torch.tensor([]).to(device)\n","        all_labels = torch.tensor([]).to(device)\n","        for i, (signals, labels) in enumerate(loader):\n","            signals, labels = signals.to(device), labels.to(device)\n","            model.to(device)\n","            outputs = model(signals.double())\n","            all_preds = torch.cat((all_preds, outputs), dim=0)\n","            all_labels = torch.cat((all_labels, labels), dim=0)\n","    return all_preds, all_labels\n","\n","def get_num_correct(preds, labels):\n","    return preds.argmax(dim=1).eq(labels).sum().item()"],"metadata":{"id":"ArHj-yoalifO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","test_preds, test_labels = get_all_preds(cnn, test_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1JguaiclnJH","executionInfo":{"status":"ok","timestamp":1640101977271,"user_tz":-180,"elapsed":3,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"a293e7a5-50af-404f-c2db-8401e0b063a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 83.5 ms, sys: 985 µs, total: 84.5 ms\n","Wall time: 85.1 ms\n"]}]},{"cell_type":"code","source":["preds_correct = get_num_correct(test_preds, test_labels)\n","\n","print('total correct:', preds_correct)\n","print('accuracy:', preds_correct/len(test_labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_qa_BsQlohP","executionInfo":{"status":"ok","timestamp":1640101978059,"user_tz":-180,"elapsed":790,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"543f2fcd-b864-4d48-e009-d846dfcd2095"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total correct: 10426\n","accuracy: 0.9942780850658021\n"]}]},{"cell_type":"code","source":["stacked = torch.stack((test_labels, test_preds.argmax(dim=1)), dim=1).type(torch.int32)"],"metadata":{"id":"5Sqvx1RFlqGG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cmt = torch.zeros(5,5, dtype=torch.int32)\n","cmt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0hegE2qZltEa","executionInfo":{"status":"ok","timestamp":1640101982900,"user_tz":-180,"elapsed":2,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"02d52dc8-376a-467f-cacb-bbdcab676d28"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0]], dtype=torch.int32)"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["for p in stacked:\n","    tl, pl = p.tolist()\n","    cmt[tl,pl] = cmt[tl,pl] +1"],"metadata":{"id":"HYueS9khlx1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cmt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TXIOKHxklyTi","executionInfo":{"status":"ok","timestamp":1640101985620,"user_tz":-180,"elapsed":2,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"ca73f8f8-6a41-4213-e591-3ea0c781bbbc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2167,    0,    0,    0,    0],\n","        [   0, 2086,    1,   13,    7],\n","        [  16,    0, 2054,    1,    1],\n","        [   4,    0,    1, 2066,    0],\n","        [   4,    2,    4,    6, 2053]], dtype=torch.int32)"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["import itertools\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","\n","def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    # plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    plt.rcParams.update({'font.size': 27})"],"metadata":{"id":"oJu-r62clztZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm = confusion_matrix(test_labels.cpu(), test_preds.argmax(dim=1).cpu())\n","print(type(cm))\n","cm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVDlrm87l2Fh","executionInfo":{"status":"ok","timestamp":1640101989314,"user_tz":-180,"elapsed":514,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"f57d17ba-76fc-46a4-8826-c94e1db1ec26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.ndarray'>\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[2167,    0,    0,    0,    0],\n","       [   0, 2086,    1,   13,    7],\n","       [  16,    0, 2054,    1,    1],\n","       [   4,    0,    1, 2066,    0],\n","       [   4,    2,    4,    6, 2053]])"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["names = ('H', 'C', 'M', 'R', 'S')\n","plt.figure(figsize=(10,10))\n","plot_confusion_matrix(cm, names)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":797},"id":"qVClO74Wl5UZ","executionInfo":{"status":"ok","timestamp":1640102021381,"user_tz":-180,"elapsed":973,"user":{"displayName":"Muhammad Firdaus","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZhMQoGKvqcZdurdnwqIa6niHa2PHaG-1gGpV7=s64","userId":"15817818160504374871"}},"outputId":"b27e4523-c3a5-4136-ce78-408f4a4879e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion matrix, without normalization\n","[[2167    0    0    0    0]\n"," [   0 2086    1   13    7]\n"," [  16    0 2054    1    1]\n"," [   4    0    1 2066    0]\n"," [   4    2    4    6 2053]]\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x720 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":[""],"metadata":{"id":"z8jraMh6slBD"},"execution_count":null,"outputs":[]}]}